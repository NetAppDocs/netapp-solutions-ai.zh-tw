---
sidebar: sidebar 
permalink: data-analytics/kafka-tech-overview.html 
keywords: storagegrid, apache, confluent, kafka, grid manager, 
summary: 本節介紹此解決方案所使用的技術。 
---
= 技術概述
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
本節介紹此解決方案所使用的技術。



== NetAppStorageGRID

NetApp StorageGRID是一個高效能、經濟高效的物件儲存平台。透過使用分層存儲，Confluent Kafka 上儲存在本機儲存或代理程式的 SAN 儲存中的大部分資料都被卸載到遠端物件儲存。此配置可減少重新平衡、擴展或收縮群集或更換故障代理的時間和成本，從而顯著改善操作。物件儲存在管理駐留在物件儲存層的資料方面發揮著重要作用，因此選擇正確的物件儲存非常重要。

StorageGRID使用分散式、基於節點的網格架構提供智慧、策略驅動的全域資料管理。它透過其無所不在的全域物件命名空間與複雜的資料管理功能結合，簡化了 PB 級非結構化資料和數十億個物件的管理。單次呼叫物件存取可跨站點擴展，並簡化高可用性架構，同時確保持續的物件訪問，無論站點或基礎設施是否中斷。

多租戶允許在同一網格內安全地為多個非結構化雲端和企業資料應用程式提供服務，從而提高NetApp StorageGRID的投資報酬率和用例。您可以使用元資料驅動的物件生命週期策略建立多個服務級別，從而優化跨多個地區的耐用性、保護性、效能和位置性。使用者可以調整資料管理策略並監控和應用流量限制，以便在不斷變化的 IT 環境中隨著需求的變化而無中斷地重新調整資料格局。



=== 使用網格管理器進行簡單管理

StorageGRID Grid Manager 是一個基於瀏覽器的圖形介面，可讓您在單一玻璃窗格中設定、管理和監控全球分散位置的StorageGRID系統。

image:confluent-kafka-004.png["此圖顯示輸入/輸出對話框或表示書面內容"]

您可以使用StorageGRID Grid Manager 介面執行下列任務：

* 管理全球分佈的 PB 級物件儲存庫，例如影像、影片和記錄。
* 監控網格節點和服務以確保物件可用性。
* 使用資訊生命週期管理 (ILM) 規則來管理物件資料隨時間推移的放置。這些規則控制著物件資料被攝取後會發生什麼、如何防止資料遺失、物件資料儲存在何處以及儲存多長時間。
* 監控系統內的交易、效能和操作。




=== 資訊生命週期管理政策

StorageGRID具有靈活的資料管理策略，包括保留對象的副本以及使用 EC（擦除編碼）方案（例如 2+1 和 4+2 等）來儲存對象，具體取決於特定的效能和資料保護要求。由於工作負載和需求隨時間而變化，ILM 策略通常也必須隨時間而變化。修改 ILM 策略是一項核心功能，可讓StorageGRID客戶快速輕鬆地適應不斷變化的環境。



=== 表現

StorageGRID透過增加更多儲存節點來擴展效能，這些節點可以是虛擬機器、裸機或專用設備，例如link:https://www.netapp.com/pdf.html?item=/media/7931-ds-3613.pdf["SG5712、SG5760、SG6060 或 SGF6024"^]。在我們的測試中，我們使用 SGF6024 設備以最小尺寸的三節點網格超越了 Apache Kafka 的關鍵效能要求。當客戶使用額外的代理來擴展他們的 Kafka 叢集時，他們可以添加更多的儲存節點來提高效能和容量。



=== 負載平衡器和端點配置

StorageGRID中的管理節點提供網格管理器 UI（使用者介面）和 REST API 端點來檢視、設定和管理您的StorageGRID系統，以及稽核日誌來追蹤系統活動。為了為 Confluent Kafka 分層儲存提供高可用性 S3 端點，我們實作了StorageGRID負載平衡器，它作為管理節點和網關節點上的服務運作。此外，負載平衡器還管理本地流量並與 GSLB（全域伺服器負載平衡）對話以協助進行災難復原。

為了進一步增強端點配置， StorageGRID提供了內建於管理節點的流量分類策略，讓您監控工作負載流量，並對您的工作負載套用各種服務品質 (QoS) 限制。流量分類策略應用於網關節點和管理節點的StorageGRID負載平衡器服務上的端點。這些策略可以幫助流量整形和監控。



=== StorageGRID中的流量分類

StorageGRID內建 QoS 功能。流量分類策略可以幫助監控來自客戶端應用程式的不同類型的 S3 流量。然後，您可以建立並套用策略來根據輸入/輸出頻寬、讀取/寫入並發請求數或讀取/寫入請求率限制此流量。



== 阿帕契卡夫卡

Apache Kafka 是一個用 Java 和 Scala 編寫的使用流處理的軟體匯流排的框架實作。其目的是提供一個統一、高吞吐量、低延遲的平台來處理即時資料饋送。  Kafka可以透過Kafka Connect連接外部系統進行資料匯出和匯入，並提供Java流處理庫Kafka Streams。 Kafka 使用針對效率進行了最佳化的二進位、基於 TCP 的協議，並依賴「訊息集」抽象，該抽象自然地將訊息組合在一起，以減少網路往返的開銷。這使得更大的順序磁碟操作、更大的網路封包和連續的記憶體區塊成為可能，從而使 Kafka 能夠將突發的隨機訊息寫入流轉換為線性寫入。下圖描述了Apache Kafka的基本資料流。

image:confluent-kafka-005.png["此圖顯示輸入/輸出對話框或表示書面內容"]

Kafka 儲存來自任意數量的進程（稱為生產者）的鍵值訊息。資料可以劃分到不同主題內的不同分區。在分區內，訊息嚴格按照其偏移量（訊息在分區內的位置）排序，並與時間戳一起索引和儲存。其他稱為消費者的進程可以從分區讀取訊息。對於流程處理，Kafka 提供了 Streams API，允許編寫 Java 應用程式使用來自 Kafka 的資料並將結果寫回 Kafka。  Apache Kafka 還可以與外部串流處理系統（如 Apache Apex、Apache Flink、Apache Spark、Apache Storm 和 Apache NiFi）協同工作。

Kafka 在一個或多個伺服器（稱為代理）的叢集上運行，所有主題的分區分佈在叢集節點上。此外，分區被複製到多個代理程式。這種架構使得 Kafka 能夠以容錯的方式傳遞大量訊息流，並使其能夠取代一些傳統的訊息傳遞系統，如 Java 訊息服務 (JMS)、高階訊息佇列協定 (AMQP) 等。自 0.11.0.0 版本以來，Kafka 提供事務寫入功能，可使用 Streams API 提供一次串流處理。

Kafka 支援兩種類型的主題：常規主題和壓縮主題。常規主題可以配置保留時間或空間界限。如果有記錄超過指定的保留時間或超出了分割區的空間限制，則允許 Kafka 刪除舊資料以釋放儲存空間。預設情況下，主題的保留時間配置為 7 天，但也可以無限期地儲存資料。對於壓縮主題，記錄不會根據時間或空間界限而過期。相反，Kafka 將後續訊息視為具有相同金鑰的舊訊息的更新，並保證永遠不會刪除每個金鑰的最新訊息。使用者可以透過寫入具有特定鍵的空值的所謂墓碑訊息來徹底刪除訊息。

Kafka 中有五個主要 API：

* 生產者 API。允許應用程式發布記錄流。
* *消費者 API。 *允許應用程式訂閱主題並處理記錄流。
* 連接器 API。執行可重複使用的生產者和消費者 API，將主題連結到現有應用程式。
* 流 API。此 API 將輸入流轉換為輸出並產生結果。
* *管理 API。 *用於管理 Kafka 主題、代理人和其他 Kafka 物件。


消費者和生產者 API 建立在 Kafka 訊息傳遞協定之上，並為 Java 中的 Kafka 消費者和生產者用戶端提供參考實作。底層訊息傳遞協定是一種二進位協議，開發人員可以使用任何程式語言編寫自己的消費者或生產者用戶端。這使得 Kafka 從 Java 虛擬機器 (JVM) 生態系統中解放出來。  Apache Kafka wiki 中維護了可用的非 Java 用戶端清單。



=== Apache Kafka 用例

Apache Kafka 最受歡迎的用途是訊息傳遞、網站活動追蹤、指標、日誌聚合、流處理、事件來源和提交日誌記錄。

* Kafka 提高了吞吐量、內建分區、複製和容錯能力，使其成為大規模訊息處理應用程式的良好解決方案。
* Kafka 可以將追蹤管道中的使用者活動（頁面瀏覽量、搜尋量）重建為一組即時發布-訂閱源。
* Kafka 經常用於營運監控數據。這涉及匯總來自分散式應用程式的統計資料以產生集中的操作資料。
* 許多人使用 Kafka 來取代日誌聚合解決方案。日誌聚合通常從伺服器上收集實體日誌檔案並將它們放在一個中心位置（例如，檔案伺服器或 HDFS）進行處理。 Kafka 抽象檔案詳細資料並將日誌或事件資料以訊息流的形式提供更清晰的抽象。這允許更低延遲的處理並且更容易支援多個資料來源和分散式資料消費。
* 許多 Kafka 使用者在由多個階段組成的處理管道中處理數據，其中從 Kafka 主題中使用原始輸入數據，然後聚合、豐富或以其他方式轉換為新主題以供進一步使用或後續處理。例如，用於推薦新聞文章的處理管道可能會從 RSS 提要中抓取文章內容並將其發佈到「文章」主題。進一步的處理可能會規範化或重複化該內容，並將清理後的文章內容發佈到新主題，最後的處理階段可能會嘗試將該內容推薦給使用者。這樣的處理管道根據各個主題創建即時資料流程圖。
* 事件溯源是一種應用程式設計風格，其中狀態變化被記錄為按時間順序排列的記錄序列。  Kafka 對非常大的儲存日誌資料的支援使其成為以這種風格構建的應用程式的優秀後端。
* Kafka 可以作為分散式系統的一種外部提交日誌。日誌有助於在節點之間複製數據，並充當故障節點恢復其數據的重新同步機制。  Kafka 中的日誌壓縮功能有助於支援這種用例。




== 匯合

Confluent 平台是一個企業級平台，它為 Kafka 提供了先進的功能，旨在幫助加速應用程式開發和連接、透過串流處理實現轉換、簡化企業大規模營運並滿足嚴格的架構要求。 Confluent 由 Apache Kafka 的原始創建者構建，它透過企業級功能擴展了 Kafka 的優勢，同時消除了 Kafka 管理或監控的負擔。如今，財富 100 強企業中有超過 80% 都採用資料流技術，其中大多數都使用 Confluent。



=== 為什麼選擇 Confluent？

透過將歷史資料和即時資料整合到單一的中央事實來源，Confluent 可以輕鬆建立全新類別的現代事件驅動應用程序，獲得通用資料管道，並解鎖具有完全可擴展性、效能和可靠性的強大新用例。



=== Confluent 的用途是什麼？

Confluent 平台讓您專注於如何從資料中獲得商業價值，而不必擔心底層機制，例如如何在不同的系統之間傳輸或整合資料。具體來說，Confluent Platform 簡化了資料來源與 Kafka 的連接、串流應用程式的建置以及 Kafka 基礎設施的保護、監控和管理。如今，Confluent 平台已廣泛應用於眾多產業，從金融服務、全通路零售、自動駕駛汽車到詐欺偵測、微服務和物聯網。

下圖顯示了 Confluent Kafka 平台元件。

image:confluent-kafka-006.png["此圖顯示輸入/輸出對話框或表示書面內容"]



=== Confluent 事件流技術概述

Confluent 平台的核心是 https://kafka.apache.org/["阿帕契卡夫卡"^]，最受歡迎的開源分散式串流平台。  Kafka 的主要功能如下：

* 發布和訂閱記錄流。
* 以容錯的方式儲存記錄流。
* 處理記錄流程。


開箱即用的 Confluent Platform 還包括 Schema Registry、REST Proxy、總共 100 多個預先建置的 Kafka 連接器和 ksqlDB。



=== Confluent 平台企業功能概述

* *匯合控制中心。 *用於管理和監控 Kafka 的基於 GUI 的系統。它允許您輕鬆管理 Kafka Connect 以及建立、編輯和管理與其他系統的連接。
* *適用於 Kubernetes 的 Confluent。 *  Confluent for Kubernetes 是一位 Kubernetes 操作員。 Kubernetes 操作員透過為特定平台應用程式提供獨特的功能和要求來擴展 Kubernetes 的編排功能。對於 Confluent 平台，這包括大幅簡化 Kafka 在 Kubernetes 上的部署流程，並自動執行典型的基礎架構生命週期任務。
* *將連接器匯合至 Kafka。 *連接器使用 Kafka Connect API 將 Kafka 連接到其他系統，例如資料庫、鍵值儲存、搜尋索引和檔案系統。 Confluent Hub 具有適用於最受歡迎的資料來源和接收器的可下載連接器，包括使用 Confluent Platform 對這些連接器進行全面測試和支援的版本。更多詳情請見 https://docs.confluent.io/home/connect/userguide.html["這裡"^]。
* *自平衡集群。 *提供自動負載平衡、故障偵測和自我修復。它支援根據需要新增或停用代理，無需手動調整。
* *匯合簇連接。 *直接將集群連接在一起，並透過連結橋將主題從一個集群鏡像到另一個集群。集群連結簡化了多資料中心、多集群和混合雲部署的設定。
* *匯合自動數據平衡器。 *監控叢集中的代理數量、分區大小、分區數量以及叢集內的領導者數量。它允許您轉移資料以在整個叢集中創建均勻的工作負載，同時限制重新平衡流量以最大限度地減少重新平衡時對生產工作負載的影響。
* *匯合複製器。 *讓在多個資料中心維護多個 Kafka 叢集變得比以往更加簡單。
* *分層儲存。 *提供使用您最喜歡的雲端供應商儲存大量 Kafka 資料的選項，從而減少營運負擔和成本。透過分層存儲，您可以將資料保存在經濟高效的物件儲存中，並且僅在需要更多運算資源時才擴展代理程式。
* Confluent JMS 用戶端。 Confluent Platform 包含一個與 JMS 相容的 Kafka 用戶端。此 Kafka 用戶端實作了 JMS 1.1 標準 API，使用 Kafka 代理作為後端。如果您有使用 JMS 的遺留應用程式並且想要用 Kafka 取代現有的 JMS 訊息代理，這將非常有用。
* *Confluent MQTT 代理。 *提供一種從 MQTT 設備和網關直接向 Kafka 發布資料的方法，無需中間的 MQTT 代理。
* *Confluent 安全插件。 * Confluent 安全外掛程式用於為各種 Confluent 平台工具和產品添加安全功能。目前，有一個可用於 Confluent REST 代理程式的插件，可協助驗證傳入的請求並將經過驗證的主體傳播到對 Kafka 的請求。這使得 Confluent REST 代理客戶端能夠利用 Kafka 代理的多租戶安全功能。

