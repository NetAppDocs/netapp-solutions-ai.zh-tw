<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">閱讀 AI/ML 博客，了解行業趨勢、創新和實際影響，以及開發人員資源、社區見解和使用NetApp AI 解決方案的實用工具。</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">閱讀NetApp專家的 AI 解決方案博客</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">閱讀 AI/ML 博客，了解行業趨勢、創新和實際影響，以及開發人員資源、社區見解和使用NetApp AI 解決方案的實用工具。</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">人工智慧趨勢和產業洞察</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">英語</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">探索各領域的產業趨勢、創新以及現實世界的人工智慧影響。<block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[AI,Analytics,artificial-intelligence]++[在NetApp上閱讀 AI 部落格^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">開發者資源與社區</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">在 Pub 上閱讀 AI 博客</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">為 AI/ML 從業者提供技術見解、實用工具和社群驅動的內容。<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">本文提供了使用 AWS 服務建立 MLOps 管道的指南，重點在於自動化模型再訓練、部署和成本最佳化。</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">第 3 部分 - 建立簡化的 MLOps 管道 (CI/CT/CD)</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">本文提供了使用 AWS 服務建立 MLOps 管道的指南，重點在於自動模型再訓練、部署和成本最佳化。</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">介紹</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">在本教程中，您將學習如何利用各種 AWS 服務建立一個包含持續整合 (CI)、持續訓練 (CT) 和持續部署 (CD) 的簡單 MLOps 管道。與傳統的 DevOps 管道不同，MLOps 需要額外的考慮才能完成操作週期。透過學習本教程，您將深入了解如何將 CT 納入 MLOps 循環，從而實現模型的持續訓練和推理的無縫部署。本教學將引導您完成利用 AWS 服務建立此端對端 MLOps 管道的過程。</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">顯現</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">功能</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">Name</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">評論</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">資料儲存</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">第 1 部分 - 將Amazon FSx for NetApp ONTAP (FSx ONTAP) 作為私有 S3 儲存桶整合到 AWS SageMaker</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell">請參閱<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> 。</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">數據科學 IDE</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS SageMaker</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">第 2 部分 - 利用Amazon FSx for NetApp ONTAP (FSx ONTAP) 作為 SageMaker 模型訓練的資料來源</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">本教程基於<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block>。</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">觸發 MLOps 管道的函數</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">AWS Lambda 函數</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Cron 作業觸發器</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS EventBridge</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">深度學習框架</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">PyTorch</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">AWS Python 開發工具包</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">boto3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">程式設計語言</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">Python</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">先決條件</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">預先設定的 FSx ONTAP檔案系統。本教學利用 FSx ONTAP中儲存的資料進行訓練程序。</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">配置為與上面提到的 FSx ONTAP檔案系統共用相同 VPC 的 *SageMaker Notebook 實例*。</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">在觸發 *AWS Lambda 函數* 之前，請確保 *SageMaker Notebook 實例* 處於 *已停止* 狀態。</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">需要 *ml.g4dn.xlarge* 執行個體類型來利用深度神經網路運算所需的 GPU 加速。</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">架構</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">這個 MLOps 管道是一個實際的實現，它利用 cron 作業來觸發無伺服器功能，進而執行使用生命週期回呼函數註冊的 AWS 服務。 *AWS EventBridge* 充當 cron 作業。它會定期呼叫負責重新訓練和重新部署模型的 *AWS Lambda 函數*。此程序涉及啟動 *AWS SageMaker Notebook* 實例以執行必要的任務。</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">逐步配置</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">生命週期配置</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">若要為 AWS SageMaker Notebook 實例配置生命週期回呼函數，您需要使用*生命週期配置*。此服務可讓您定義啟動筆記本執行個體時需要執行的必要操作。具體來說，可以在*生命週期配置*中實現一個 shell 腳本，以便在訓練和部署過程完成後自動關閉筆記本實例。這是必要的配置，因為成本是 MLOps 中的主要考慮因素之一。</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">值得注意的是，*生命週期配置*的配置需要事先設定。因此，建議在繼續其他 MLOps 管道設定之前優先配置這一方面。</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">若要設定生命週期配置，請開啟 *Sagemaker* 面板並導覽至 *Admin configuration* 部分下的 *Lifecycle configuration*。</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">SageMaker 面板</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">選擇“筆記本實例”選項卡，然後按一下“建立配置”按鈕</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">生命週期配置歡迎頁面</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">將以下程式碼貼到輸入區域。</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">該腳本執行 Jupyter Notebook，用於處理模型的重新訓練和重新部署以進行推理。執行完成後，筆記本將在5分鐘內自動關機。要了解有關問題陳述和代碼實現的更多信息，請參閱<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block>。</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">建立生命週期配置</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">建立後，導覽至 Notebook 實例，選擇目標實例，然後按一下「動作」下拉式功能表下的「更新設定」。</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">更新設定下拉選單</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">選擇已建立的*生命週期配置*，然後按一下*更新筆記本實例*。</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">更新筆記本的生命週期配置</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">AWS Lambda 無伺服器函數</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">如前所述，*AWS Lambda 函數*負責啟動 *AWS SageMaker Notebook 實例*。</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">若要建立 *AWS Lambda 函數*，請導覽至對應的面板，切換至 *函數* 選項卡，然後按一下 *建立函數*。</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">AWS lambda 函數歡迎頁面</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">請在頁面上提交所有必需的條目，並記得將運行時切換為 *Python 3.10*。</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">建立 AWS lambda 函數</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">請驗證指定的角色是否具有所需的權限*AmazonSageMakerFullAccess*，然後按一下*建立功能*按鈕。</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">選擇執行角色</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">選擇已建立的Lambda函數。在代碼標籤中，將以下程式碼複製並貼上到文字區域中。此程式碼啟動名為 *fsxn-ontap* 的筆記本實例。</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">按一下“*部署*”按鈕以套用此程式碼變更。</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">部署</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">若要指定如何觸發此 AWS Lambda 函數，請按一下新增觸發器按鈕。</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">新增 AWS 函數觸發器</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">從下拉式選單中選擇 EventBridge，然後按一下標示為「建立新規則」的單選按鈕。在計劃表達式欄位中，輸入<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block>，然後按一下新增按鈕以建立並將此新的 cron 作業規則套用至 AWS Lambda 函數。</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">完成觸發器</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">完成這兩步驟配置後，每天，*AWS Lambda 函數*都會啟動 *SageMaker Notebook*，使用 *FSx ONTAP* 儲存庫中的資料執行模型重新訓練，將更新後的模型重新部署到生產環境，並自動關閉 *SageMaker Notebook 實例*以優化成本。這確保模型保持最新。</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">開發 MLOps 管道的教學到此結束。</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">這是 FSx ONTAP MLOps 部分的介紹頁面。</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">適用於 MLOps 的Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">本節深入探討 AI 基礎架構開發的實際應用，提供使用 FSx ONTAPMLOps 管道的端對端演練。它包含三個綜合範例，引導您透過這個強大的資料管理平台滿足您的 MLOps 需求。</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">這些文章重點關注：</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">在本節結束時，您將對如何使用 FSx ONTAP簡化 MLOps 流程有深入的了解。</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">這篇文章提供了使用 AWS SageMaker 將 FSx ONTAP配置為私人 S3 儲存桶的指南。</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">本節提供了使用 AWS SageMaker 將 FSx ONTAP配置為私有 S3 儲存桶的指南。</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">以 SageMaker 為例，本頁面提供了將 FSx ONTAP配置為私有 S3 儲存桶的指導。</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">影片連結</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">有關 FSx ONTAP的更多信息，請查看此簡報（<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> )</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">使用者指南</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">伺服器創建</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">建立 SageMaker Notebook 實例</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">開啟 AWS 主控台。在搜尋面板中，搜尋 SageMaker 並點擊服務 *Amazon SageMaker*。</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">開啟 AWS 主控台</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">開啟 Notebook 標籤下的 *Notebook 實例*，點選橘色按鈕 *建立筆記本實例*。</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">AWS SageMaker Notebook執行個體控制台</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">在建立頁面中，輸入*筆記本實例名稱*展開*網路*面板保留其他項目的預設值，並選擇*VPC*、*子網路*和*安全群組*。  （此*VPC*和*Subnet*稍後將用於建立 FSx ONTAP檔案系統）點擊右下角的橘色按鈕*建立筆記本實例*。</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">建立筆記本實例</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">建立 FSx ONTAP檔案系統</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">開啟 AWS 主控台。在搜尋面板中，搜尋 Fsx 並點擊服務 *FSx*。</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">FSx 面板</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">點選*建立檔案系統*。</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">建立檔案系統</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">選擇第一張卡 *FSx ONTAP* 並點選 *下一步*。</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">選擇檔案系統類型</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">在詳細資訊配置頁面中。</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">選擇*標準建立*選項。</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">建立檔案系統面板</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">輸入*檔案系統名稱*和*SSD儲存容量*。</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">指定檔案系統詳細信息</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">確保使用與 *SageMaker Notebook* 實例相同的 *VPC* 和 *subnet*。</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">網路和安全配置</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">為您的 SVM（儲存虛擬機器）輸入*儲存虛擬機器*名稱和*指定密碼*。</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">預設儲存虛擬機器配置</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">保留其他條目的預設值，然後按一下右下角的橘色按鈕「下一步」。</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">確認配置</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">點選審核頁面右下角的橘色按鈕*建立檔案系統*。</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">檢查配置並確認建立</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">啟動 FSx 檔案系統可能需要大約 *20-40 分鐘*。</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">檢查 FSx 控制台</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">伺服器配置</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">ONTAP配置</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">開啟已建立的FSx檔案系統。請確保狀態為*可用*。</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">等待後端創建</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">選擇*管理*標籤並保留*管理端點 - IP 位址*和* ONTAP管理員使用者名稱*。</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">檔案系統詳細資料控制台</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">開啟已建立的*SageMaker Notebook實例*，然後點選*開啟JupyterLab*。</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">AWS SageMaker Notebook 執行個體控制台</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">在 Jupyter Lab 頁面中，開啟一個新的*終端機*。</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Jupyter Lab 歡迎頁面</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">輸入 ssh 命令 ssh &lt;管理員使用者名稱&gt;@&lt; ONTAP伺服器 IP&gt; 登入 FSx ONTAP檔案系統。  （使用者名稱和 IP 位址從步驟 2 檢索）請使用建立 *儲存虛擬機器* 時使用的密碼。</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Jupyter Lab 終端</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">按以下順序執行命令。我們使用 *fsxn-ontap* 作為 *FSx ONTAP私有 S3 儲存桶名稱* 的名稱。請使用*儲存虛擬機器名稱*作為*-vserver* 參數。</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Jupyter Lab 終端輸出</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">執行下列指令來擷取 FSx ONTAP私有 S3 的端點 IP 和憑證。</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">保留端點 IP 和憑證以供將來使用。</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">客戶端配置</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">在 SageMaker Notebook 實例中，建立一個新的 Jupyter 筆記本。</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">開啟一個新的 Jupyter 筆記本</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">使用下列程式碼作為解決方案將檔案上傳到 FSx ONTAP私人 S3 儲存桶。有關全面的程式碼範例，請參閱此筆記本。<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">這完成了 FSx ONTAP和 SageMaker 實例之間的整合。</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">有用的調試清單</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">確保 SageMaker Notebook 實例和 FSx ONTAP檔案系統位於同一個 VPC 中。</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">記得在ONTAP上執行 *set dev* 指令將權限等級設定為 *dev*。</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">常見問題（截至 2023 年 9 月 27 日）</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">Q：為什麼我在將檔案上傳到 FSx ONTAP時收到錯誤「*呼叫 CreateMultipartUpload 操作時發生錯誤（未實作）：您要求的 s3 命令未實作*」？</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">答：作為私有 S3 儲存桶，FSx ONTAP支援上傳最大 100MB 的檔案。使用S3協定時，大於100MB的檔案會被分成100MB的區塊，並呼叫‘CreateMultipartUpload’函數。但是，FSx ONTAP私有 S3 的目前實作不支援此功能。</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">Q：為什麼在將檔案上傳到 FSx ONTAP時出現錯誤「*呼叫 PutObject 操作時發生錯誤（AccessDenied）：存取被拒絕*」？</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">答：若要從 SageMaker Notebook 執行個體存取 FSx ONTAP私有 S3 儲存桶，請將 AWS 憑證切換到 FSx ONTAP憑證。但是，授予實例寫入權限需要一種解決方法，即安裝儲存桶並執行「chmod」shell 命令來更改權限。</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">Q：如何將 FSx ONTAP私有 S3 儲存桶與其他 SageMaker ML 服務整合？</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">答：遺憾的是，SageMaker 服務 SDK 並沒有提供指定私有 S3 儲存桶端點的方法。因此，FSx ONTAP S3 與 Sagemaker Data Wrangler、Sagemaker Clarify、Sagemaker Glue、Sagemaker Athena、Sagemaker AutoML 等 SageMaker 服務不相容。</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">本文是關於使用Amazon FSx for NetApp ONTAP (FSx ONTAP) 在 SageMaker 中訓練 PyTorch 模型的教程，具體針對輪胎品質分類項目。</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">第 2 部分 - 利用 AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) 作為 SageMaker 模型訓練的資料來源</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">本文是關於使用Amazon FSx for NetApp ONTAP (FSx ONTAP) 在 SageMaker 中訓練 PyTorch 模型的教程，具體針對輪胎品質分類項目。</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">本教學提供了一個電腦視覺分類專案的實際範例，提供了在 SageMaker 環境中利用 FSx ONTAP作為資料來源建立 ML 模型的實務經驗。該專案專注於使用深度學習框架 PyTorch 根據輪胎影像對輪胎品質進行分類。它強調使用 FSx ONTAP作為 Amazon SageMaker 中的資料來源來開發機器學習模型。</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">什麼是 FSx ONTAP</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">Amazon FSx ONTAP確實是 AWS 提供的完全託管的儲存解決方案。它利用 NetApp 的ONTAP檔案系統提供可靠且高效能的儲存。透過支援 NFS、SMB 和 iSCSI 等協議，它允許從不同的計算實例和容器進行無縫存取。該服務旨在提供卓越的效能，確保快速且有效率的資料操作。它還具有高可用性和耐用性，確保您的資料保持可存取和保護。此外， Amazon FSx ONTAP的儲存容量是可擴充的，您可以根據需要輕鬆調整。</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">網路環境</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">網路環境</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP （Amazon FSx ONTAP）是一項 AWS 儲存服務。它包括在NetApp ONTAP系統上運行的檔案系統和連接到它的 AWS 管理的系統虛擬機器 (SVM)。在提供的圖中，AWS 管理的NetApp ONTAP伺服器位於 VPC 外部。 SVM作為SageMaker和NetApp ONTAP系統之間的中介，接收來自SageMaker的操作請求並轉送到底層儲存。若要存取 FSx ONTAP，SageMaker 必須放置在與 FSx ONTAP部署相同的 VPC 內。此配置可確保 SageMaker 和 FSx ONTAP之間的通訊和資料存取。</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">資料存取</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">在現實場景中，資料科學家通常利用 FSx ONTAP中儲存的現有資料來建立他們的機器學習模型。但是，出於演示目的，由於 FSx ONTAP檔案系統在建立後最初是空的，因此需要手動上傳訓練資料。這可以透過將 FSx ONTAP作為磁碟區安裝到 SageMaker 來實現。檔案系統成功掛載後，您可以將資料集上傳到掛載位置，以便在 SageMaker 環境中訓練模型。這種方法可讓您利用 FSx ONTAP的儲存容量和功能，同時與 SageMaker 進行模型開發和訓練。</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">第 1 部分 - 將Amazon FSx for NetApp ONTAP (FSx ONTAP) 作為私有 S3 儲存桶整合到 AWS SageMaker</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">資料讀取過程涉及將 FSx ONTAP配置為私有 S3 儲存桶。詳細配置說明請參考<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">整合概述</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">訓練工作流程</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">使用 FSx ONTAP中的訓練資料在 SageMaker 中建立深度學習模型的工作流程可以概括為三個主要步驟：資料載入器定義、模型訓練和部署。從高層次來看，這些步驟構成了 MLOps 管道的基礎。然而，為了全面實施，每個步驟都涉及幾個詳細的子步驟。這些子步驟涵蓋資料預處理、資料集拆分、模型配置、超參數調整、模型評估和模型部署等各種任務。這些步驟確保在 SageMaker 環境中使用來自 FSx ONTAP的訓練資料建構和部署深度學習模型的流程全面有效。</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">逐步集成</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">資料Loader</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">為了使用資料訓練 PyTorch 深度學習網絡，創建了一個資料載入器以方便資料的輸入。資料載入器不僅定義批次大小，還確定讀取和預處理批次中每個記錄的過程。透過配置資料載入器，我們可以批次處理數據，從而實現深度學習網路的訓練。</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">資料載入器由3部分組成。</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">預處理函數</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">上面的程式碼片段示範了使用 *torchvision.transforms* 模組定義影像預處理轉換。在本教程中，建立預處理物件來套用一系列轉換。首先，*ToTensor()* 轉換將影像轉換為張量表示。隨後，*Resize((224,224))* 轉換將影像調整為固定大小 224x224 像素。最後，*Normalize()* 轉換透過減去平均值並除以每個通道的標準差來對張量值進行歸一化。用於標準化的平均值和標準差值通常用於預訓練的神經網路模型。總的來說，這段程式碼透過將圖像資料轉換為張量、調整其大小以及規範化像素值來準備進一步處理或輸入到預先訓練的模型中。</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">PyTorch 資料集類</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">此類別提供取得資料集中記錄總數的功能，並定義讀取每筆記錄資料的方法。在 *__getitem__* 函數中，程式碼利用 boto3 S3 bucket 物件從 FSx ONTAP檢索二進位資料。從 FSx ONTAP存取資料的程式碼樣式類似於從 Amazon S3 讀取資料。後續講解深入探討私有 S3 物件 *bucket* 的創建過程。</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">FSx ONTAP作為私有 S3 儲存庫</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">為了從 SageMaker 中的 FSx ONTAP讀取數據，需要建立一個使用 S3 協定指向 FSx ONTAP儲存的處理程序。這使得 FSx ONTAP可以被視為私人 S3 儲存桶。處理程序配置包括指定 FSx ONTAP SVM 的 IP 位址、儲存桶名稱和必要的憑證。有關取得這些配置項目的詳細說明，請參閱以下文件：<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> 。</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">在上面的例子中，bucket 物件用於實例化 PyTorch 資料集物件。數據集對象將在後續章節中進一步解釋。</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">PyTorch 資料Loader</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">在提供的範例中，指定批次大小為 64，表示每個批次將包含 64 筆記錄。透過結合 PyTorch *Dataset* 類別、預處理函數和訓練批次大小，我們獲得了用於訓練的資料載入器。此資料載入器有助於在訓練階段分批迭代資料集的過程。</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">模型訓練</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">此程式碼實現了標準的 PyTorch 訓練流程。它定義了一個名為*TyreQualityClassifier*的神經網路模型，使用卷積層和線性層對輪胎品質進行分類。訓練循環迭代資料批次，計算損失，並使用反向傳播和最佳化更新模型的參數。此外，它還列印當前時間、紀元、批次和損失以供監控目的。</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">模型部署</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">程式碼將 PyTorch 模型儲存到 *Amazon S3*，因為 SageMaker 要求將模型儲存在 S3 中以便部署。透過將模型上傳到 *Amazon S3*，SageMaker 就可以存取它，從而允許對已部署的模型進行部署和推理。</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">此程式碼有助於在 SageMaker 上部署 PyTorch 模型。它定義了一個自訂序列化器 *TyreQualitySerializer*，它將輸入資料預處理並序列化為 PyTorch 張量。 *TyreQualityPredictor* 類別是自訂預測器，它利用定義的序列化器和 *JSONDeserializer*。程式碼還創建了一個 *PyTorchModel* 物件來指定模型的 S3 位置、IAM 角色、框架版本和推理的入口點。程式碼產生時間戳並根據模型和時間戳記建立端點名稱。最後，使用 deploy 方法部署模型，指定實例數量、實例類型和產生的端點名稱。這使得 PyTorch 模型可以在 SageMaker 上部署並進行推理。</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">推理</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">這是使用已部署端點進行推理的範例。</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">本節總結了有關 Apache Spark 的NetApp儲存解決方案的文檔。</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">結論</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">在本文檔中，我們討論了 Apache Spark 架構、客戶用例以及與大數據、現代分析、AI、ML 和 DL 相關的NetApp儲存產品組合。在我們基於行業標準基準測試工具和客戶需求的效能驗證測試中， NetApp Spark 解決方案展現了相對於原生 Hadoop 系統的卓越效能。本報告中提供的客戶使用案例和效能結果的組合可以幫助您為您的部署選擇合適的 Spark 解決方案。</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">本文檔重點介紹 Apache Spark 架構、客戶用例以及與大數據分析和人工智慧相關的NetApp儲存產品組合。它還展示了使用業界標準 AI、機器學習和深度學習工具針對典型 Hadoop 系統的各種測試結果，以便您可以選擇合適的 Spark 解決方案。</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570：適用於 Apache Spark 的NetApp儲存解決方案：架構、用例和效能結果</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang，Karthikeyan Nagalingam， NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">本文檔重點介紹 Apache Spark 架構、客戶用例以及與大數據分析和人工智慧 (AI) 相關的NetApp儲存產品組合。它還展示了使用業界標準 AI、機器學習 (ML) 和深度學習 (DL) 工具針對典型 Hadoop 系統進行的各種測試結果，以便您可以選擇合適的 Spark 解決方案。首先，您需要一個 Spark 架構、適當的元件和兩種部署模式（叢集和用戶端）。</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">該文件還提供了解決配置問題的客戶用例，並討論了與大數據分析以及 Spark 的 AI、ML 和 DL 相關的NetApp儲存產品組合的概述。然後，我們得到來自 Spark 特定用例和NetApp Spark 解決方案組合的測試結果。</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">客戶挑戰</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">本節重點在於零售、數位行銷、銀行、離散製造、流程製造、政府和專業服務等資料成長產業中客戶面臨的大數據分析和 AI/ML/DL 挑戰。</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">不可預測的表現</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">傳統的 Hadoop 部署通常使用商品硬體。為了提高效能，您必須調整網路、作業系統、Hadoop 叢集、生態系統元件（如 Spark）和硬體。即使您調整每一層，也很難達到所需的效能水平，因為 Hadoop 運行在並非為您的環境的高效能而設計的商用硬體上。</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">介質和節點故障</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">即使在正常條件下，商品硬體也容易故障。如果資料節點上的磁碟發生故障，則 Hadoop 主伺服器預設該節點不健康。然後，它透過網路將該節點上的特定資料從副本複製到健康節點。此過程會減慢任何 Hadoop 作業的網路封包速度。當不健康的節點恢復健康狀態時，叢集必須再次複製資料並刪除過度複製的資料。</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoop供應商鎖定</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoop 經銷商擁有自己的 Hadoop 發行版和版本控制，將客戶鎖定在這些發行版上。然而，許多客戶需要記憶體分析支持，而這種支援不會將客戶綁定到特定的 Hadoop 發行版。他們需要自由地改變分佈，同時仍保留他們的分析能力。</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">缺乏對多種語言的支持</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">客戶通常需要除了 MapReduce Java 程式之外的多種語言支援來執行他們的作業。  SQL 和腳本等選項為獲取答案提供了更大的靈活性，為組織和檢索資料提供了更多的選項，以及將資料移至分析框架的更快的方式。</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">使用難度</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">一段時間以來，人們一直抱怨 Hadoop 難以使用。儘管 Hadoop 的每個新版本都變得更簡單、更強大，但這種批評仍然存在。  Hadoop 要求您了解 Java 和 MapReduce 程式模式，這對資料庫管理員和具有傳統腳本技能的人員來說是一個挑戰。</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">複雜的框架和工具</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">企業AI團隊面臨多重挑戰。即使擁有專業的數據科學知識，不同部署生態系統和應用程式的工具和框架也可能無法簡單地從一個轉換到另一個。數據科學平台應該與基於 Spark 構建的相應大數據平台無縫集成，易於數據移動、可重複使用的模型、開箱即用的代碼以及支持原型設計、驗證、版本控制、共享、重用和快速將模型部署到生產的最佳實踐的工具。</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">為什麼選擇NetApp？</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp可以透過以下方式改善您的 Spark 體驗：</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">NetApp NFS 直接存取（如下圖所示）允許客戶在其現有或新的 NFSv3 或 NFSv4 資料上執行大數據分析作業，而無需移動或複製資料。它可以防止資料的多次複製，並且無需將資料與來源同步。</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">更有效率的儲存和更少的伺服器複製。例如， NetApp E 系列 Hadoop 解決方案需要兩個而不是三個資料副本，而FAS Hadoop 解決方案需要一個資料來源，但不需要資料複製或副本。  NetApp儲存解決方案還能減少伺服器之間的流量。</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">驅動器和節點故障期間更好的 Hadoop 作業和叢集行為。</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">更好的數據提取性能。</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">替代的 Apache Spark 配置。</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">例如，在金融和醫療保健領域，資料從一個地方移動到另一個地方必須滿足法律義務，這不是一件容易的事。在這種情況下， NetApp NFS 直接存取會從原始位置分析財務和醫療保健資料。另一個主要優勢是，使用NetApp NFS 直接存取可以透過使用本機 Hadoop 指令簡化 Hadoop 資料的保護，並利用NetApp豐富的資料管理產品組合來實現資料保護工作流程。</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">NetApp NFS 直接存取為 Hadoop/Spark 叢集提供了兩種部署選項：</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">預設情況下，Hadoop 或 Spark 叢集使用 Hadoop 分散式檔案系統 (HDFS) 進行資料儲存和預設檔案系統。  NetApp NFS 直接存取可以用 NFS 儲存取代預設的 HDFS 作為預設檔案系統，從而實現對 NFS 資料的直接分析。</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">在另一個部署選項中， NetApp NFS 直接存取支援在單一 Hadoop 或 Spark 叢集中將 NFS 與 HDFS 一起配置為附加儲存。在這種情況下，客戶可以透過 NFS 匯出共享數據，並從同一集群存取數據以及 HDFS 數據。</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">使用NetApp NFS 直接存取的主要優勢包括：</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">從目前位置分析數據，從而避免將分析數據移動到 Hadoop 基礎架構（如 HDFS）這一耗時耗能的任務。</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">將副本數量從三個減少到一個。</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">使用戶能夠分離計算和存儲以獨立擴展它們。</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">利用ONTAP豐富的資料管理功能提供企業資料保護。</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">通過 Hortonworks 資料平台認證。</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">支援混合資料分析部署。</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">利用動態多執行緒功能減少備份時間。</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657： NetApp混合雲資料解決方案 - 基於客戶使用案例的 Spark 和 Hadoop</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">看<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block>用於備份 Hadoop 資料、從雲端到本地的備份和災難復原、對現有 Hadoop 資料進行 DevTest、資料保護和多雲連接以及加速分析工作負載。</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">以下部分介紹了對 Spark 客戶來說重要的儲存功能。</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">儲存分層</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">透過 Hadoop 儲存分層，您可以根據儲存策略儲存具有不同儲存類型的檔案。儲存類型包括<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block>，<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> ，<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> ，<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> ，<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> ， 和<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block>。</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">我們在NetApp AFF儲存控制器和具有不同儲存策略的 SSD 和 SAS 磁碟機的 E 系列儲存控制器上對 Hadoop 儲存分層進行了驗證。具有AFF-A800 的 Spark 叢集有四個運算工作節點，而有 E 系列的叢集有八個。這主要是為了比較固態硬碟 (SSD) 與硬碟 (HDD) 的效能。</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">下圖顯示了NetApp針對 Hadoop SSD 的解決方案的效能。</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">是時候對 1TB 資料進行排序了。</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 NetApp E系列Hadoop解決方案</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">基線 NL-SAS 配置使用八個運算節點和 96 個 NL-SAS 磁碟機。此配置在 4 分 38 秒內產生了 1TB 的資料。看<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block>有關叢集和儲存配置的詳細資訊。</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">使用 TeraGen，SSD 配置產生 1TB 資料的速度比 NL-SAS 配置快 15.66 倍。此外，SSD 配置使用了一半數量的計算節點和一半數量的磁碟機（總共 24 個 SSd 磁碟機）。根據作業完成時間，它幾乎比 NL-SAS 配置快兩倍。</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">使用 TeraSort，SSD 配置對 1TB 資料的排序速度比 NL-SAS 配置快 1138.36 倍。此外，SSD 配置使用了一半數量的計算節點和一半數量的磁碟機（總共 24 個 SSd 磁碟機）。因此，每個驅動器的速度大約比 NL-SAS 配置快三倍。</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">重點是從旋轉磁碟過渡到全快閃記憶體可以提高效能。計算節點的數量不是瓶頸。借助 NetApp 的全快閃存儲，運行時性能可以很好地擴展。</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">使用 NFS，資料在功能上相當於被集中在一起，這可以根據您的工作負載減少計算節點的數量。  Apache Spark 叢集使用者在更改運算節點數量時不必手動重新平衡資料。</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">效能擴展 - 橫向擴展</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">當您需要從AFF解決方案中的 Hadoop 叢集取得更多運算能力時，您可以新增具有適當數量儲存控制器的資料節點。  NetApp建議從每個儲存控制器陣列 4 個資料節點開始，然後根據工作負載特性將每個儲存控制器的資料節點數量增加到 8 個。</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF和FAS非常適合就地分析。根據運算需求，您可以新增節點管理器，且無中斷操作可讓您按需新增儲存控制器而無需停機。我們提供AFF和FAS的豐富功能，例如 NVME 媒體支援、保證效率、資料減少、QOS、預測分析、雲端分層、複製、雲端部署和安全性。為了幫助客戶滿足他們的需求， NetApp提供了檔案系統分析、配額和機上負載平衡等功能，無需額外的授權費用。 NetApp在並發作業數量、更低的延遲、更簡單的操作以及更高的每秒千兆位元組吞吐量方面比我們的競爭對手錶現更好。此外， NetApp Cloud Volumes ONTAP可在三大雲端供應商上運作。</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">效能擴展 - 擴大規模</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">當您需要額外的儲存容量時，擴充功能可讓您將磁碟機新增至AFF、 FAS和 E 系列系統。使用Cloud Volumes ONTAP，將儲存擴展到 PB 層級需要結合兩個因素：將不常用的資料從區塊儲存分層到物件存儲，以及堆疊Cloud Volumes ONTAP授權而無需額外的運算。</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">多種協定</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">NetApp系統支援大多數 Hadoop 部署協議，包括 SAS、iSCSI、FCP、InfiniBand 和 NFS。</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">營運和支援的解決方案</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">認證</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">夥伴</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">本文檔中所述的 Hadoop 解決方案由NetApp支援。這些解決方案也經過了主要 Hadoop 經銷商的認證。欲了解更多信息，請參閱<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block>站點和 Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block>和<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block>站點。</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">本節介紹 Apache Spark 的性質和元件以及它們如何為此解決方案做出貢獻。</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">解決方案技術</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark 是一種流行的程式框架，用於編寫可直接與 Hadoop 分散式檔案系統 (HDFS) 協同工作的 Hadoop 應用程式。  Spark 已準備好投入生產，支援串流資料處理，並且比 MapReduce 更快。 Spark 具有可配置的記憶體資料緩存，可實現高效迭代，並且 Spark shell 具有互動性，可用於學習和探索資料。使用 Spark，您可以用 Python、Scala 或 Java 建立應用程式。  Spark 應用程式由一個或多個具有一個或多個任務的作業組成。</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">每個 Spark 應用程式都有一個 Spark 驅動程式。在 YARN-Client 模式下，驅動程式在客戶端本地運行。在 YARN-Cluster 模式下，驅動程式在應用程式主機上的叢集中運作。在叢集模式下，即使客戶端斷開連接，應用程式仍繼續運作。</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">此圖顯示輸入/輸出對話框或表示書面內容</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">有三個集群管理器：</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*獨立。 *此管理器是 Spark 的一部分，可以輕鬆設定叢集。</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">Apache Mesos。這是一個通用叢集管理器，也運行 MapReduce 和其他應用程式。</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">Hadoop YARN。這是 Hadoop 3 中的資源管理器。</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">彈性分散式資料集（RDD）是 Spark 的主要元件。  RDD 從叢集記憶體中儲存的資料重新建立遺失和缺少的數據，並儲存來自檔案或以程式設計方式建立的初始資料。  RDD 是從檔案、記憶體中的資料或另一個 RDD 建立的。 Spark 程式設計執行兩種操作：轉換和操作。轉換基於現有 RDD 建立新的 RDD。操作從 RDD 傳回一個值。</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">轉換和操作也適用於 Spark 資料集和 DataFrames。資料集是分散式資料集合，它兼具 RDD 的優勢（強型別、使用 lambda 函數）和 Spark SQL 優化執行引擎的優勢。可以從 JVM 物件建立資料集，然後使用功能轉換（map、flatMap、filter 等）進行操作。 DataFrame 是按命名列組織起來的資料集。它在概念上等同於關聯式資料庫中的表或 R/Python 中的資料框。  DataFrames 可以從多種來源構建，例如結構化資料檔案、Hive/HBase 中的表、本地或雲端的外部資料庫或現有的 RDD。</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Spark 應用程式包括一個或多個 Spark 作業。作業在執行器中運行任務，執行器在 YARN 容器中運行。每個執行器都在單一容器中運行，並且執行器在應用程式的整個生命週期中都存在。應用程式啟動後，執行器就固定了，YARN 不會調整已指派的容器的大小。執行器可以對記憶體資料同時運行任務。</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">本節介紹誰可能對該解決方案的內容感興趣。</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">目標受眾</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">分析和數據科學領域涉及 IT 和商業的多個學科：</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">資料科學家需要靈活地使用他們選擇的工具和函式庫。</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">資料工程師需要知道資料如何流動以及位於何處。</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">DevOps 工程師需要工具將新的 AI 和 ML 應用程式整合到他們的 CI 和 CD 管道中。</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">雲端管理員和架構師必須能夠設定和管理混合雲資源。</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">商業用戶希望能夠存取分析、AI、ML 和 DL 應用程式。</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">在本技術報告中，我們描述了NetApp AFF、E 系列、 StorageGRID、NFS 直接存取、Apache Spark、Horovod 和 Keras 如何幫助這些角色為企業帶來價值。</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">我們使用 TeraGen 基準測試工具中的 TeraSort 和 TeraValidate 腳本來測量 E5760、E5724 和AFF-A800 配置的 Spark 效能驗證。此外，還測試了三個主要用例：Spark NLP 管道和 TensorFlow 分散式訓練、Horovod 分散式訓練以及使用 Keras 進行多工深度學習，透過 DeepFM 進行 CTR 預測。</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">測試結果</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">我們使用 TeraGen 基準測試工具中的 TeraSort 和 TeraValidate 腳本來測量 E5760、E5724 和AFF-A800 配置的 Spark 效能驗證。此外，還測試了三個主要用例：Spark NLP 管道和 TensorFlow 分散式訓練、Horovod 分散式訓練以及使用 Keras 進行 DeepFM CTR 預測的多工深度學習。</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">對於 E 系列和StorageGRID驗證，我們使用了 Hadoop 複製因子 2。對於AFF驗證，我們只使用一個資料來源。</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">下表列出了 Spark 效能驗證的硬體配置。</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">類型</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoop 工作節點</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">驅動器類型</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">每個節點的驅動器</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">儲存控制器</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">單一高可用性 (HA) 對</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">單一 HA 對</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">固態硬碟</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">下表列出了軟體要求。</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">軟體</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">版本</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">紅帽企業版</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDK 運作環境</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64 位元伺服器虛擬機</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">Git</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">火花</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">喀拉拉</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">霍羅沃德</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">金融情緒分析</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910：利用NetApp AI 進行客戶溝通情緒分析</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">NetApp DataOps 工具包</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">道框架</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">我們發表了<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block>，其中使用<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>、 AFF儲存和NVIDIA DGX 系統。此管道利用 DataOps Toolkit 執行批量音訊訊號處理、自動語音辨識 (ASR)、遷移學習和情緒分析，<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> ，以及<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>。將情緒分析用例擴展到金融服務業，我們建立了 SparkNLP 工作流程，為各種 NLP 任務（例如命名實體識別）加載了三個 BERT 模型，並獲得了納斯達克十大公司季度收益電話會議的句子級情緒。</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">以下腳本<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block>使用 FinBERT 模型處理 HDFS 中的轉錄本，並產生正面、中性和負面情緒計數，如下表所示：</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">下表列出了 2016 年至 2020 年納斯達克十大公司的收益電話會議句子級情緒分析。</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">情緒計數和百分比</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">全部 10 家公司</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">蘋果</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">亞馬遜</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">思科</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">Google</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">國際貿易中心</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">微軟</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">正計數</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">中立計數</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">負數</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">未分類的計數</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">（總數）</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">從百分比來看，執行長和財務長所說的大多數句子都是事實，因此帶有中立的情緒。在收益電話會議期間，分析師提出的問題可能會傳達正面或負面的情緒。值得進一步定量研究負面或正面情緒如何影響交易當天或隔天的股票價格。</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">下表列出了納斯達克十大公司的句子級情感分析，以百分比表示。</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">情緒百分比</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">積極的</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">中性的</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">消極的</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">未分類</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">在工作流程運行時方面，我們看到了顯著的 4.78 倍改進<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block>模式到 HDFS 中的分散式環境，並透過利用 NFS 進一步提高 0.14%。</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">如下圖所示，資料和模型並行提高了資料處理和分散式 TensorFlow 模型推理的速度。 NFS 中的資料位置產生了稍微更好的運行時間，因為工作流程瓶頸是預訓練模型的下載。如果我們增加成績單資料集的大小，NFS 的優勢就更加明顯。</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Spark NLP 情緒分析端對端工作流程執行時。</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Horovod 表現的分散式訓練</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">針對每個主要用例的 Python 腳本</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">以下命令使用單一<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block>具有 160 個執行器的節點，每個執行器都有一個核心。執行器記憶體限制為 5GB，以避免記憶體不足錯誤。請參閱<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block>有關數據處理、模型訓練和模型準確率計算的更多詳細信息，請參閱<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>。</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">經過 10 個訓練週期後，最終的運行時間如下：</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">處理輸入資料、訓練 DNN 模型、計算準確度以及產生 TensorFlow 檢查點和預測結果的 CSV 檔案花費了超過 43 分鐘。我們將訓練週期數限制為 10，在實踐中通常設定為 100，以確保令人滿意的模型準確率。訓練時間通常與訓練次數呈線性關係。</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">接下來，我們使用叢集中可用的四個工作節點，並在<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block>HDFS 中的資料模式：</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">最終的運轉時間改進如下：</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">借助 Horovod 模型和 Spark 中的資料並行性，我們看到運行速度提高了 5.29 倍<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block>相對<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block>具有十個訓練階段的模式。下圖中圖例顯示了這一點<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block>和<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block>。如果可用的話，可以使用 GPU 進一步加速底層 TensorFlow DNN 模型訓練。我們計劃進行此項測試並在未來的技術報告中發布結果。</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">我們的下一個測試比較了 NFS 和 HDFS 中的輸入資料的運行時間。 AFF A800上的 NFS 磁碟區已安裝在<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block>分佈於 Spark 叢集的五個節點（一個主節點，四個工作節點）上。我們運行了與先前的測試類似的命令，<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block>參數現在指向 NFS 掛載：</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">使用 NFS 的運行結果如下：</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">速度又提高了 1.43 倍，如下圖所示。因此，透過將NetApp全快閃儲存連接到其集群，客戶可以享受 Horovod Spark 工作流程的快速資料傳輸和分發優勢，與在單一節點上運行相比，可實現 7.55 倍的加速。</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark 工作流程運行時。</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">CTR預測表現的深度學習模型</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">對於旨在最大化點擊率的推薦系統，必須學習使用者行為背後複雜的特徵交互，這些特徵交互可以透過數學方式從低階到高階計算。對於良好的深度學習模型來說，低階和高階特徵交叉應該同等重要，而不應偏向其中任何一方。深度分解機（DeepFM）是一種基於分解機的神經網絡，它將用於推薦的分解機和用於特徵學習的深度學習結合在新的神經網路架構中。</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">廣度與深度模型</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">雖然傳統的分解機將成對的特徵交叉建模為特徵之間潛在向量的內積，並且理論上可以捕獲高階信息，但在實踐中，機器學習從業者通常只使用二階特徵交叉，因為計算和存儲複雜度很高。深度神經網路變體，例如Google的<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block>另一方面，透過結合線性寬模型和深度模型，在混合網路結構中學習複雜的特徵交互作用。</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">這個 Wide &amp; Deep 模型有兩個輸入，一個用於底層的廣度模型，另一個用於深度模型，後者仍然需要專家的特徵工程，因此該技術不太適用於其他領域。與廣度和深度模型不同，DeepFM 可以使用原始特徵進行有效訓練，而無需任何特徵工程，因為它的廣度部分和深度部分共享相同的輸入和嵌入向量。</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">每個主要用例的 Python 腳本。</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">我們首先處理了 Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> （11GB）檔案轉換為名為<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>儲存在 NFS 掛載中<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block>使用<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>來自部分<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block>在此腳本中，函數<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block>執行幾個字串方法來刪除製表符並插入<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block>作為分隔符號和<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block>作為換行符。請注意，您只需處理原始<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block>一次，這樣程式碼區塊就顯示為註解。</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">為了對不同的 DL 模型進行以下測試，我們使用<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>作為輸入檔。在後續的測試運行中，輸入的 CSV 檔案被讀入 Spark DataFrame，其模式包含以下字段<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block>，整數密集特徵<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block>和稀疏特徵<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block>。下列<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block>指令接受輸入 CSV，以 20% 的比例訓練 DeepFM 模型進行交叉驗證，並在十個訓練週期後選出最佳模型來計算測試集上的預測準確率：</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">請注意，由於數據文件<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>超過 11GB，則必須設定足夠的<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block>大於資料集大小以避免錯誤。</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">阿帕契箭</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">在上述<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block>配置我們還啟用了<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>，將 Spark DataFrame 轉換為 Pandas DataFrame，<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block>方法。</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">隨機分割後，訓練資料集中有超過 3,600 萬行，測試集中有 900 萬個樣本：</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">由於本技術報告專注於不使用任何 GPU 的 CPU 測試，因此必須使用適當的編譯器標誌來建立 TensorFlow。此步驟避免呼叫任何 GPU 加速函式庫，並充分利用 TensorFlow 的高階向量擴充 (AVX) 和 AVX2 指令。這些特徵是為線性代數計算而設計的，例如向量加法、前饋中的矩陣乘法或反向傳播 DNN 訓練。 AVX2 提供的融合乘加 (FMA) 指令使用 256 位元浮點 (FP) 暫存器，非常適合整數程式碼和資料類型，可實現高達 2 倍的加速。對於 FP 程式碼和資料類型，AVX2 比 AVX 實現了 8% 的加速。</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">巴澤爾</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">若要從原始碼建置 TensorFlow， NetApp建議使用<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>。對於我們的環境，我們在 shell 提示字元下執行以下命令來安裝<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block>，<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> ，以及 Bazel。</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">您必須啟用 GCC 5 或更新版本才能在建置過程中使用 C++17 功能，該功能由 RHEL 透過軟體集合庫 (SCL) 提供。以下命令安裝<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block>以及 RHEL 7.9 叢集上的 GCC 11.2.1：</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">文章</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">請注意，最後兩個命令啟用<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block>，使用<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block>（GCC 11.2.1）。此外，請確保您的<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block>版本高於 1.8.3（隨 RHEL 7.9 提供）。參考這個<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block>用於更新<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block>至 2.24.1。</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">針對每個主要用例的 Python 腳本，</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">我們假設您已經克隆了最新的 TensorFlow 主倉庫。然後創建一個<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block>目錄與<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block>檔案使用 AVX、AVX2 和 FMA 從原始程式碼建置 TensorFlow。運行<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block>檔案並指定正確的 Python 二進位位置。<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block>由於我們沒有使用 GPU，因此在我們的測試中被停用。一個<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block>文件根據您的設定產生。此外，我們編輯了文件並設置<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block>啟用 HDFS 支援。參考<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block>在本節中<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block>以獲得完整的設定和標誌清單。</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">使用正確的標誌建立 TensorFlow 後，執行以下腳本來處理 Criteo Display Ads 資料集，訓練 DeepFM 模型，並根據預測分數計算接收者操作特徵曲線下面積 (ROC AUC)。</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">經過十次訓練後，我們獲得了測試資料集上的 AUC 分數：</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">以與先前的用例類似的方式，我們將 Spark 工作流程運行時與位於不同位置的資料進行了比較。下圖顯示了 Spark 工作流程運行時深度學習 CTR 預測的比較。</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">比較 Spark 工作流程運行時的深度學習 CTR 預測。</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">本頁描述了可以使用該解決方案的不同領域。</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">用例摘要</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">串流資料</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark 可以處理串流數據，用於串流提取、轉換和載入 (ETL) 過程；數據豐富；觸發事件檢測；以及複雜的會話分析：</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">流式 ETL。 *資料在被推送到資料儲存之前會不斷清理和匯總。 Netflix 使用 Kafka 和 Spark 串流建立即時線上電影推薦和資料監控解決方案，每天可以處理來自不同資料來源的數十億個事件。然而，用於批次處理的傳統 ETL 的處理方式有所不同。首先讀取該數據，然後將其轉換為資料庫格式，然後寫入資料庫。</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*數據豐富。 * Spark Streaming 使用靜態資料豐富即時數據，以實現更即時的資料分析。例如，線上廣告主可以根據客戶行為資訊投放個人化、有針對性的廣告。</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*觸發事件檢測。 * Spark 串流可讓您偵測並快速回應可能表示有嚴重問題的異常行為。例如，金融機構使用觸發器來偵測和阻止詐欺交易，醫院使用觸發器來檢測患者生命徵像中檢測到的危險健康變化。</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*複雜的會話分析。 * Spark 流會收集使用者登入網站或應用程式後的活動等事件，然後進行分組和分析。例如，Netflix 使用此功能提供即時電影推薦。</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912： NetApp Confluent Kafka 分層儲存最佳實務指南</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">有關串流資料配置、Confluent Kafka 驗證和效能測試的更多內容，請參閱<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block>。</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">機器學習</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Spark 整合框架可協助您使用機器學習程式庫 (MLlib) 對資料集執行重複查詢。  MLlib 用於聚類、分類和降維等領域，用於一些常見的大數據功能，例如預測智慧、用於行銷目的的客戶細分和情感分析。 MLlib 用於網路安全，對封包進行即時檢查，以發現惡意活動的跡象。它可以幫助安全提供者了解新的威脅並領先駭客，同時即時保護他們的客戶。</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">深度學習</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow 是業界流行的深度學習框架。 TensorFlow支援在CPU或GPU叢集上進行分散式訓練。這種分散式訓練允許使用者在具有大量深層的資料上運行它。</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">直到最近，如果我們想將 TensorFlow 與 Apache Spark 一起使用，我們需要在 PySpark 中為 TensorFlow 執行所有必要的 ETL，然後將資料寫入中間儲存。然後，該資料將載入到 TensorFlow 叢集上，用於實際的訓練流程。此工作流程要求使用者維護兩個不同的集群，一個用於 ETL，一個用於 TensorFlow 的分散式訓練。運作和維護多個叢集通常很繁瑣且耗時。</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">早期 Spark 版本中的 DataFrames 和 RDD 不太適合深度學習，因為隨機存取受到限制。在氫化計畫的 Spark 3.0 中，加入了對深度學習框架的原生支援。這種方法允許在 Spark 叢集上進行非基於 MapReduce 的調度。</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">互動式分析</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">Apache Spark 的速度夠快，可以使用 Spark 以外的開發語言（包括 SQL、R 和 Python）執行探索性查詢而無需採樣。 Spark 使用視覺化工具來處理複雜資料並以互動方式進行視覺化。具有結構化流的 Spark 對網路分析中的即時資料執行互動式查詢，使您能夠對網路訪客的當前會話執行互動式查詢。</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">推薦系統</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">多年來，隨著企業和消費者對線上購物、線上娛樂和許多其他行業的巨大變化做出了反應，推薦系統為我們的生活帶來了巨大的變化。事實上，這些系統是人工智慧在生產中最明顯的成功案例之一。在許多實際用例中，推薦系統與對話式 AI 或與 NLP 後端互動的聊天機器人結合，以獲取相關資訊並產生有用的推論。</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">如今，許多零售商正在採用更新的商業模式，例如線上購買、店內取貨、路邊取貨、自助結帳、掃描即走等等。這些模式在新冠疫情期間特別突出，因為它們讓消費者的購物更加安全、更加便利。人工智慧對於這些日益增長的數位趨勢至關重要，這些趨勢受到消費者行為的影響，反之亦然。為了滿足消費者日益增長的需求、增強客戶體驗、提高營運效率和增加收入， NetApp可協助其企業客戶和企業使用機器學習和深度學習演算法來設計更快、更準確的推薦系統。</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">有幾種流行的技術用於提供推薦，包括協同過濾、基於內容的系統、深度學習推薦模型 (DLRM) 和混合技術。客戶之前利用 PySpark 實現協同過濾來創建推薦系統。  Spark MLlib 實作了用於協同過濾的交替最小二乘法 (ALS)，這是 DLRM 興起之前企業中非常流行的演算法。</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">自然語言處理</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">對話式人工智慧是透過自然語言處理 (NLP) 實現的，它是幫助電腦與人類溝通的人工智慧的一個分支。 NLP 在每個垂直行業和許多用例中都很普遍，從智慧助理和聊天機器人到Google搜尋和預測文字。根據<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block>預測到2022年，70%的人將每天與對話式人工智慧平台互動。為了實現人與機器之間的高品質對話，反應必須快速、聰明且聽起來自然。</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">客戶需要大量資料來處理和訓練他們的 NLP 和自動語音辨識 (ASR) 模型。他們還需要在邊緣、核心和雲端移動數據，並且需要在幾毫秒內進行推理的能力，以與人類建立自然的交流。  NetApp AI 和 Apache Spark 是運算、儲存、資料處理、模型訓練、微調和部署的理想組合。</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">情緒分析是 NLP 中的一個研究領域，它從文本中提取正面、負面或中性情緒。情緒分析有多種用例，從確定支援中心員工與呼叫者對話的表現到提供適當的自動聊天機器人回應。它也被用來根據公司代表和季度收益電話會議上的聽眾之間的互動來預測公司的股價。此外，情緒分析可用於確定客戶對品牌提供的產品、服務或支援的看法。</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Spark NLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">約翰·斯諾實驗室</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">財經新聞情緒</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">我們使用了<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block>來自的圖書館<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block>載入預訓練管道和 Transformer (BERT) 模型的雙向編碼器表示，包括<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block>和<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block>，大規模執行標記化、命名實體識別、模型訓練、擬合和情緒分析。 Spark NLP 是唯一正在生產的開源 NLP 庫，它提供最先進的轉換器，例如 BERT、ALBERT、ELECTRA、XLNet、DistilBERT、RoBERTa、DeBERTa、XLM-RoBERTa、Longformer、ELMO、Universal Sentence Encoder、Google T5、MarianMT 和 GPT2。該程式庫不僅適用於 Python 和 R，還可以透過原生擴充 Apache Spark 在 JVM 生態系統（Java、Scala 和 Kotlin）中大規模運行。</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">抽象的</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">本文檔介紹如何從大數據分析和高效能運算 (HPC) 系統中移動數據，以便將其用於人工智慧 (AI) 工作流程。 AI 通常透過 NFS 導出來處理 NFS 資料。但是，您可能會將 AI 資料放在大數據分析和高效能運算 (HPC) 平台中。這可以是 Hadoop 分散式檔案系統 (HDFS)、二進位大物件 (Blob)、S3 儲存或 IBM 的通用平行檔案系統 (GPFS)。在本文檔中，我們介紹如何使用 Hadoop 原生命令、 NetApp就地分析模組 (NIPAM) 和NetApp XCP 將資料從大數據分析平台和 GPFS 移至 NFS。本文檔也討論了將資料從大數據和 HPC 轉移到 AI 所帶來的商業利益。</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">在哪裡可以找到更多信息</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">要了解有關本文檔中描述的信息的更多信息，請查看以下文檔和/或網站：</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">NetApp FlexGroup卷最佳實務與實作指南</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp產品文檔</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">本節介紹此解決方案的業務優勢。</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">商業利益</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">將數據從大數據分析轉移到人工智慧有以下好處：</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">能夠將資料從不同的 Hadoop 檔案系統和 GPFS 提取到統一的 NFS 儲存系統</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">一種與 Hadoop 整合的自動化資料傳輸方式</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">降低從 Hadoop 檔案系統移動資料的庫開發成本</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">透過使用 NIPAM，透過從單一資料來源聚合多個網路介面的吞吐量實現最高效能</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">預定和按需傳輸資料的方法</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">使用ONTAP資料管理軟體實現統一 NFS 資料的儲存效率和企業管理能力</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">使用 Hadoop 方法進行資料傳輸，實現零成本</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">本頁討論了客戶在嘗試存取大數據分析資料以進行 AI 操作時可能面臨的挑戰。</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">客戶在嘗試存取大數據分析資料以進行 AI 操作時可能會面臨以下挑戰：</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">客戶資料位於資料湖儲存庫。資料湖可以包含不同類型的數據，例如結構化、非結構化、半結構化、日誌和機器對機器資料。所有這些資料類型都必須在人工智慧系統中處理。</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI 與 Hadoop 檔案系統不相容。典型的 AI 架構無法直接存取 HDFS 和 HCFS 數據，必須將這些數據移至 AI 可理解的檔案系統 (NFS)。</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">將資料湖資料遷移至 AI 通常需要專門的流程。資料湖中的資料量可能非常大。客戶必須擁有一種高效、高吞吐量且經濟實惠的方式將資料移至 AI 系統。</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">正在同步資料。如果客戶希望大數據平台和AI之間同步數據，有時候經過AI處理的數據可以和大數據一起進行分析處理。</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">在大數據叢集中，資料儲存在 HDFS 或 HCFS 中，例如 MapR-FS、Windows Azure Storage Blob、S3 或 Google 檔案系統。我們使用 HDFS、MapR-FS 和 S3 作為來源進行測試，在 NIPAM 的幫助下，使用來源中的 hadoop distcp 命令將資料複製到NetApp ONTAP NFS 匯出。</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">數據移動器解決方案</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">在大數據叢集中，資料儲存在 HDFS 或 HCFS 中，例如 MapR-FS、Windows Azure Storage Blob、S3 或 Google 檔案系統。我們以 HDFS、MapR-FS 和 S3 作為來源，在 NIPAM 的幫助下將資料複製到NetApp ONTAP NFS 匯出，使用<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>來自源的命令。</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">下圖說明了從使用 HDFS 儲存運行的 Spark 叢集到NetApp ONTAP NFS 磁碟區的典型資料移動，以便NVIDIA可以處理 AI 操作。</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">這<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>命令使用 MapReduce 程式複製資料。  NIPAM 與 MapReduce 協同工作，在複製資料時充當 Hadoop 叢集的驅動程式。 NIPAM 可以將負載分佈到單一匯出的多個網路介面上。當您將資料從 HDFS 或 HCFS 複製到 NFS 時，此程序會透過將資料分佈在多個網路介面上來最大化網路吞吐量。</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">MapR 不支援或認證 NIPAM。</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">人工智慧資料移動器解決方案是基於客戶處理來自人工智慧操作的 Hadoop 資料的需求。 NetApp使用 NIPAM 將資料從 HDFS 移至 NFS。在一個用例中，客戶需要將資料移至本機的 NFS，而另一個客戶需要將資料從 Windows Azure Storage Blob 移至Google Cloud NetApp Volumes ，以便處理來自雲端中的 GPU 雲端實例的資料。</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">人工智慧資料移動解決方案</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">下圖說明了數據移動器解決方案的詳細資訊。</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">建置資料移動器解決方案需要以下步驟：</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN 提供 HDFS，NAS 透過 NIPAM 將 NFS 磁碟區提供給生產資料湖叢集。</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">客戶的資料在HDFS和NFS。  NFS 數據可以是來自其他應用程式的生產數據，用於大數據分析和 AI 操作。</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexClone技術建立生產 NFS 磁碟區的克隆並將其配置到內部的 AI 叢集。</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">使用 NIPAM 將 HDFS SAN LUN 中的資料複製到 NFS 磁碟區中，並且<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>命令。 NIPAM 使用多個網路介面的頻寬來傳輸資料。此過程減少了資料複製時間，從而可以傳輸更多資料。</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">兩個 NFS 磁碟區均已配置給 AI 叢集以進行 AI 操作。</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">為了使用雲端中的 GPU 處理本地 NFS 數據，NFS 磁碟區透過NetApp SnapMirror技術鏡像到NetApp私有儲存 (NPS)，並安裝到 GPU 的雲端服務供應商。</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">客戶希望使用雲端服務供應商的 GPU 來處理 EC2/EMR、HDInsight 或 DataProc 服務中的資料。  Hadoop 資料移動器使用 NIPAM 將資料從 Hadoop 服務移至Google Cloud NetApp Volumes，並且<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>命令。</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">Google Cloud NetApp Volumes資料透過 NFS 協定配置給 AI。透過 AI 處理的資料除了可以透過 NIPAM、 SnapMirror和 NPS 傳送到NVIDIA叢集之外，還可以傳送到本地位置進行大數據分析。</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">在這種情況下，客戶在遠端位置的 NAS 系統中擁有大量文件數數據，這些數據是內部NetApp儲存控制器上進行 AI 處理所必需的。在這種情況下，最好使用XCP遷移工具來以更快的速度遷移資料。</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">混合用例客戶可以使用BlueXP Copy and Sync 將本機資料從 NFS、CIFS 和 S3 資料遷移到雲端，反之亦然，以便使用NVIDIA叢集等中的 GPU 進行 AI 處理。  BlueXP Copy and Sync 和 XCP Migration Tool 皆用於將 NFS 資料移轉到NetApp ONTAP NFS。</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">在本次驗證中，我們使用了四台伺服器作為網路共享磁碟（NSD）伺服器，為GPFS提供實體磁碟。 GPFS 建立於 NSD 磁碟之上，以將其匯出為 NFS 匯出，以便 NFS 用戶端可以存取它們，如下圖所示。我們使用 XCP 將資料從 GPFS 匯出的 NFS 複製到NetApp NFS 磁碟區。</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS 到NetApp ONTAP NFS</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPFS 基礎知識</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS 中使用下列節點類型：</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*管理節點。 *指定一個可選字段，其中包含管理命令用於在節點之間進行通訊的節點名稱。例如，管理節點<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block>可以將網路檢查傳遞給叢集中的所有其他節點。</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*仲裁節點。 *確定節點是否包含在派生仲裁的節點池中。您至少需要一個節點作為仲裁節點。</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*管理節點*指示節點是否屬於節點池的一部分，可以從中選擇檔案系統管理員和令牌管理器。將多個節點定義為管理節點是一個好主意。您指定為管理器的節點數取決於工作負載和您擁有的 GPFS 伺服器許可證數量。如果您正在執行大型平行作業，則可能需要比支援 Web 應用程式的四節點叢集更多的管理器節點。</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD 伺服器。 *準備每個實體磁碟以供 GPFS 使用的伺服器。</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*協定節點。 *透過任何安全外殼 (SSH) 協定直接與 NFS 共用 GPFS 資料的節點。此節點需要 GPFS 伺服器許可證。</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS、NFS 和 XCP 的操作列表</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">本節提供了建立 GPFS、將 GPFS 匯出為 NFS 匯出以及使用 XCP 傳輸資料的操作清單。</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">建立GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">若要建立 GPFS，請完成以下步驟：</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">在其中一台伺服器上下載並安裝 Linux 版本的頻譜規模資料存取。</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">在所有節點上安裝必備套件（例如 chef），並在所有節點上停用安全增強 Linux（SELinux）。</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">設定安裝節點並將管理節點和 GPFS 節點新增至叢集定義檔。</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">新增管理器節點、仲裁節點、NSD 伺服器和 GPFS 節點。</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">新增 GUI、管理和 GPFS 節點，並根據需要新增額外的 GUI 伺服器。</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">新增另一個 GPFS 節點並檢查所有節點的清單。</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">在叢集定義檔中的所有 GPFS 節點上指定叢集名稱、設定檔、遠端 shell 二進位檔案、遠端檔案複製二進位檔案和連接埠範圍。</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">查看 GPFS 配置設定並新增額外的管理節點。</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">停用資料收集並將資料包上傳至 IBM 支援中心。</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">啟用 NTP 並在安裝前預先檢查配置。</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">配置、建立和檢查 NSD 磁碟。</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">建立 GPFS。</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">掛載 GPFS。</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">驗證並提供 GPFS 所需的權限。</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">透過執行以下命令驗證 GPFS 讀寫<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>命令。</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">將 GPFS 匯出到 NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">若要將 GPFS 匯出至 NFS，請完成下列步驟：</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">透過以下方式將 GPFS 匯出為 NFS<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block>文件。</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">安裝所需的 NFS 伺服器套件。</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">啟動 NFS 服務。</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">列出 GPFS 中的檔案以驗證 NFS 用戶端。</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">配置 NFS 用戶端</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">若要設定 NFS 用戶端，請完成下列步驟：</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">透過<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block>文件。</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">啟動 NFS 用戶端服務。</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">在NFS客戶端上透過NFS協定掛載GPFS。</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">驗證 NFS 掛載資料夾中的 GPFS 檔案清單。</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">使用 XCP 將資料從 GPFS 匯出的 NFS 移至NetApp NFS。</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">驗證 NFS 用戶端上的 GPFS 檔案。</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">本節提供使用NetApp XCP 設定 GPFS 和將資料移至 NFS 所需的詳細步驟。</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS 轉 NFS-詳細步驟</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">配置 GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">在其中一台伺服器上下載並安裝適用於 Linux 的 Spectrum Scale Data Access。</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">在所有節點上安裝必備套件（包括 chef 和核心頭）。</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">在所有節點上停用 SELinux。</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">設定安裝節點。</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">將管理節點和 GPFS 節點新增至叢集定義檔。</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">新增管理器節點和GPFS節點。</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">新增仲裁節點和 GPFS 節點。</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">新增 NSD 伺服器和 GPFS 節點。</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">新增 GUI、管理和 GPFS 節點。</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">新增另一個 GUI 伺服器。</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">新增另一個 GPFS 節點。</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">驗證並列出所有節點。</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">在群集定義檔中指定群集名稱。</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">指定設定檔。</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">指定 GPFS 使用的遠端 shell 二進位；使用<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block>。</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">指定 GPFS 使用的遠端檔案複製二進位檔案；使用<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block>。</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">指定所有 GPFS 節點上要設定的連接埠範圍；使用<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block>。</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">查看 GPFS 配置設定。</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">新增管理節點。</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">啟用 NTP。</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">安裝前預先檢查配置。</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">配置 NSD 磁碟。</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">建立 NSD 磁碟。</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">檢查NSD磁碟狀態。</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">檢查並提供 GPFS 所需的權限。</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">透過執行以下命令檢查 GPFS 讀寫<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>命令。</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">若要將 GPFS 匯出至 NFS，請完成下列步驟：</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">列出 GPFS 中的檔案以驗證 NFS 用戶端。</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">配置 NFS 用戶端</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">在 NFS 用戶端中安裝程式包。</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">驗證 NFS 掛載資料夾中的 GPFS 檔案清單。</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">使用 XCP 將資料從 GPFS 匯出的 NFS 移至NetApp NFS。</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">對於此解決方案， NetApp驗證了從資料湖 (HDFS) 和 MapR 叢集資料到ONTAP NFS 的資料遷移。資料駐留在 MapR-FS 和 HDFS 中。  NetApp XCP 引進了一項新功能，可將資料從分散式檔案系統（如 HDFS 和 MapR-FS）直接移轉到ONTAP NFS。</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS 和 MapR-FS 到ONTAP NFS</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">對於此解決方案， NetApp驗證了從資料湖 (HDFS) 和 MapR 叢集資料到ONTAP NFS 的資料遷移。資料駐留在 MapR-FS 和 HDFS 中。  NetApp XCP 引進了一項新功能，可將資料從分散式檔案系統（如 HDFS 和 MapR-FS）直接移轉到ONTAP NFS。  XCP 使用非同步線程和 HDFS C API 呼叫來與 MapR-FS 和 HDFS 進行通訊並傳輸資料。</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">下圖顯示了從資料湖（HDFS）和MapR-FS到ONTAP NFS的資料遷移。有了這個新功能，您不必將來源匯出為 NFS 共用。</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">為什麼客戶要從 HDFS 和 MapR-FS 移轉到 NFS？</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">大多數 Hadoop 發行版（例如 Cloudera 和 Hortonworks）都使用 HDFS，而 MapR 發行版則使用自己的檔案系統（稱為 Mapr-FS）來儲存資料。  HDFS 和 MapR-FS 資料為資料科學家提供了寶貴的見解，可用於機器學習 (ML) 和深度學習 (DL)。 HDFS 和 MapR-FS 中的資料不共享，這意味著其他應用程式無法使用它。客戶正在尋找共享數據，特別是在銀行業，客戶的敏感數據被多個應用程式使用。 Hadoop最新版本（3.x以上版本）支援NFS資料來源，無需額外的第三方軟體即可存取。借助新的NetApp XCP 功能，可以將資料從 HDFS 和 MapR-FS 直接移動到NetApp NFS，以便提供對多個應用程式的訪問</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">在 Amazon Web Services (AWS) 中進行了測試，將資料從 MapR-FS 傳輸到 NFS，以使用 12 個 MAPR 節點和 4 個 NFS 伺服器進行初始效能測試。</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">數量</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">尺寸</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">虛擬 CPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">記憶</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">儲存</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">網路</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS 伺服器</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8個7500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR 節點</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4個7500 NVMe SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">根據初步測試，我們獲得了 20GBps 的吞吐量，並且每天能夠傳輸 2PB 的資料。</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863：TR-4863： NetApp XCP 最佳實務指南 - 資料移動器、檔案遷移和分析</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">有關不將 HDFS 匯出到 NFS 的 HDFS 資料移轉的更多信息，請參閱<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block>。</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">本文提供了使用NetApp XCP 和 NIPAM 將大數據分析資料和 HPC 資料遷移到 AI 的指南。我們也討論了將資料從大數據和 HPC 轉移到 AI 所帶來的商業利益。</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732：大數據分析與人工智慧</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam， NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">本文檔介紹如何將大數據分析資料和 HPC 資料遷移到 AI。 AI 透過 NFS 匯出處理 NFS 數據，而客戶通常將其 AI 數據放在大數據分析平台中，例如 HDFS、Blob 或 S3 儲存以及 HPC 平台（例如 GPFS）。本文提供了使用NetApp XCP 和 NIPAM 將大數據分析資料和 HPC 資料遷移到 AI 的指南。我們也討論了將資料從大數據和 HPC 轉移到 AI 所帶來的商業利益。</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">概念和組件</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">大數據分析存儲</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">大數據分析是HDFS的主要儲存提供者。客戶經常使用與 Hadoop 相容的檔案系統 (HCFS)，例如 Windows Azure Blob Storage、MapR 檔案系統 (MapR-FS) 和 S3 物件儲存。</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">通用平行檔案系統</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">IBM 的 GPFS 是一個企業檔案系統，它提供了 HDFS 的替代方案。  GPFS 為應用程式提供了靈活性，可以決定區塊大小和複製佈局，從而提供良好的效能和效率。</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">NetApp就地分析模組</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">NetApp就地分析模組 (NIPAM) 作為 Hadoop 叢集存取 NFS 資料的驅動程式。它有四個元件：連接池、NFS 輸入流、檔案句柄快取和 NFS 輸出流。有關更多信息，請參閱<block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> 。</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop分散式複製</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop分散式複製（DistCp）是用於大型叢集間和叢集內複製任務的分散式複製工具。該工具使用 MapReduce 進行資料分發、錯誤處理和報告。它擴展檔案和目錄列表並將它們輸入到映射任務中以從來源列表複製資料。下圖展示了 HDFS 和非 HDFS 中的 DistCp 操作。</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp 無需使用額外的驅動程式即可在兩個 HDFS 系統之間移動資料。 NetApp為非 HDFS 系統提供驅動程式。對於 NFS 目標，NIPAM 提供驅動程式來複製數據，Hadoop DistCp 在複製資料時使用該驅動程式與 NFS 目標進行通訊。</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">Google Cloud NetApp Volumes是一種具有極高效能的雲端原生檔案服務。該服務可協助客戶透過快速增加或減少資源以及使用NetApp功能來提高生產力並減少員工停機時間，從而加快產品上市時間。  Google Cloud NetApp Volumes是災難復原和備份到雲端的正確替代方案，因為它減少了整體資料中心的佔用空間並消耗了更少的原生公有雲儲存。</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP 是一款客戶端軟體，可實現快速可靠的任意到NetApp和NetApp到NetApp資料遷移。該工具旨在將大量非結構化 NAS 資料從任何 NAS 系統複製到NetApp儲存控制器。 XCP 遷移工具使用多核心、多通道 I/O 流引擎，可以並行處理許多請求，例如資料遷移、檔案或目錄清單以及空間報告。這是預設的NetApp資料遷移工具。您可以使用 XCP 將資料從 Hadoop 叢集和 HPC 複製到NetApp NFS 儲存。下圖顯示了使用 XCP 從 Hadoop 和 HPC 叢集到NetApp NFS 磁碟區的資料傳輸。</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">NetApp BlueXP複製與同步</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP Copy and Sync 是一種混合資料複製軟體即服務，可在本機儲存和雲端儲存之間無縫且安全地傳輸和同步 NFS、S3 和 CIFS 資料。該軟體用於資料遷移、存檔、協作、分析等。資料傳輸完成後， BlueXP Copy and Sync 會在來源和目標之間持續同步資料。接下來，它會傳輸增量。它還可以保護您自己的網路、雲端或本地的資料。該軟體基於現收現付模式，提供經濟高效的解決方案，並為您的資料傳輸提供監控和報告功能。</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">本節提供使用NetApp XCP 將 MapR-FS 資料移至ONTAP NFS 所需的詳細步驟。</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS 到ONTAP NFS</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">為每個 MapR 節點配置三個 LUN，並賦予所有 MapR 節點的 LUN 所有權。</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">在安裝過程中，為 MapR 叢集磁碟選擇新新增的用於 MapR-FS 的 LUN。</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">根據 MapR 6.1 文件安裝 MapR 叢集。</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">使用 MapReduce 指令檢查基本的 Hadoop 操作，例如<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block>。</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">將客戶資料保存在 MapR-FS 中。例如，我們使用 Teragen 在 MapR-FS 中產生了大約一兆位元組的樣本資料。</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">將 MapR-FS 配置為 NFS 導出。</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">在所有 MapR 節點上停用 nlockmgr 服務。</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">從所有 MapR 節點上的 MapR-FS 匯出特定資料夾<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block>文件。匯出子資料夾時，請勿匯出具有不同權限的父資料夾。</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">刷新MapR-FS NFS服務。</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">將虛擬 IP 範圍指派給 MapR 叢集中的特定伺服器或一組伺服器。然後，MapR 叢集為特定伺服器分配一個 IP，用於 NFS 資料存取。  IP 可實現高可用性，這意味著，如果具有特定 IP 的伺服器或網路發生故障，則 IP 範圍中的下一個 IP 可用於 NFS 存取。</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">如果您希望從所有 MapR 節點提供 NFS 訪問，那麼您可以為每個伺服器分配一組虛擬 IP，並且可以使用每個 MapR 節點的資源進行 NFS 資料存取。</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">檢查每個 MapR 節點上分配的虛擬 IP 並將其用於 NFS 資料存取。</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">使用指派的虛擬 IP 掛載 NFS 匯出的 MapR-FS 來檢查 NFS 操作。但是，使用NetApp XCP 進行資料傳輸不需要此步驟。</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">配置NetApp XCP 以將資料從 MapR-FS NFS 網關傳輸到ONTAP NFS。</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">配置 XCP 的目錄位置。</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">將許可證文件複製到<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block>。</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">使用<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block>命令。</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">檢查 NFS 導出的來源。</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">使用 XCP 從多個 MapR 節點從多個來源 IP 和多個目標 IP（ONTAP LIF）傳輸資料。</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">檢查儲存控制器上的負載分佈。</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">基於此驗證，資料科學家和工程師可以透過NetApp Cloud Volumes ONTAP的 S3 儲存桶存取來自 AWS SageMaker Jupyter Notebooks 的 NFS 資料。這種方法可以輕鬆存取和共享來自 NFS 和 S3 的相同數據，而無需額外的軟體。</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">使用 SageMaker BlazingText 進行文字分類</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">ONTAP版本對 S3 物件儲存的支持</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">資料可在 NFS 中使用，並可透過 AWS SageMaker 的 S3 存取。</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">資料科學家和其他應用程式的資料二元性</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">技術要求</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">對於資料二元性用例，您需要NetApp BlueXP、 NetApp Cloud Volumes ONTAP和 AWS SageMaker Notebooks。</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">軟體需求</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">下表列出了實現用例所需的軟體元件。</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">AWS SageMaker 筆記本</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">部署流程</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">部署資料二元性解決方案涉及以下任務：</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">BlueXP連接器</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">機器學習數據</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">透過 Jupyter Notebook 驗證機器學習</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">BlueXP連接器</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">在本次驗證中，我們使用了 AWS。它也適用於 Azure 和 Google Cloud。若要在 AWS 中建立BlueXP連接器，請完成下列步驟：</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">我們使用了基於BlueXP中的 mcarl-marketplace-subscription 的憑證。</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">選擇適合您環境的區域（例如，us-east-1 [N. Virginia]），並選擇身份驗證方法（例如，Assume Role 或 AWS keys）。在此驗證中，我們使用 AWS 金鑰。</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">提供連接器的名稱並建立角色。</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">根據您是否需要公共 IP，提供網路詳細信息，例如 VPC、子網路或密鑰對。</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">提供安全群組的詳細信息，例如來自來源類型的 HTTP、HTTPS 或 SSH 訪問，例如任何地方和 IP 範圍資訊。</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">審查並建立BlueXP連接器。</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">驗證BlueXP EC2 執行個體狀態是否在 AWS 控制台中執行，並從 *Networking* 標籤中檢查 IP 位址。</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">從BlueXP入口網站登入連接器使用者介面，或您可以使用 IP 位址從瀏覽器存取。</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">若要在BlueXP中建立Cloud Volumes ONTAP實例，請完成下列步驟：</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">建立一個新的工作環境，選擇雲端供應商，並選擇Cloud Volumes ONTAP實例的類型（例如單一 CVO、HA 或Amazon FSx ONTAP for ONTAP）。</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">提供詳細信息，例如Cloud Volumes ONTAP叢集名稱和憑證。在此驗證中，我們建立了一個Cloud Volumes ONTAP<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block>。</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">選擇Cloud Volumes ONTAP所需的服務。在這次驗證中，我們選擇僅監控，因此我們停用了*資料感知與合規性*和*備份到雲端服務*。</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">在*位置和連線*部分中，選擇 AWS 區域、VPC、子網路、安全性群組、SSH 驗證方法以及密碼或金鑰對。</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">選擇充電方式。我們使用*專業版*進行此驗證。</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">您可以選擇預先配置的包，例如*POC 和小型工作負載*、*資料庫和應用程式資料生產工作負載*、*經濟高效的 DR* 或 *最高效能生產工作負載*。在本次驗證中，我們選擇*Poc 和 Small Workloads*。</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">建立具有特定大小、允許的協定和匯出選項的磁碟區。在此驗證中，我們建立了一個名為<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>。</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">選擇設定檔磁碟類型和分層策略。在本次驗證中，我們停用了*儲存效率*和*通用 SSD - 動態效能*。</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">最後，檢查並建立Cloud Volumes ONTAP實例。然後等待 15-20 分鐘讓BlueXP建立Cloud Volumes ONTAP工作環境。</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">配置以下參數以啟用 Duality 協定。從ONTAP 9 開始支援 Duality 協定 (NFS/S3)。  12.1 及更高版本。</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">在此驗證中，我們建立了一個名為<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block>和音量<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>。</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">驗證 SVM 是否支援 NFS 和 S3 協定。如果沒有，請修改 SVM 以支援它們。</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">如果需要，請建立並安裝 CA 憑證。</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">建立服務資料策略。</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">檢查匯總詳細資訊。</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">建立使用者和群組。</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">在 NFS 磁碟區上建立一個儲存桶。</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">若要從 AWS SageMaker 建立 AWS Notebook，請完成以下步驟：</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">確保建立 Notebook 實例的使用者俱有 AmazonSageMakerFullAccess IAM 原則或屬於具有 AmazonSageMakerFullAccess 權限的現有群組的一部分。在此驗證中，使用者是現有群組的一部分。</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">提供以下資訊：</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">筆記本實例名稱。</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">實例類型。</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">平台標識符。</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">選擇具有 AmazonSageMakerFullAccess 權限的 IAM 角色。</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">根訪問 – 啟用。</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">加密金鑰 - 選擇無自訂加密。</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">保留其餘預設選項。</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">在本次驗證中，SageMaker實例詳情如下：</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">描述該步驟的螢幕截圖。</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">啟動 AWS Notebook。</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">開啟 Jupyter 實驗室。</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">登入終端機並掛載Cloud Volumes ONTAP磁碟區。</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">使用 AWS CLI 指令檢查在Cloud Volumes ONTAP磁碟區上建立的儲存桶。</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">在這次驗證中，我們使用了來自眾包社群努力的 DBpedia 的資料集，從各種維基媒體計畫創建的資訊中提取結構化內容。</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">從 DBpedia GitHub 位置下載資料並提取。使用與上一節相同的終端。</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">將資料複製到Cloud Volumes ONTAP位置並使用 AWS CLI 從 S3 儲存桶中進行檢查。</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">執行基本驗證以確保讀取/寫入功能在 S3 儲存桶上正常運作。</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">透過 Jupyter Notebook 驗證機器學習</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">以下驗證透過使用以下 SageMaker BlazingText 範例透過文字分類提供機器學習建置、訓練和部署模型：</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">安裝 boto3 和 SageMaker 套件。</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">輸出：</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">在下一步中，數據<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block>) 從 s3 bucket 下載<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block>到機器學習中使用的 Jupyter Notebook 實例。</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">以下程式碼建立從整數索引到類別標籤的映射，用於在推理期間檢索實際的類別名稱。</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">輸出列出了<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block>儲存桶用作 AWS SageMaker 機器學習驗證的資料。</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">開始資料預處理階段，將訓練資料預處理為空格分隔的標記化文字格式，BlazingText 演算法和 nltk 函式庫可以使用該格式對來自 DBPedia 資料集的輸入句子進行標記化。下載 nltk 標記器和其他函式庫。這<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block>並行應用於每個資料實例使用 Python 多處理模組。</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">將格式化和訓練資料集上傳到 S3，以便 SageMaker 可以使用它來執行訓練作業。然後使用 Python SDK 將兩個檔案上傳到儲存桶和前綴位置。</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">在載入模型工件的 S3 處設定輸出位置，以便工件可以作為演算法訓練作業的輸出。創建一個<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block>物件來啟動訓練工作。</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">定義 SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block>使用資源配置和超參數在 c4.4xlarge 實例上使用監督模式在 DBPedia 資料集上訓練文字分類。</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">準備資料通道和演算法之間的握手。為此，創建<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block>來自資料通道的對象，並將它們保存在字典中以供演算法使用。</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">作業完成後，將出現「作業完成」訊息。訓練好的模型可以在設定為<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block>在估算器中。</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">訓練完成後，將訓練好的模型部署為 Amazon SageMaker 即時託管終端節點以進行預測。</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">預設情況下，模型會傳回一個機率最高的預測。檢索頂部<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block>預測，設定<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block>在設定檔中。</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">關閉筆記本之前刪除端點。</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">資料科學家和工程師經常需要存取以 NFS 格式儲存的數據，但直接從 AWS SageMaker 中的 S3 協定存取這些資料可能具有挑戰性，因為 AWS 僅支援 S3 儲存桶存取。但是， NetApp ONTAP透過為 NFS 和 S3 啟用雙協定存取提供了解決方案。透過此解決方案，資料科學家和工程師可以透過NetApp Cloud Volumes ONTAP的 S3 儲存桶存取來自 AWS SageMaker 筆記本的 NFS 資料。這種方法可以輕鬆存取和共享來自 NFS 和 S3 的相同數據，而無需額外的軟體。</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967：使用NetApp檔案物件二元性和 AWS SageMaker 進行雲端資料管理</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">NFS 和 S3 雙協定存取的潛在用例是在機器學習和資料科學領域。例如，一個資料科學家團隊可能正在使用 AWS SageMaker 進行機器學習項目，這需要存取以 NFS 格式儲存的資料。但是，可能還需要透過 S3 儲存桶存取和共享數據，以便與其他團隊成員合作或與使用 S3 的其他應用程式整合。</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">此解決方案採用以下技術：</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">AWS SageMaker 筆電。為開發人員和資料科學家提供機器學習功能，以有效地建立、訓練和部署高品質的 ML 模型。</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP。 *支援在本機以及 AWS、Azure 和 Google Cloud 上發現、部署和操作儲存。它提供資料保護，防止資料遺失、網路威脅和意外中斷，並優化資料儲存和基礎設施。</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP。 *在 AWS、Azure 和 Google Cloud 上提供具有 NFS、SMB/CIFS、iSCSI 和 S3 協定的企業級儲存卷，讓使用者在存取和管理雲端中的資料時擁有更大的靈活性。</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">NetApp Cloud Volumes ONTAP由BlueXP創建，用於儲存 ML 資料。</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">下圖展示了該解決方案的技術組件。</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">該圖顯示了該解決方案的技術組件。</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">透過利用NetApp Cloud Volumes ONTAP，團隊可以將其資料儲存在單一位置，並可透過 NFS 和 S3 協定存取。資料科學家可以直接從 AWS SageMaker 存取 NFS 格式的數據，而其他團隊成員或應用程式可以透過 S3 儲存桶存取相同的資料。</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">這種方法可以輕鬆且有效率地存取和共享數據，而無需額外的軟體或不同儲存解決方案之間的資料遷移。它還允許團隊成員之間更簡化的工作流程和協作，從而更快、更有效地開發機器學習模型。</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">本文檔提供了將 Kafka 與NetApp儲存體結合使用的最佳實務指南，包括 Confluent Kafka 認證測試、效能結果、調整、Kafka 連接器和自我重新平衡功能。</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">本文檔提供了將 Confluent 分層儲存與NetApp儲存體結合使用的最佳實務指南，包括驗證測試、分層儲存效能結果、調整、Confluent S3 連接器和自平衡功能。考慮到 ILM 策略、經過多項效能測試驗證的 Confluent 效能以及業界標準的 S3 API， NetApp StorageGRID物件儲存是 Confluent 分層儲存的最佳選擇。</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">什麼是 Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3-sink 參數詳情</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">阿帕契卡夫卡</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Confluent 平台中的無限存儲</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent 分層儲存 - 最佳實踐與規模</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Confluent 平台的 Amazon S3 接收器連接器</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka 大小</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID大小調整</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafka 用例</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Confluence 平台 6.0 中的自平衡 Kafka 集群</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">本文檔介紹了在NetApp儲存控制器上使用 Kafka 的最佳實務指南。</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam、Joseph Kandatilparambil、 NetApp Rankesh Kumar、Confluence</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka 是一個社群分散式事件流平台，每天都能夠處理數兆個事件。 Kafka 最初被認為是一個訊息佇列，基於分散式提交日誌的抽象化。自 2011 年由 LinkedIn 創建並開源以來，Kafka 已經從一個訊息佇列發展成為一個成熟的事件流平台。  Confluent 透過 Confluent 平台提供 Apache Kafka 的分發。  Confluent 平台為 Kafka 提供了額外的社群和商業功能，旨在增強大規模生產中營運商和開發人員的串流體驗。</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">本文檔透過提供以下內容描述了在 NetApp 物件儲存產品上使用 Confluent 分層儲存的最佳實踐指南：</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">使用NetApp物件儲存進行匯合驗證 – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">分層儲存效能測試</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">NetApp儲存系統上 Confluent 的最佳實務指南</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">為什麼選擇 Confluent 分層儲存？</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">本文由 Confluent 撰寫</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent 已成為許多應用程式的預設即時串流平台，尤其是對於大數據、分析和串流媒體工作負載。分層儲存使用戶能夠在 Confluent 平台中將運算與儲存分開。它使儲存資料更具成本效益，使您能夠儲存幾乎無限量的資料並按需擴大（或縮小）工作負載，並使資料和租戶重新平衡等管理任務更加容易。 S3 相容儲存系統可以利用所有這些功能，將所有事件集中在一個地方，實現資料民主化，因此無需複雜的資料工程。有關為什麼應該為 Kafka 使用分層存儲的更多信息，請查看<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>。</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">為什麼選擇NetApp StorageGRID進行分層儲存？</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID是NetApp推出的業界領先的物件儲存平台。  StorageGRID是一種軟體定義的基於物件的儲存解決方案，支援業界標準物件 API，包括 Amazon Simple Storage Service (S3) API。 StorageGRID大規模儲存和管理非結構化數據，以提供安全、持久的物件儲存。內容被放置在正確的位置、正確的時間和正確的儲存層，從而優化工作流程並降低全球分佈的富媒體的成本。</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRID最大的差異在於其資訊生命週期管理 (ILM) 策略引擎，它支援策略驅動的資料生命週期管理。策略引擎可以使用元資料來管理資料在其整個生命週期內的儲存方式，以便最初優化效能，並隨著資料老化自動優化成本和耐用性。</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">啟用 Confluent 分層存儲</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">分層儲存的基本概念是將資料儲存任務與資料處理任務分開。透過這種分離，資料儲存層和資料處理層可以更輕鬆地獨立擴展。</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Confluent 的分層儲存解決方案必須處理兩個因素。首先，它必須解決或避免常見的物件儲存一致性和可用性屬性，例如 LIST 操作中的不一致和偶爾的物件不可用。其次，它必須正確處理分層儲存與 Kafka 的複製和容錯模型之間的交互，包括殭屍領導者繼續分層偏移範圍的可能性。  NetApp物件儲存提供一致的物件可用性和 HA 模型，使分層儲存可用於層偏移範圍。  NetApp物件儲存提供一致的物件可用性和 HA 模型，使分層儲存可用於層偏移範圍。</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">透過分層存儲，您可以使用高效能平台在串流資料尾部附近進行低延遲讀寫，還可以使用更便宜、可擴展的物件儲存（如NetApp StorageGRID ）進行高吞吐量歷史讀取。我們也為具有 netapp 儲存控制器的 Spark 提供了技術解決方案，詳細資訊請見此處。下圖顯示了 Kafka 如何融入即時分析管道。</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">下圖描述了NetApp StorageGRID如何作為 Confluent Kafka 的物件儲存層。</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">本節介紹 Confluent 認證所使用的硬體和軟體。此資訊適用於使用NetApp儲存的 Kafka 部署。</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">漿紗</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka 大小調整可以透過四種組態模式進行：簡單、粒度、反向和分割。</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">簡單的</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">簡單模式適合首次使用 Apache Kafka 的使用者或早期使用案例。對於此模式，您可以提供吞吐量 MBps、讀取扇出、保留和資源利用率百分比（預設值為 60%）等要求。您也可以進入環境，例如本機（裸機、VMware、Kubernetes 或 OpenStack）或雲端。根據這些信息，Kafka 叢集的大小提供了代理、zookeeper、Apache Kafka 連接工作器、模式註冊表、REST 代理、ksqlDB 和 Confluent 控制中心所需的伺服器數量。</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">對於分層存儲，請考慮使用粒度配置模式來確定 Kafka 叢集的大小。粒度模式適合經驗豐富的 Apache Kafka 使用者或定義明確的用例。本節介紹生產者、流處理器和消費者的大小。</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">生產者</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">若要描述 Apache Kafka 的生產者（例如本機用戶端、REST 代理程式或 Kafka 連接器），請提供以下資訊：</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*姓名。 *火花。</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*生產者類型。 *應用程式或服務、代理（REST、MQTT、其他）和現有資料庫（RDBMS、NOSQL、其他）。您也可以選擇“我不知道”。</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*平均吞吐量。 *以每秒事件數計算（例如 1,000,000）。</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*峰值吞吐量。 *以每秒事件數計算（例如 4,000,000）。</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*平均訊息大小。 *以位元組為單位，未壓縮（最大 1MB；例如 1000）。</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*訊息格式。 *選項包括 Avro、JSON、協議緩衝區、二進制、文字、“我不知道”和其他。</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*複製因子。 *選項為 1、2、3（Confluent 建議）、4、5 或 6。</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*保留時間。 *有一天（例如）。您希望將資料儲存在 Apache Kafka 中多久？輸入 -1 和任意單位可表示無限時間。計算器假設無限保留的保留時間為 10 年。</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">選取「啟用分層儲存以減少代理數量並允許無限儲存？」複選框。</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">啟用分層儲存後，保留欄位控制在代理本地儲存的熱資料集。檔案保留欄位控制資料在檔案物件儲存中的儲存時間。</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*檔案存放保留。 *一年（例如）。您希望將資料保存在檔案儲存中多久？輸入 -1 和任意單位可獲得無限持續時間。計算器假設無限保留的保留時間為 10 年。</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*增長乘數。 * 1（例如）。如果此參數的值是基於目前吞吐量，則將其設為 1。若要根據額外成長確定大小，請將此參數設定為成長乘數。</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">生產者實例的數量。 10（例如）。將運行多少個生產者實例？此輸入需要將 CPU 負載納入尺寸計算。空白值表示 CPU 負載未納入計算。</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">根據此範例輸入，尺寸對生產者有以下影響：</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">未壓縮位元組的平均吞吐量：1GBps。未壓縮位元組的峰值吞吐量：4GBps。壓縮位元組的平均吞吐量：400MBps。壓縮位元組的峰值吞吐量：1.6GBps。這是基於預設的 60% 壓縮率（您可以更改此值）。</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">所需的代理熱集儲存總量：31,104TB，包括複製和壓縮。所需的總代理外存檔儲存：378,432TB（壓縮）。使用<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block>用於StorageGRID大小調整。</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">流處理器必須描述從 Apache Kafka 使用資料並返回 Apache Kafka 的應用程式或服務。大多數情況下，這些都是在 ksqlDB 或 Kafka Streams 中建構的。</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*姓名。 *火花飄帶。</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*處理時間。 *該處理器處理一條訊息需要多長時間？</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 毫秒（簡單、無狀態轉換）[範例]，10 毫秒（有狀態的記憶體操作）。</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100ms（有狀態網路或磁碟操作），1000ms（第三方 REST 呼叫）。</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">我已經對這個參數進行了基準測試，並且確切地知道需要多長時間。</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*輸出保留。 * 1天（範例）。流處理器將其輸出傳回給 Apache Kafka。您希望這些輸出資料在 Apache Kafka 中儲存多久？輸入 -1 和任意單位可獲得無限持續時間。</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">選取核取方塊“啟用分層儲存以減少代理數量並允許無限儲存？”</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*檔案存放保留。 * 1年（例如）。您希望將資料保存在檔案儲存中多久？輸入 -1 和任意單位可獲得無限持續時間。計算器假設無限保留的保留時間為 10 年。</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*輸出直通百分比。 * 100（例如）。流處理器將其輸出傳回給 Apache Kafka。入站吞吐量的百分比將輸出回 Apache Kafka？例如，如果入站吞吐量為 20MBps，且該值為 10，則輸出吞吐量將為 2MBps。</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">這是從哪些應用程式讀取的？選擇“Spark”，這是基於生產者類型的大小調整中使用的名稱。根據上述輸入，您可以預期流處理器執行個體和主題分區估計的大小會產生以下影響：</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">此流處理器應用程式需要以下數量的實例。傳入的主題可能也需要這麼多的分區。聯絡 Confluent 確認此參數。</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1,000 表示平均吞吐量，無成長乘數</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">峰值吞吐量為 4,000，無成長乘數</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1,000 表示平均吞吐量，並帶有成長乘數</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">峰值吞吐量為 4,000，並帶有增長乘數</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">消費者</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">描述使用來自 Apache Kafka 的資料但不傳回 Apache Kafka 的應用程式或服務；例如，本機用戶端或 Kafka 連接器。</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*姓名。 *激發消費者。</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*處理時間。 *該消費者需要多長時間來處理一則訊息？</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1ms（例如，像日誌記錄這樣的簡單且無狀態的任務）</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10ms（快速寫入資料儲存）</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 毫秒（資料儲存寫入速度慢）</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000ms（第三方 REST 呼叫）</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">一些其他已知持續時間的基準測試過程。</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*消費者類型。 *應用程式、代理程式或接收器至現有資料儲存（RDBMS、NoSQL 等）。</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">這是從哪些應用程式讀取的？將此參數與先前確定的生產者和流量大小連接起來。</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">根據上述輸入，您必須確定消費者實例的大小和主題分區估計。消費者應用程式需要以下數量的實例。</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">平均吞吐量為 2,000，無成長乘數</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">峰值吞吐量為 8,000，無成長乘數</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">平均吞吐量為 2,000，包括成長乘數</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">峰值吞吐量為 8,000，包括成長乘數</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">傳入的主題可能也需要這個數量的分區。聯絡 Confluent 進行確認。</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">除了對生產者、流處理器和消費者的要求之外，您還必須提供以下額外要求：</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*重建時間。 *例如4小時。如果 Apache Kafka 代理主機發生故障，其資料遺失，並且需要配置新主機來取代故障主機，那麼這個新主機必須多快重建自身？如果值未知，請將此參數留空。</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*資源利用率目標（百分比）。 *例如，60。您希望您的主機在平均吞吐量期間的使用率為何？  Confluent 建議利用率為 60%，除非您使用 Confluent 自平衡集群，在這種情況下利用率可能會更高。</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">描述你的環境</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*您的叢集將在什麼環境中運作？ *亞馬遜網路服務、微軟 Azure、Google雲端平台、本地裸機、本地 VMware、本地 OpenStack 還是本地 Kubernates？</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*主人詳細資料。 *核心數：例如48個，網卡類型（10GbE、40GbE、16GbE、1GbE或其他類型）。</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*儲存磁碟區。 *主持人：12（例如）。每個主機支援多少個硬碟或 SSD？  Confluent 建議每台主機配備 12 個硬碟。</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*儲存容量/磁碟區（以 GB 為單位）。 * 1000（例如）。單一磁碟區可以儲存多少 GB 的儲存空間？  Confluent 建議使用 1TB 磁碟。</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">儲存配置。儲存卷如何配置？ Confluent 建議使用 RAID10 來充分利用 Confluent 的所有功能。也支援 JBOD、SAN、RAID 1、RAID 0、RAID 5 和其他類型。</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*單卷吞吐量（MBps）。 * 125（例如）。單一儲存卷每秒的讀取或寫入速度是多少兆位元組？  Confluent 建議使用標準硬碟，其吞吐量通常為 125MBps。</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*記憶體容量（GB）。 *  64（例如）。</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">確定環境變數後，選擇“Size my Cluster”。根據上面指出的範例參數，我們確定了 Confluent Kafka 的以下大小：</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka。 *經紀人數量：22。您的叢集受儲存限制。考慮啟用分層儲存以減少主機數量並允許無限儲存。</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">Apache ZooKeeper。數量：5；Apache Kafka Connect Workers：數量：2；Schema Registry：數量：2；REST Proxy：數量：2；ksqlDB：數量：2；Confluent Control Center：數量：1。</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">對於平台團隊，請使用反向模式，無需考慮用例。使用分區模式來計算單一主題需要多少個分區。看<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block>根據反向和分割模式進行大小調整。</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">解決方案架構細節</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">本節介紹用於 Confluent 驗證的硬體和軟體。此資訊適用於使用NetApp儲存的 Confluent Platform 部署。下表涵蓋了經過測試的解決方案架構和基本組件。</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">解決方案組件</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">細節</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka 版本 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">三位動物園管理員</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">五台經紀商伺服器</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">五款工具伺服器</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">一個 Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">一個控制中心</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux（Ubuntu 18.04）</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">所有伺服器</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID用於分層存儲</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID軟體</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000（負載平衡器）</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 個 SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3 協議</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100GbE（代理程式和StorageGRID實例之間的網路連線）</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15台富士通PRIMERGY RX2540伺服器</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">每個配備：* 2 個 CPU，共 16 個實體核心 * Intel Xeon * 256GB 實體記憶體 * 100GbE 雙端口</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">本文檔提供了將 Dremio 與NetApp儲存區結合使用的最佳實務指南，包括 TPCDS 認證測試、調整和客戶使用案例詳細資訊。</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">總而言之，本技術報告提供了混合 Iceberg Lakehouse 與 Dremio 結合使用以及來自NetApp儲存控制器的各種資料來源（包括ONTAP S3、NAS 和StorageGRID）的全面部署詳細資訊。部署程序成功執行，並利用 TPC-DS 基準測試工具在不同資料來源中執行了 99 個 SQL 查詢。該報告也探討了NetApp內部的客戶使用案例，展示了 Dremio 在滿足多樣化業務需求方面的多功能性和有效性。此外，還研究了涉及汽車零件銷售客戶的特定用例，並強調了利用 Dremio 進行數據分析和洞察的實際應用和好處。</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">整體而言，本文檔是了解 Dremio 與NetApp儲存控制器的部署和使用的寶貴資源，展現了其在推動各行業資料驅動決策和最佳化的能力和潛力。</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Zookeeper 安裝</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">德雷米奧</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">使用 storageGRID 設定 Dremio</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">NetApp用例</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">我們已經通過 Dremio 平台認證並在NetApp物件儲存中進行了 Lakehouse 驗證。</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">部署流程</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">此圖展示了採用NetApp儲存控制器的 dremio 架構</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">在此參考架構驗證中，我們使用了由一個協調器和四個執行器組成的 Dremio 配置<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">NetApp設定</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">儲存系統初始化</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">儲存虛擬機器 (SVM) 創建</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">邏輯網路介面的分配</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">NFS、S3 配置和許可</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">對於 NFS（網路檔案系統），請依照下列步驟操作：1.為 NFSv4 或 NFSv3 建立 Flex Group 磁碟區。在我們為此驗證設定的設定中，我們使用了 48 個 SSD，其中 1 個 SSD 專用於控制器的根卷，另外 47 個 SSD 分佈在 NFSv4]]。驗證 Flex Group 磁碟區的 NFS 匯出策略是否對 Dremio 伺服器網路具有讀取/寫入權限。</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">在所有 Dremio 伺服器上，建立一個資料夾，並透過每個 Dremio 伺服器上的邏輯介面 (LIF) 將 Flex Group 磁碟區掛載到該資料夾上。</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">對於 S3（簡單儲存服務），請依照下列步驟操作：</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">使用「vserver object-store-server create」指令設定一個啟用 HTTP 的物件儲存伺服器，並將管理狀態設為「up」。您可以選擇啟用 HTTPS 並設定自訂偵聽器連接埠。</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">使用「vserver object-store-server user create -user &lt;username&gt;」指令建立 object-store-server 使用者。</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">若要取得存取金鑰和金鑰，可以執行下列指令：「set diag; vserver object-store-server user show -user &lt;username&gt;」。但是，今後這些金鑰將在使用者建立過程中提供，或者可以使用 REST API 呼叫來檢索。</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">使用步驟 2 中建立的使用者建立物件儲存伺服器群組並授予存取權限。在這個例子中，我們提供了「FullAccess」。</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">透過將其類型設為「S3」來建立兩個 S3 儲存桶。一個用於 Dremio 配置，一個用於客戶資料。</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">Zookeeper 設定</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">您可以使用 Dremio 提供的 zookeeper 配置。在此驗證中，我們使用了單獨的 Zookeeper。我們遵循了此網頁連結中提到的步驟<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Dremio 設定</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">我們按照此網頁連結透過 tar ball 安裝 Dremio。</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">建立一個 Dremio 群組。</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">建立一個 dremio 使用者。</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">建立 Dremio 目錄。</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">下載 tar 文件<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">將 Dremio 解壓縮到 /opt/dremio 目錄中。</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">為設定資料夾建立符號連結。</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">設定您的服務配置（SystemD 設定）。</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">將 dremio 守護程式的單元檔案從 /opt/dremio/share/dremio.service 複製到 /etc/systemd/system/dremio.service。</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">重啟系統</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">啟用 dremio 在啟動時啟動。</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">在協調器上配置 Dremio。有關更多信息，請參閱 Dremio 配置</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">Dremio.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">核心站點.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">Dremio 設定儲存在NetApp物件儲存中。在我們的驗證中，「dremioconf」儲存桶位於 ontap S3 儲存桶中。下圖顯示了「dremioconf」S3儲存桶的「scratch」和「uploads」資料夾的一些詳細資訊。</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">該圖顯示了 dremio 與NetApp物件存儲</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">在執行器上配置 Dremio。在我們的設定中，我們有 3 個執行者。</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml – 與協調器設定相同。</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">NetApp建議使用StorageGRID作為 Datalake 和 Lakehouse 環境的主要物件儲存解決方案。此外， NetApp ONTAP也用於實現檔案/物件二元性。在本文檔中，我們根據客戶要求對ONTAP S3 進行了測試，並且它成功地充當了資料來源。</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">多源設定</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">在 Dremio 中將ONTAP S3 和 storageGRID 配置為 s3 來源。</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Dremio 儀表板 -&gt; 資料集 -&gt; 來源 -&gt; 新增來源。</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">在常規部分，請更新 AWS 存取權限和金鑰</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">在進階選項中，啟用相容模式，使用以下詳細資訊更新連線屬性。來自NetApp儲存控制器的端點 IP/名稱，來自 ontap S3 或 storageGRID。</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">盡可能啟用本地緩存，盡可能使用的總可用快取的最大百分比 = 100</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">該圖顯示了NetApp物件儲存中的檔案列表</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">然後查看NetApp物件儲存的儲存桶列表。<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">storageGRID 儲存桶詳細資訊的範例視圖<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">在 Dremio 中將 NAS（特別是 NFS）配置為來源。</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">在常規部分中，輸入名稱和 NFS 掛載路徑。請確保 NFS 掛載路徑安裝在 Dremio 叢集中所有節點的同一個資料夾中。</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">本文檔介紹了在NetApp儲存控制器上使用 Dremio 的最佳實務指南。</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">NetApp和 Dremio 的下一代混合 Iceberg Lakehouse 解決方案</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">在本文檔中，我們討論了 Dremio 與來自NetApp儲存控制器的不同資料來源的部署細節，包括ONTAP S3、NAS 和StorageGRID。在部署期間，我們使用 TPC-DS 基準測試工具跨各種來源執行 99 個 SQL 查詢。該文件還探討了NetApp內部的客戶用例，以及涉及汽車零件銷售客戶的用例。</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">本節介紹用於 dremio 認證的硬體和軟體。此資訊適用於使用NetApp儲存的 dremio 部署。</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">解決方案概述</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">混合 Iceberg Lakehouse 解決方案提供了獨特的優勢，以解決資料湖客戶面臨的客戶挑戰。透過利用 Dremio Unified Lakehouse 平台和NetApp ONTAP、 StorageGRID和NetApp Cloud 解決方案，公司可以為其業務營運增加顯著的價值。該解決方案不僅可以存取包括NetApp來源在內的多個資料來源，還可以提高整體分析效能並幫助公司獲得業務洞察力，從而促進業務成長。</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">NetApp概述</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">NetApp 的產品（例如ONTAP和StorageGRID）可實現儲存和運算的分離，從而根據特定需求實現最佳資源利用率。這種靈活性使客戶能夠使用NetApp存儲解決方案獨立擴展其存儲</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">透過利用 NetApp 的儲存控制器，客戶可以使用 NFS 和 S3 協定有效地向其向量資料庫提供資料。這些協定方便了客戶資料儲存和管理向量資料庫索引，從而無需透過檔案和物件方法存取多個資料副本。</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">NetApp ONTAP為 AWS、Azure 和 Google Cloud 等領先的雲端服務供應商提供對 NAS 和物件儲存的原生支援。這種廣泛的兼容性確保了無縫集成，實現了客戶資料移動性、全球可訪問性、災難復原、動態可擴展性和高效能。</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">我們業界領先的物件儲存 storageGRID 提供了強大的策略引擎，用於自動放置資料、靈活的部署選項以及透過分層擦除編碼實現的無與倫比的耐用性。它具有可擴展的架構，可在單一命名空間中支援數十億個物件和 PB 級資料。該解決方案支援混合雲集成，允許資料分層到主要雲端平台。它在 2019 年 IDC Marketscape 全球基於物件的供應商評估中被評為領導者。</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">此外，storageGRID 也擅長透過軟體定義的物件儲存、地理冗餘和多站點功能大規模管理非結構化資料。它採用基於策略的資訊生命週期管理，並提供鏡像和搜尋等雲端整合功能。它擁有多項認證，包括通用標準、NF203 數位安全組件、ISO/IEC 25051、畢馬威和科哈塞特合規評估。</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">總而言之， NetApp storageGRID 提供了強大的功能、可擴展性、混合雲整合和合規性認證，可高效管理大規模非結構化資料。</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">NetApp ONTAP是一款強大的儲存解決方案，可提供廣泛的企業功能。它包括快照，可提供應用程式一致且防篡改的即時備份。 SnapRestore支援按需近乎即時地恢復備份，而SnapMirror提供整合的遠端備份和災難復原功能。該解決方案還採用了自主勒索軟體保護 (ARP)，透過多管理員驗證、具有 FIPS 認證的靜態資料加密、傳輸中資料加密、多因素身份驗證 (MFA) 和基於角色的存取控制 (RBAC) 等功能確保資料安全。全面的日誌記錄、稽核、板載和外部金鑰管理、安全清除以及多租用戶安全管理進一步增強了資料安全性和合規性。</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">NetApp ONTAP還具有SnapLock功能，它以較低的總擁有成本提供符合法規的資料保留，具有高水準的完整性、效能和保留。它與NetApp ONTAP 9 完全集成，並提供針對惡意行為、惡意管理員和勒索軟體的保護。</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">該解決方案包括用於動態資料和靜態資料加密的 NSE/NVE 加密、多因素管理存取和多管理驗證。 Active IQ提供基於 AI 的預測分析和糾正措施，而 QoS 確保服務品質工作負載控制。透過 SysMgr/GUI/CLI/API 可以直觀地實現管理和自動化整合。  FabricPool支援自動資料分層，透過內嵌資料壓縮、重複資料刪除和壓縮提供效率。  NetApp保證滿足工作負載效率目標，且客戶無需承擔任何費用。</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">NetApp ONTAP支援各種協議，包括 NVMe/FC、FC、NVMe/TCP、iSCSI、NFS、SMB 和 S3，使其成為統一的儲存解決方案。整體而言， NetApp ONTAP提供廣泛的企業功能、強大的安全性、合規性、效率和多功能性，以滿足多樣化的儲存需求。</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">Dremio 概述</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio 是用於自助分析和人工智慧的統一 Lakehouse 平台。  Dremio 統一分析平台透過 Lakehouse 的靈活性、可擴展性和效能，讓使用者更接近數據，而成本僅為傳統資料倉儲解決方案的一小部分。  Dremio 支援「左移」分析，以消除複雜且昂貴的資料整合和 ETL，提供無需資料移動的無縫企業級分析。  Dremio 還具有以下特點：</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">透過通用語意層和緊密整合的高效能 SQL 查詢引擎實現易於使用的自助服務分析，從而更輕鬆地連接、管理和分析雲端和本地的所有資料。</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Dremio 的 Apache Iceberg 原生 Lakehouse 管理功能簡化了資料發現，並自動化了資料最佳化，透過受 Git 啟發的資料版本控制提供高效能分析。</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">Dremio 建立在開源和開放標準的基礎上，幫助企業避免鎖定並保持創新優勢。企業公司信賴 Dremio，認為它是最容易使用的 Lakehouse 平台，在所有工作負載下都具有最佳的性價比。</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">Dremio 和NetApp混合 Iceberg Lakehouse 解決方案為客戶帶來什麼價值？</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*改進的資料管理和可訪問性*：Dremio 以其資料湖平台而聞名，該平台使組織能夠直接從其資料湖中高速查詢資料。另一方面， NetApp是雲端資料服務和資料儲存解決方案的領先供應商。該聯合產品為客戶提供了一套全面的解決方案，用於有效地儲存、管理、存取和分析其企業的數據。</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*效能最佳化*：憑藉 NetApp 在資料儲存方面的專業知識以及 Dremio 在資料處理和資料最佳化方面的能力，此合作夥伴關係提供了一種解決方案，可以提高資料操作的效能，減少延遲，並提高業務洞察的速度。  Dremio 甚至為 NetApp 自己的內部 IT 分析基礎架構帶來了效能優勢。</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*可擴充性*：Dremio 和NetApp都提供了可擴充的解決方案。此聯合解決方案為客戶提供高度可擴展的資料儲存、資料管理和分析環境。在混合 Iceberg Lakehouse 環境中，Dremio SQL 查詢引擎與NetApp StorageGRID配對，提供無與倫比的可擴展性、並發性和查詢效能，能夠滿足任何業務的分析需求。</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*資料安全與治理*：兩家公司都非常重視資料安全和治理。它們共同提供強大的安全和資料治理功能，確保資料受到保護並且滿足資料治理要求。基於角色和細粒度的存取控制、全面審計、端到端資料沿襲、統一身分管理以及具有廣泛合規性和安全框架的 SSO 等功能可確保公司的分析資料環境安全且受到管理。</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*成本效益*：透過將 Dremio 的資料湖引擎與 NetApp 的儲存解決方案結合，客戶可以降低與資料管理和資料移動相關的成本。組織也能夠從傳統的資料湖環境遷移到由NetApp和 Dremio 組成的更現代的 Lakehouse 解決方案。此混合 Iceberg Lakehouse 解決方案提供高速查詢效能和市場領先的查詢並發性，可降低 TCO 並縮短業務洞察時間。</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">本節介紹此解決方案所使用的技術。</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">技術要求</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">以下概述的硬體和軟體配置用於本文檔中執行的驗證。這些配置可作為幫助您設定環境的指南，但請注意，特定組件可能會因個別客戶的要求而有所不同。</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">硬體需求</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">硬體</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">NetApp AFF儲存陣列 HA 對</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48個3.49TB SSD-NVM</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">兩個 S3 儲存桶：Dremio 元資料和客戶資料。</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">4台富士通PRIMERGY RX2540 M4</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">64 個 CPU</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">英特爾至強金 6142 CPU @ 2.60GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">256 GM 實體內存</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 個 100GbE 網路端口</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">聯網</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100 GbE</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100、3xSGF6024 * 3 x 24 x 7.68TB * 兩個 S3 儲存桶：Dremio 元資料和客戶資料。</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">版本 - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">企業版</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">本地部署</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">5節點Dremio集群</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">1 個主協調員和 4 個執行員</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">本節介紹 Dremio 與 NetApp 物件儲存的客戶使用案例詳細資訊。</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">客戶用例</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">NetApp ActiveIQ 用例</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">ActiveIQ舊架構</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*挑戰*：NetApp 自己的內部Active IQ解決方案最初設計用於支援眾多用例，現已發展成為面向內部使用者和客戶的綜合產品。然而，由於資料的快速增長和對高效資料存取的需求，基於 Hadoop/MapR 的底層後端基礎設施在成本和效能方面帶來了挑戰。擴展儲存意味著添加不必要的運算資源，從而導致成本增加。</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">此外，管理 Hadoop 叢集非常耗時，並且需要專業知識。資料效能和管理問題進一步使情況複雜化，查詢平均需要 45 分鐘，並且由於配置錯誤導致資源匱乏。為了應對這些挑戰， NetApp尋求現有傳統 Hadoop 環境的替代方案，並確定基於 Dremio 構建的新型現代解決方案可以降低成本、分離儲存和運算、提高效能、簡化資料管理、提供細粒度控制並提供災難復原功能。</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">ActiveIQ 與 Dremio 的新架構</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*解決方案*：<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> Dremio 使NetApp能夠分階段實現其基於 Hadoop 的資料基礎架構的現代化，為統一分析提供路線圖。與其他需要對資料處理進行重大更改的供應商不同，Dremio 與現有管道無縫集成，從而節省了遷移期間的時間和成本。透過過渡到完全容器化的環境， NetApp降低了管理開銷、提高了安全性並增強了彈性。  Dremio 採用 Apache Iceberg 和 Arrow 等開放式生態系統，確保了面向未來性、透明度和可擴展性。</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">作為 Hadoop/Hive 基礎設施的替代品，Dremio 透過語意層提供了二級用例的功能。雖然現有的基於 Spark 的 ETL 和資料提取機制仍然存在，但 Dremio 提供了統一的存取層，以便更輕鬆地發現和探索數據，而無需重複。這種方法顯著減少了資料複製因素，並分離了儲存和計算。</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*好處*：借助 Dremio， NetApp透過最大限度地減少資料環境中的運算消耗和磁碟空間要求，實現了顯著的成本削減。新的Active IQ數據湖由 8,900 個表組成，包含 3PB 的數據，而先前的基礎架構包含超過 7PB 的數據。遷移到 Dremio 還涉及從 33 個微型叢集和 4,000 個核心過渡到 Kubernetes 叢集上的 16 個執行器節點。即使運算資源大幅減少， NetApp 的效能仍被顯著提升。透過 Dremio 直接存取數據，查詢運行時間從 45 分鐘減少到 2 分鐘，從而使預測性維護和優化的洞察時間提高了 95%。遷移也使計算成本降低了 60% 以上，查詢速度提高了 20 倍以上，總擁有成本 (TCO) 節省了 30% 以上。</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">汽車零件銷售客戶用例。</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*挑戰*：在這家全球汽車零件銷售公司中，高階主管和企業財務規劃和分析小組無法獲得銷售報告的綜合視圖，而被迫閱讀單獨的業務線銷售指標報告並嘗試合併它們。這導致客戶根據至少一天前的數據做出決策。獲得新的分析見解的準備時間通常需要四週以上的時間。排除資料管道故障需要更多時間，在本來就很長的時間表上再增加三天或更長時間。緩慢的報告開發過程以及報告效能迫使分析師群體不斷等待資料處理或加載，而不是讓他們發現新的業務見解並推動新的業務行為。這些問題環境由不同業務線的眾多不同資料庫組成，導致出現大量資料孤島。緩慢而分散的環境使資料治理變得複雜，因為分析師有太多方法可以得出自己的事實版本，而不是單一的事實來源。該方法在數據平台和人力成本上花費了超過 190 萬美元。維護遺留平台和填寫資料請求每年需要七名現場技術工程師 (FTE)。隨著資料請求的成長，資料智慧團隊無法擴展舊環境以滿足未來的需求</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*解決方案*：在NetApp物件儲存中經濟高效地儲存和管理大型 Iceberg 表。使用 Dremio 的語意層建立資料域，讓業務用戶輕鬆建立、搜尋和分享資料產品。</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*客戶受益*：• 改善並優化現有資料架構，將洞察時間從四周縮短至數小時 • 將故障排除時間從三天縮短至數小時 • 降低資料平台和管理成本超過 380,000 美元 • 每年節省 (2) 個 FTE 資料智慧工作量</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">我們使用NetApp物件儲存（例如ONTAP和 storagegrid）對五個節點的 sql 工作負載執行了 tpc-ds 測試。</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">解決方案驗證概述</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">在本節中，我們從多個來源執行了 SQL 測試查詢來驗證功能、測試並驗證對NetApp儲存的溢位。</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">物件儲存上的 SQL 查詢</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">在 dremio.env 中將每台伺服器的記憶體設定為 250GB</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">檢查 dremio.conf 檔案中的溢出位置 (${DREMIO_HOME}"/dremiocache) 和儲存詳細資訊。</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">將 Dremio 溢出位置指向NetApp NFS 存儲</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">選擇上下文。在我們的測試中，我們對位於ONTAP S3 中的 TPCDS 產生的 parquet 檔案進行了測試。  Dremio 儀表板 -&gt; SQL 運行器 -&gt; 上下文 -&gt; NetAppONTAPS3-&gt;Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">將上下文設定為 ontaps3 parquet 資料夾</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">從 Dremio 儀表板運行 TPC-DS query67</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">執行查詢 67，它是 TPC-DS 中的 99 個查詢之一</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">檢查作業是否在所有執行器上執行。  Dremio 儀表板 -&gt; 作業 -&gt; &lt;jobid&gt; -&gt; 原始設定檔 -&gt; 選擇 EXTERNAL_SORT -&gt; 主機名</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">Q67 查詢中的節點列表</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">當 SQL 查詢執行時，您可以檢查NetApp儲存控制器中用於資料快取的分割資料夾。</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">查詢 67 完成時溢出詳細信息</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">SQL 查詢已完成並溢出<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">已完成查詢的作業摘要 67</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">工作完成情況總結。<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">查詢結果中的 splleddata 詳細信息</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">檢查溢出資料的大小<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">相同的程式適用於 NAS 和StorageGRID物件儲存。</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">本節概述了NetApp為滿足各種 Hadoop 資料保護要求而提供的用例和解決方案。</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">本節概述了NetApp為滿足各種 Hadoop 資料保護要求而提供的用例和解決方案。透過使用由NetApp支援的資料結構，客戶可以：</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">利用 NetApp 豐富的資料管理功能以及與 Hadoop 原生工作流程的集成，可以靈活地選擇正確的資料保護解決方案。</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">將其 Hadoop 叢集備份視窗時間減少近 70%。</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">消除 Hadoop 叢集備份造成的任何效能影響。</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">同時為單一分析資料來源提供不同雲端供應商的多雲資料保護和資料存取。</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">使用FlexClone技術建立快速且節省空間的 Hadoop 叢集副本。</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">要了解有關本文檔中描述的信息的更多信息，請參閱以下文檔和/或網站：</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetApp大數據分析解決方案</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">使用NetApp儲存的 Apache Spark 工作負載</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">適用於 Apache Spark 的NetApp儲存解決方案</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">NetApp支援的資料結構上的 Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">致謝</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland， NetApp澳新銀行維多利亞區銷售部銷售代表</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">NetApp業務發展經理 Hoseb Dermanilian</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">NetApp MPSG 總監 Lee Dorrier</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">NetApp澳新銀行維多利亞區 SE 系統工程師 David Thiessen</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">版本歷史記錄</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">日期</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">文件版本歷史記錄</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">版本 1.0</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018年1月</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">初始版本</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">版本 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021年10月</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">更新案例 #5：加速分析工作負載</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">版本 3.0</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">2023年11月</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">刪除了 NIPAM 詳細信息</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">NetApp提供支援的資料結構簡化並整合了跨雲端和本地環境的資料管理，從而加速數位轉型。  NetApp提供支援的資料結構可提供一致且整合的資料管理服務和應用程式（構建塊），以實現資料可見性和洞察、資料存取和控制以及資料保護和安全性。</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">由NetApp支援的適用於大數據架構的資料結構</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">NetApp提供支援的資料結構簡化並整合了跨雲端和本地環境的資料管理，從而加速數位轉型。</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">NetApp提供支援的資料結構為資料可見性和洞察、資料存取和控制以及資料保護和安全性提供了一致且整合的資料管理服務和應用程式（構建塊），如下圖所示。</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">經過驗證的資料結構客戶用例</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">NetApp支援的資料結構為客戶提供了以下九種經過驗證的用例：</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">加速分析工作負載</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">加速 DevOps 轉型</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">建置雲端託管基礎設施</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">整合雲端資料服務</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">保護和保障資料安全</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">優化非結構化數據</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">提高資料中心效率</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">提供數據洞察和控制</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">簡化和自動化</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">本文檔涵蓋九個用例中的兩個（及其解決方案）：</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS 直接訪問</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">NetApp NFS 允許客戶在其現有或新的 NFSv3 或 NFSv4 資料上執行大數據分析作業，而無需移動或複製資料。它可以防止資料的多次複製，並且無需將資料與來源同步。例如，在金融領域，資料從一個地方移動到另一個地方必須滿足法律義務，這不是一件容易的事。在這種情況下， NetApp NFS 直接存取會從原始位置分析財務資料。另一個主要優勢是，使用NetApp NFS 直接存取可以透過使用本機 Hadoop 命令簡化 Hadoop 資料的保護，並利用 NetApp 豐富的資料管理產品組合實現資料保護工作流程。</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS 直接存取為 Hadoop/Spark 叢集提供了兩種部署選項：</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">預設情況下，Hadoop/Spark叢集使用Hadoop分散式檔案系統（HDFS）作為資料儲存和預設檔案系統。  NetApp NFS 直接存取可以用 NFS 儲存取代預設的 HDFS 作為預設檔案系統，從而實現對 NFS 資料的直接分析操作。</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">在另一個部署選項中， NetApp NFS 直接存取支援在單一 Hadoop/Spark 叢集中將 NFS 與 HDFS 一起配置為附加儲存。在這種情況下，客戶可以透過 NFS 匯出共享數據，並從同一個叢集存取數據以及 HDFS 數據。</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">使用NetApp NFS 直接存取的主要優勢包括：</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">從目前位置分析數據，從而避免將分析數據移動到 Hadoop 基礎架構（如 HDFS）這一耗時耗能的任務。</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">將副本數量從三個減少到一個。</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">使用戶能夠分離計算和存儲以獨立擴展它們。</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">利用ONTAP豐富的資料管理功能提供企業資料保護。</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">已通過 Hortonworks 資料平台認證。</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">支援混合資料分析部署。</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">利用動態多執行緒功能減少備份時間。</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">大數據的建構模組</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">NetApp提供支援的資料結構整合了資料管理服務和應用程式（構建塊），用於資料存取、控制、保護和安全，如下圖所示。</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">上圖中的構建塊包括：</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS 直接存取。 *為最新的 Hadoop 和 Spark 叢集提供對NetApp NFS 磁碟區的直接訪問，無需額外的軟體或驅動程式要求。</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* NetApp Cloud Volumes ONTAP和Google Cloud NetApp Volumes 。 *基於在 Amazon Web Services (AWS) 或 Microsoft Azure 雲端服務中的Azure NetApp Files (ANF) 中執行的ONTAP的軟體定義連線儲存。</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* NetApp SnapMirror技術*。在本機和ONTAP Cloud 或 NPS 實例之間提供資料保護功能。</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*雲端服務提供者。 *這些供應商包括 AWS、Microsoft Azure、Google Cloud 和 IBM Cloud。</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*平台即服務*。基於雲端的分析服務，例如 AWS 中的 Amazon Elastic MapReduce (EMR) 和 Databricks 以及 Microsoft Azure HDInsight 和 Azure Databricks。</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp 是一個用於大型叢集間和叢集內複製的本機工具。  Hadoop DistCp 基本流程是典型的備份工作流程，使用 Hadoop 原生工具（如 MapReduce）將 Hadoop 資料從 HDFS 來源複製到對應的目標。</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop 資料保護與NetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp 是一個用於大型叢集間和叢集內複製的本機工具。下圖所示的 Hadoop DistCp 基本流程是一個典型的備份工作流程，使用 MapReduce 等 Hadoop 原生工具將 Hadoop 資料從 HDFS 來源複製到對應的目標。</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">NetApp NFS 直接存取使客戶能夠將 NFS 設定為 Hadoop DistCp 工具的目標位置，以便透過 MapReduce 將資料從 HDFS 來源複製到 NFS 共用中。  NetApp NFS 直接存取充當 DistCp 工具的 NFS 驅動程式。</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">本文檔介紹了使用NetApp AFF和FAS儲存系統、 NetApp Cloud Volumes ONTAP、 NetApp互連儲存以及適用於 Spark 和 Hadoop 的NetApp FlexClone技術的混合雲端資料解決方案。這些解決方案架構允許客戶為其環境選擇合適的資料保護解決方案。  NetApp根據與客戶及其業務用例的互動設計了這些解決方案。</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam 和 Sathish Thyagarajan， NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">本文檔介紹了使用NetApp AFF和FAS儲存系統、 NetApp Cloud Volumes ONTAP、 NetApp互連儲存以及適用於 Spark 和 Hadoop 的NetApp FlexClone技術的混合雲端資料解決方案。這些解決方案架構允許客戶為其環境選擇合適的資料保護解決方案。 NetApp根據與客戶及其業務用例的互動設計了這些解決方案。本文檔提供以下詳細資訊：</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">為什麼我們需要為 Spark 和 Hadoop 環境提供資料保護以及客戶面臨的挑戰。</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">由NetApp願景及其建構塊和服務提供支援的資料結構。</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">如何使用這些構建塊來建立靈活的資料保護工作流程。</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">根據實際客戶使用案例分析幾種架構的優缺點。每個用例提供以下元件：</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">客戶場景</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">要求和挑戰</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">解決方案</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">解決方案總結</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">為什麼要進行 Hadoop 資料保護？</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">在 Hadoop 和 Spark 環境中，必須解決以下問題：</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*軟體或人為故障。 *在執行 Hadoop 資料操作時，軟體更新中的人為錯誤可能會導致錯誤行為，從而導致工作出現意外結果。在這種情況下，我們需要保護資料以避免失敗或不合理的結果。例如，由於交通號誌分析應用程式的軟體更新執行不力，導致新功能無法正確分析純文字形式的交通號誌資料。該軟體仍分析JSON和其他非文字檔案格式，導致即時交通管制分析系統產生缺少資料點的預測結果。這種情況可能會導致錯誤輸出，進而引發交通號誌事故。資料保護可以透過提供快速回滾到先前工作應用程式版本的功能來解決此問題。</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*尺寸和規模。 *由於資料來源數量和資料量的不斷增加，分析資料的大小也日益增長。社群媒體、行動應用程式、數據分析和雲端運算平台是當前大數據市場的主要數據來源，這些數據成長非常迅速，因此需要對數據進行保護，以確保數據操作的準確性。</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Hadoop 的原生資料保護。 * Hadoop 有一個原生指令來保護數據，但是該指令在備份期間不提供資料的一致性。它僅支援目錄級備份。  Hadoop 建立的快照是唯讀的，不能直接用於重複使用備份資料。</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop 和 Spark 客戶面臨的資料保護挑戰</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop 和 Spark 客戶面臨的一個共同挑戰是減少備份時間並提高備份可靠性，同時又不會在資料保護期間對生產叢集的效能產生負面影響。</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">客戶還需要最大限度地減少復原點目標 (RPO) 和復原時間目標 (RTO) 停機時間，並控制其內部部署和基於雲端的災難復原站點，以實現最佳業務連續性。這種控制通常來自企業級管理工具。</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Hadoop 和 Spark 環境非常複雜，因為不僅資料量龐大且不斷成長，而且資料到達的速度也在加快。這種情況使得從來源資料快速建立高效、最新的 DevTest 和 QA 環境變得困難。  NetApp認識到這些挑戰並提供了本文中介紹的解決方案。</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">在此場景中，一家大型金融服務和投資銀行的分析平台使用NetApp NFS 儲存解決方案進行了現代化改造，從而顯著提高了其資產管理和量化業務部門的投資風險和衍生性商品分析能力。</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">用例 5：加速分析工作負載</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">設想</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">在客戶現有的環境中，用於分析平台的 Hadoop 基礎架構利用了 Hadoop 伺服器的內部儲存。由於 JBOD 環境的專有性，組織內的許多內部客戶無法利用他們的蒙特卡羅定量模型，該模型是依賴即時資料重複樣本的模擬。對市場走勢不確定性的影響的理解能力不足，對量化資產管理業務部門不利。</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">該銀行的定量業務部門需要一種有效的預測方法來實現準確、及時的預測。為此，團隊意識到需要實現基礎設施現代化，減少現有的 I/O 等待時間，並提高 Hadoop 和 Spark 等分析應用程式的效能，以有效模擬投資模型、衡量潛在收益和分析風險。</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">解決方案</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">客戶現有的 Spark 解決方案已配備 JBOD。然後利用NetApp ONTAP、 NetApp StorageGRID和 MinIO Gateway to NFS 來減少銀行量化金融小組的 I/O 等待時間，該小組對評估潛在收益和風險的投資模型進行模擬和分析。此圖顯示了採用NetApp儲存的 Spark 解決方案。</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">如上圖所示，部署了AFF A800、A700 系統和StorageGRID ，以便在六節點 Hadoop 叢集中透過 NFS 和 S3 協定存取 parquet 文件，並使用 Spark、YARN 和 Hive 元資料服務進行資料分析操作。</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">客戶舊環境中的直接連接儲存 (DAS) 解決方案的缺點是無法獨立擴展運算和儲存。借助NetApp ONTAP Spark 解決方案，該銀行的財務分析業務部門能夠將儲存與運算分離，並根據需要更有效地無縫地提供基礎設施資源。</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">透過使用具有 NFS 的ONTAP ，計算伺服器 CPU 幾乎完全用於 Spark SQL 作業，並且 I/O 等待時間減少了近 70%，為 Spark 工作負載提供了更好的運算能力和效能提升。隨後，提高 CPU 使用率也使客戶能夠利用 GPU（例如 GPUDirect）進一步實現平台現代化。此外， StorageGRID為 Spark 工作負載提供了低成本的儲存選項，而 MinIO Gateway 透過 S3 協定提供對 NFS 資料的安全存取。對於雲端中的數據， NetApp建議使用Cloud Volumes ONTAP、 Azure NetApp Files和Google Cloud NetApp Volumes。</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">此用例基於需要將基於雲端的分析資料備份到其內部資料中心的廣播客戶。</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">用例 2：從雲端到本地的備份和災難恢復</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">此用例基於一個廣播客戶，該客戶需要將基於雲端的分析資料備份到其內部資料中心，如下圖所示。</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">在這種情況下，物聯網感測器資料被引入雲端中，並使用 AWS 內的開源 Apache Spark 叢集進行分析。要求是將處理後的資料從雲端備份到本地端。</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">此用例的主要要求和挑戰包括：</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">啟用資料保護不會對雲端中的生產 Spark/Hadoop 叢集造成任何效能影響。</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">需要以高效、安全的方式將雲端感測器資料移動並保護到本地。</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">在不同條件下靈活地將資料從雲端傳輸到本地，例如按需、即時以及低叢集負載時間期間。</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">客戶使用 AWS Elastic Block Store (EBS) 作為其 Spark 叢集 HDFS 存儲，以透過 Kafka 接收和提取來自遠端感測器的資料。因此，HDFS 儲存可作為備份資料的來源。</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">為了滿足這些要求， NetApp ONTAP Cloud 部署在 AWS 中，並建立了一個 NFS 共用作為 Spark/Hadoop 叢集的備份目標。</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">建立 NFS 共用後，將資料從 HDFS EBS 儲存複製到ONTAP NFS 共用。當資料駐留在ONTAP Cloud 中的 NFS 時，可以根據需要使用SnapMirror技術以安全且有效率的方式將資料從雲端鏡像到本機儲存中。</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">此圖顯示了從雲端到本地解決方案的備份和災難復原。</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">在這種情況下，客戶擁有一個大型的內部部署 Hadoop 儲存庫，並希望將其備份以用於災難復原目的。然而，客戶目前的備份解決方案成本高昂，且備份視窗長達 24 小時以上。</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">用例 1：備份 Hadoop 數據</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">軟體向後相容性：</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">所提出的替代備份解決方案應與生產 Hadoop 叢集中目前運行的軟體版本相容。</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">為了滿足承諾的 SLA，建議的替代解決方案應該實現非常低的 RPO 和 RTO。</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">NetApp備份解決方案所建立的備份可用於在資料中心本機建置的 Hadoop 叢集以及在遠端站點的災難復原位置執行的 Hadoop 叢集。</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">所提出的解決方案必須具有成本效益。</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">所提出的解決方案必須減少備份期間對目前正在執行的生產分析作業的效能影響。</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">客戶現有的備份解決方案x</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">下圖是原有的Hadoop原生備份方案。</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">生產資料透過中間備份叢集保護到磁帶上：</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">透過執行以下命令將 HDFS1 資料複製到 HDFS2<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block>命令。</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">備份叢集充當NFS網關，透過Linux手動將資料複製到磁帶<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block>透過磁帶庫指令。</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Hadoop原生備份方案的優點包括：</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">該解決方案基於 Hadoop 原生命令，使用戶無需學習新的程式。</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">該解決方案利用行業標準架構和硬體。</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">原有Hadoop原生備份方案的缺點包括：</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">備份視窗時間過長超過24小時，導致生產資料容易受到攻擊。</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">備份期間叢集效能明顯下降。</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">複製到磁帶是一個手動過程。</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">就所需硬體和手動流程所需的人力而言，備份解決方案的成本很高。</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">備份解決方案</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">基於這些挑戰和要求，並考慮到現有的備份系統，提出了三種可能的備份解決方案。以下小節分別描述這三種不同的備份解決方案，標示為解決方案 A 到解決方案 C。</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">解決方案 A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">在解決方案 A 中，備份 Hadoop 叢集將二級備份傳送至NetApp NFS 儲存系統，因此無需磁帶，如下圖所示。</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">解決方案A的詳細任務包括：</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">生產 Hadoop 叢集在需要保護的 HDFS 中擁有客戶的分析資料。</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">帶有 HDFS 的備份 Hadoop 叢集可作為資料的中間位置。只需一組磁碟（JBOD）即可為生產和備份 Hadoop 叢集中的 HDFS 提供儲存。</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">透過運行<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block>命令。</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop快照用於保護從生產到備份Hadoop叢集的資料。</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAP儲存控制器提供 NFS 匯出卷，該磁碟區配置給備份 Hadoop 叢集。</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">透過運行<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block>指令利用 MapReduce 和多個映射器，分析資料從備份 Hadoop 叢集到 NFS 受到保護。</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">將資料儲存在NetApp儲存系統上的 NFS 後，根據需要使用NetApp Snapshot、 SnapRestore和FlexClone技術備份、還原和複製 Hadoop 資料。</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">透過使用SnapMirror技術，Hadoop 資料可以受到保護，保存到雲端以及災難復原位置。</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">解決方案A的優點包括：</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop 生產資料受到備份叢集的保護。</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS 資料透過 NFS 進行保護，從而實現對雲端和災難復原位置的保護。</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">透過將備份作業卸載到備份叢集來提高效能。</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">消除手動磁帶操作</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">允許透過NetApp工具實現企業管理功能。</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">只需對現有環境進行最少的改變。</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">是一種經濟有效的解決方案。</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">該解決方案的缺點是它需要備份叢集和額外的映射器來提高效能。</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">客戶最近部署了解決方案 A，因為它簡單、成本低且整體效能好。</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">在此解決方案中，可以使用ONTAP的 SAN 磁碟取代 JBOD。此選項將備份叢集儲存負載轉移至ONTAP；但缺點是需要 SAN 結構交換器。</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">解決方案 B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">解決方案B將NFS卷添加到生產Hadoop集群，從而無需備份Hadoop集群，如下圖所示。</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">解決方案B的詳細任務包括：</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAP儲存控制器將 NFS 匯出配置到生產 Hadoop 叢集。</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">Hadoop 原生<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>指令將 Hadoop 資料從生產叢集 HDFS 保護到 NFS。</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">將資料儲存在NetApp儲存系統的NFS中後，依需求使用Snapshot、 SnapRestore、 FlexClone技術對Hadoop資料進行備份、復原、複製。</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">解決方案B的優點包括：</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">生產叢集針對備份解決方案進行了輕微修改，簡化了實施並降低了額外的基礎設施成本。</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">備份作業不需要備份叢集。</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS 生產資料在轉換為 NFS 資料時受到保護。</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">該解決方案允許透過NetApp工具實現企業管理功能。</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">此解決方案的缺點是它是在生產叢集中實現的，這會在生產叢集中增加額外的管理員任務。</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">解決方案 C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">在解決方案 C 中， NetApp SAN 磁碟區直接配置到 Hadoop 生產叢集用於 HDFS 存儲，如下圖所示。</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">解決方案C的詳細步驟包括：</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN 儲存在生產 Hadoop 叢集中配置用於 HDFS 資料儲存。</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot 和SnapMirror技術用於備份生產 Hadoop 叢集的 HDFS 資料。</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">由於備份位於儲存層，因此 Snapshot 複製備份過程中不會對 Hadoop/Spark 叢集的生產效能產生影響。</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">快照技術可提供在幾秒鐘內完成的備份，無論資料大小如何。</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">解決方案C的優點包括：</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">可以使用快照技術建立節省空間的備份。</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">在這種用例中，客戶的要求是基於現有的 Hadoop 集群快速有效地建立新的 Hadoop/Spark 集群，該集群包含大量用於同一資料中心和遠端位置的開發測試和報告目的的分析資料。</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">用例 3：在現有 Hadoop 資料上啟用 DevTest</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">在這種情況下，從本地以及災難復原位置的大型 Hadoop 資料湖實作建置多個 Spark/Hadoop 叢集。</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">為 DevTest、QA 或任何其他需要存取相同生產資料的目的建立多個 Hadoop 叢集。這裡的挑戰是以非常節省空間的方式瞬間多次克隆一個非常大的 Hadoop 叢集。</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">將 Hadoop 資料同步到 DevTest 和報告團隊以提高營運效率。</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">在生產和新叢集中使用相同的憑證分發 Hadoop 資料。</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">使用調度策略有效率地建立QA集群，而不影響生產集群。</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone技術用於滿足剛才所述的要求。 FlexClone技術是 Snapshot 副本的讀/寫副本。它從父 Snapshot 副本數據中讀取數據，並且僅為新/修改的區塊消耗額外的空間。它速度快並且節省空間。</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">首先，使用NetApp一致性群組建立現有叢集的 Snapshot 副本。</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">NetApp系統管理員或儲存管理提示中的快照副本。一致性群組Snapshot副本是應用程式一致性群組Snapshot副本， FlexClone磁碟區是基於一致性群組Snapshot副本建立的。值得一提的是， FlexClone磁碟區繼承了父磁碟區的 NFS 導出策略。建立 Snapshot 副本後，必須安裝一個新的 Hadoop 叢集以用於 DevTest 和報告目的，如下圖所示。來自新 Hadoop 叢集的克隆 NFS 磁碟區存取 NFS 資料。</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">此圖顯示了 DevTest 的 Hadoop 叢集。</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">此用例與負責為客戶的大數據分析資料提供多雲連接的雲端服務合作夥伴相關。</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">用例 4：資料保護和多雲連接</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">在這種情況下，AWS 從不同來源接收的物聯網資料儲存在 NPS 的中心位置。  NPS 儲存連接到位於 AWS 和 Azure 的 Spark/Hadoop 集群，使在多個雲端中運行的大數據分析應用程式能夠存取相同的資料。</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">客戶希望使用多個雲端對相同資料運行分析作業。</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">必須透過不同的感測器和集線器從不同來源（例如本地和雲端）接收資料。</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">該解決方案必須高效且具有成本效益。</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">主要挑戰是建立一個經濟高效的解決方案，在本地和不同雲端之間提供混合分析服務。</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">此圖說明了資料保護和多雲連接解決方案。</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">如上圖所示，來自感測器的資料透過 Kafka 串流並輸入到 AWS Spark 叢集中。資料儲存在 NPS 中的 NFS 共用中，NPS 位於 Equinix 資料中心內的雲端供應商之外。由於NetApp NPS 分別透過 Direct Connect 和 Express Route 連線連接到 Amazon AWS 和 Microsoft Azure，因此客戶可以從 Amazon 和 AWS 分析叢集存取 NFS 資料。這種方法解決了跨多個超大規模器的雲端分析問題。</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">因此，由於內部部署和 NPS 儲存都運行ONTAP軟體， SnapMirror可以將 NPS 資料鏡像到內部部署叢集中，從而提供跨內部部署和多個雲端的混合雲分析。</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">為了獲得最佳效能， NetApp通常建議使用多個網路介面和直接連接/快速路由來存取雲端實例的資料。</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">本節對資料保護用例進行了高層描述，這是本文的重點。其餘部分為每個用例提供了更多詳細信息，例如客戶問題（場景）、要求和挑戰以及解決方案。</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop 資料保護案例概述</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">對於此用例， NetApp NFS 磁碟區可協助一家大型金融機構將長備份視窗時間從 24 多個小時縮短至數小時。</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">透過使用NetApp支援的資料結構作為建置模組，一家大型廣播公司能夠根據不同的資料傳輸模式（例如按需、即時或基於 Hadoop/Spark 叢集負載）滿足將雲端資料備份到其內部資料中心的需求。</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">NetApp解決方案可協助線上音樂經銷商在不同分支機構快速建立多個節省空間的 Hadoop 集群，以建立報告並透過使用規劃策略運行日常 DevTest 任務。</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">一家大型服務供應商使用由NetApp支援的資料結構從不同的雲端實例為其客戶提供多雲分析。</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">一家最大的金融服務和投資銀行使用NetApp網路附加儲存解決方案來減少 I/O 等待時間並加速其定量金融分析平台。</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">本節介紹了從此次認證中獲得的經驗教訓。</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">最佳實踐指南</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">根據我們的驗證，S3 物件儲存最適合 Confluent 保存資料。</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">我們可以使用高吞吐量 SAN（特別是 FC）來保存代理熱資料或本機磁碟，因為在 Confluent 分層儲存配置中，代理資料目錄中儲存的資料大小取決於資料移至物件儲存時的段大小和保留時間。</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">當segment.bytes較高時，物件儲存提供更好的效能；我們測試了512MB。</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">在 Kafka 中，主題中產生的每個記錄的鍵或值的長度（以位元組為單位）由<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>範圍。對於StorageGRID，S3 物件提取和檢索效能提升到更高的值。例如，512 位元組提供 5.8GBps 的檢索，1024 位元組提供 7.5GBps 的 s3 檢索，而 2048 位元組提供接近 10GBps 的檢索。</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">下圖展示了基於<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>。</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">Kafka 調優。為了提高分層儲存的效能，可以增加 TierFetcherNumThreads 和 TierArchiverNumThreads。作為一般準則，您需要增加 TierFetcherNumThreads 以匹配實體 CPU 核心的數量，並將 TierArchiverNumThreads 增加到 CPU 核心數量的一半。例如，在伺服器屬性中，如果您有一台具有八個實體核心的機器，請設定 confluent.tier.fetcher.num.threads = 8 和 confluent.tier.archiver.num.threads = 4。</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*主題刪除的時間間隔*當主題被刪除時，物件儲存中的日誌段檔案的刪除不會立即開始。相反，在刪除這些文件之前有一個預設值為 3 小時的時間間隔。您可以修改配置 confluent.tier.topic.delete.check.interval.ms 來變更此間隔的值。如果刪除主題或集群，您也可以手動刪除相應儲存桶中的物件。</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*分層儲存內部主題的 ACL。 *對於內部部署，建議的最佳實踐是在用於分層儲存的內部主題上啟用 ACL 授權器。設定 ACL 規則以限制只有代理使用者才能存取此資料。這可以保護內部主題並防止未經授權存取分層儲存資料和元資料。</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">替換用戶<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block>與您部署中的實際代理主體一起。</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">例如，命令<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block>設定內部主題的 ACL 以進行分層儲存。目前，只有一個與分層儲存相關的內部主題。此範例建立了一個 ACL，為內部主題上的所有操作提供主要的 Kafka 權限。</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">我們已經對帶有 Kafka 的 Confluent Platform 進行了認證，用於NetApp StorageGRID中的分層儲存。</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">匯合驗證</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">我們使用NetApp StorageGRID中的 Confluent Platform 6.2 Tiered Storage 進行了驗證。  NetApp和 Confluent 團隊共同進行了此次驗證，並運行了驗證所需的測試案例。</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Confluent 平台設置</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">我們使用以下設定進行驗證。</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">為了驗證，我們使用了三個 zookeeper、五個 broker、五個測試腳本執行伺服器、命名工具伺服器（配備 256GB RAM 和 16 個 CPU）。對於NetApp存儲，我們使用了具有四個 SGF6024 的 SG1000 負載平衡器的StorageGRID 。儲存和代理程式透過 100GbE 連線進行連線。</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">下圖顯示了用於 Confluent 驗證的配置的網路拓撲。</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">工具伺服器充當向 Confluent 節點發送請求的應用程式用戶端。</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Confluent 分層儲存配置</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">分層儲存配置在Kafka中需要以下參數：</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">為了驗證，我們使用了具有 HTTP 協定的StorageGRID ，但 HTTPS 也可以使用。存取密鑰和密鑰儲存在<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block>範圍。</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetApp物件儲存 - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">我們在StorageGRID中配置了單一站點配置以進行驗證。</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">驗證測試</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">我們完成了以下五個測試案例進行驗證。這些測試在 Trogdor 框架上執行。前兩個是功能測試，其餘三個是效能測試。</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">物件儲存正確性測試</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">此測試確定物件儲存 API 上的所有基本操作（例如，取得/放置/刪除）是否根據分層儲存的需求正常運作。這是每個物件儲存服務都應該在後續測試之前通過的基本測試。這是一個要么通過要么失敗的斷言測試。</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">分層功能正確性測試</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">此測試通過或失敗的斷言測試來確定端到端分層儲存功能是否運作良好。該測試創建了一個測試主題，該主題預設配置為啟用分層，並且熱集大小大大減少。它為新建立的測試主題產生一個事件流，等待代理將段存檔到物件存儲，然後使用事件流並驗證所消耗的流是否與產生的流相符。向事件流產生的訊息數量是可配置的，這使得使用者可以根據測試的需要產生足夠大的工作量。減少的熱集大小可確保活動段之外的消費者提取僅從物件儲存中提供；這有助於測試物件儲存讀取的正確性。我們已經在有和沒有物件儲存故障注入的情況下執行了此測試。我們透過停止StorageGRID中某個節點的服務管理器服務來模擬節點故障，並驗證端對端功能是否與物件儲存相容。</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">層級獲取基準</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">此測試驗證了分層物件儲存的讀取效能，並檢查了基準測試產生的段在高負載下的範圍提取讀取請求。在這個基準測試中，Confluent 開發了自訂客戶端來滿足層級取得請求。</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">生產-消費性工作負載基準測試</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">此測試透過段歸檔間接產生物件儲存上的寫入工作負載。當消費者群體取得段時，從物件儲存產生讀取工作負載（讀取的段）。此工作負載由測試腳本產生。該測試檢查了並行執行緒對物件儲存的讀寫效能。我們對分層功能正確性測試進行了測試，測試了有和沒有物件儲存故障注入的情況。</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">保留工作量基準</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">此測試檢查了物件儲存在繁重的主題保留工作負載下的刪除效能。保留工作負載是使用測試腳本產生的，該腳本與測試主題並行產生許多訊息。測試主題是使用基於大小和基於時間的激進保留設定進行配置，這會導致事件流不斷從物件儲存中清除。然後將這些片段存檔。這導致代理在物件儲存中執行大量刪除操作，並收集物件儲存刪除操作的效能。</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">什麼是 Apache Kafka？</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">什麼是愚蠢的重命名？</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP 用於串流應用程式。</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">NetApp產品文檔</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">什麼是 NFS？</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">什麼是 Kafka 分區重新分配？</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">什麼是 OpenMessaging 基準？</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">如何遷移 Kafka 代理？</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">如何使用 Prometheus 監控 Kafka 代理程式？</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Apache Kafka 託管平台</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">支援 Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Apache Kafka 諮詢服務</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">NetApp針對愚蠢重命名問題的解決方案為先前與 NFS 不相容的工作負載提供了一種簡單、廉價且集中管理的儲存形式。</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">這種新模式使客戶能夠創建更易於管理的 Kafka 集群，這些集群更易於遷移和鏡像，以實現災難復原和資料保護。我們還看到 NFS 提供了其他好處，例如降低 CPU 使用率和加快恢復時間、顯著提高儲存效率以及透過NetApp ONTAP實現更好的效能。</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">本文檔描述了以下主題：愚蠢的重命名問題和解決方案驗證、降低 CPU 使用率以減少 I/O 等待時間、加快 Kafka 代理恢復時間以及雲端和本地的效能。</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947：使用NetApp NFS 儲存的 Apache Kafka 工作負載 - 功能驗證與效能</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole、Karthikeyan Nagalingam 和 Joe Scott， NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka 是一個分散式發布-訂閱訊息系統，具有強大的佇列，可以接受大量訊息資料。使用 Kafka，應用程式可以非常快速地向主題寫入和讀取資料。由於其容錯性和可擴展性，Kafka 經常被用在大數據領域，作為一種可靠的方式來快速提取和移動大量資料流。使用案例包括串流處理、網站活動追蹤、指標收集和監控、日誌聚合、即時分析等。</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">這裡</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">儘管 NFS 上的正常 Kafka 操作運作良好，但在 NFS 上執行的 Kafka 叢集調整大小或重新分割期間，愚蠢的重命名問題會導致應用程式崩潰。這是一個重大問題，因為必須調整 Kafka 叢集的大小或重新分區以實現負載平衡或維護目的。您可以找到更多詳細信息<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block>。</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">本文檔描述了以下主題：</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">愚蠢的重命名問題和解決方案驗證</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">降低 CPU 使用率以減少 I/O 等待時間</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">更快的 Kafka 代理程式恢復時間</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">雲端和本地的效能</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">為什麼使用 NFS 儲存來儲存 Kafka 工作負載？</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">生產應用程式中的 Kafka 工作負載可以在應用程式之間傳輸大量資料。這些資料保存並儲存在 Kafka 叢集中的 Kafka 代理節點中。 Kafka 也以可用性和並行性而聞名，它透過將主題分成多個分區，然後在整個叢集中複製這些分區來實現。這最終意味著流經 Kafka 群集的大量資料通常會倍增。隨著代理數量的變化，NFS 可以非常快速且輕鬆地重新平衡資料。對於大型環境，當代理數量發生變化時，跨 DAS 重新平衡資料非常耗時，並且在大多數 Kafka 環境中，代理數量經常會發生變化。</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">其他好處包括：</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*到期。 *  NFS 是一種成熟的協議，這意味著它的實現、保護和使用的大多數方面都已被很好地理解。</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*打開。 *  NFS 是一個開放協議，其持續發展在互聯網規範中被記錄為一個自由開放的網路協議。</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*具有成本效益。 *  NFS 是一種低成本的網路檔案共用解決方案，由於它使用現有的網路基礎設施，因此易於設定。</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*集中管理。 *  NFS 的集中管理減少了單一使用者係統上新增軟體和磁碟空間的需求。</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*分散式。 *  NFS 可用作分散式檔案系統，減少可移動媒體儲存設備的需求。</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">為什麼選擇NetApp來處理 Kafka 工作負載？</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">NetApp NFS 實施被認為是該協議的黃金標準，並應用於無數企業 NAS 環境。除了NetApp的信譽之外，它還提供以下優勢：</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">可靠性和效率</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">可擴充性和效能</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">高可用性（ NetApp ONTAP叢集中的 HA 合作夥伴）</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">資料保護</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">災難復原（NetApp SnapMirror）。 *您的網站癱瘓了，或者您想從另一個網站開始並從上次中斷的地方繼續。</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">儲存系統的可管理性（使用NetApp OnCommand進行管理）。</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*負載平衡。 *此叢集可讓您從託管在不同節點上的資料 LIF 存取不同的磁碟區。</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*無中斷運作。 *  LIF 或磁碟區移動對於 NFS 用戶端來說是透明的。</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">在本地，我們使用具有ONTAP 9.12.1RC1 的NetApp AFF A900儲存控制器來驗證 Kafka 叢集的效能和擴充。我們使用了與先前的ONTAP和AFF分層儲存最佳實踐相同的測試平台。</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">本地AFF A900的效能概述與驗證</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">在本地，我們使用具有ONTAP 9.12.1RC1 的NetApp AFF A900儲存控制器來驗證 Kafka 叢集的效能和擴展性。我們使用了與先前的ONTAP和AFF分層儲存最佳實踐相同的測試平台。</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">我們使用 Confluent Kafka 6.2.0 來評估AFF A900。該叢集有八個代理節點和三個 zookeeper 節點。為了進行效能測試，我們使用了五個 OMB 工作節點。</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">儲存配置</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">我們使用NetApp FlexGroups 實例為日誌目錄提供單一命名空間，從而簡化復原和配置。我們使用 NFSv4.1 和 pNFS 來提供對日誌段資料的直接路徑存取。</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">客戶端調優</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">每個客戶端使用以下命令掛載FlexGroup實例。</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">此外，我們增加了<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block>從預設<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block>到<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block>。這與ONTAP中的預設會話槽限制相符。</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Kafka 代理調優</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">為了最大限度地提高測試系統的吞吐量，我們顯著增加了某些關鍵線程池的預設參數。對於大多數配置，我們建議遵循 Confluent Kafka 最佳實踐。此調整用於最大化儲存的未完成 I/O 的並發性。這些參數可以進行調整以符合您的代理程式的運算資源和儲存屬性。</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">工作負載產生器測試方法</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">我們對吞吐量驅動程式和主題配置使用了與雲端測試相同的 OMB 配置。</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">使用 Ansible 在AFF叢集上設定了FlexGroup實例。</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">ONTAP SVM 上已啟用 pNFS。</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">工作負載由吞吐量驅動程式觸發，使用與Cloud Volumes ONTAP相同的工作負載配置。請參閱“<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> “ 以下。工作負載使用的複製因子為 3，這表示在 NFS 中維護了三個日誌段副本。</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">最後，我們使用積壓完成了測量，以衡量消費者趕上最新消息的能力。 OMB 透過在測量開始時暫停消費者來建立積壓。這會產生三個不同的階段：積壓創建（僅生產者的流量）、積壓消耗（消費者密集的階段，其中消費者追趕主題中錯過的事件）和穩定狀態。請參閱“<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block> ”獲取更多資訊。</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">穩態性能</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">我們使用 OpenMessaging Benchmark 評估了AFF A900 ，以提供與 AWS 中的Cloud Volumes ONTAP和 AWS 中的 DAS 類似的比較。所有效能值代表生產者和消費者層級的 Kafka 叢集吞吐量。</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">Confluent Kafka 和AFF A900的穩定狀態效能為生產者和消費者實現了超過 3.4GBps 的平均吞吐量。 Kafka 叢集中的訊息超過 340 萬條。透過以每秒位元組數為單位視覺化 BrokerTopicMetrics 的持續吞吐量，我們可以看到AFF A900支援的出色穩定狀態效能和流量。</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">此圖顯示了代理網路吞吐量。</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">這與按主題傳遞的訊息的視圖非常一致。下圖提供了按主題的細分情況。在測試的配置中，我們看到四個主題中每個主題有近 90 萬個訊息。</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">極致效能與探索儲存極限</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">對於AFF，我們也使用積壓功能對 OMB 進行了測試。當 Kafka 叢集中累積了大量事件積壓時，積壓功能會暫停消費者訂閱。在此階段，僅發生生產者流量，產生提交到日誌的事件。這最接近地模擬了批次或離線分析工作流程；在這些工作流程中，消費者訂閱已啟動，並且必須讀取已從代理快取中逐出的歷史資料。</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">為了了解此配置中儲存對消費者吞吐量的限制，我們測量了僅生產者階段，以了解 A900 可以吸收多少寫入流量。請參閱下一節“<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block> 「來了解如何利用這些數據。</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">在本次測量的僅生產者部分，我們看到了高峰值吞吐量，突破了 A900 效能的極限（當其他代理資源未飽和地為生產者和消費者流量提供服務時）。</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">我們將此測量的訊息大小增加到 16k，以限制每個訊息的開銷並最大化 NFS 掛載點的儲存吞吐量。</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Confluent Kafka 叢集實現了 4.03GBps 的峰值生產者吞吐量。</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">OMB 完成填入事件積壓日誌後，消費者流量重新啟動。在積壓工作消耗的測量過程中，我們觀察到所有主題的峰值消費者吞吐量超過 20GBps。儲存 OMB 日誌資料的 NFS 磁碟區的組合吞吐量接近 ~30GBps。</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">尺寸指南</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">尺寸指南</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">亞馬遜網路服務提供<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block>用於 Kafka 叢集大小調整和擴展。</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">此大小提供了一個有用的公式來確定 Kafka 叢集的儲存吞吐量需求：</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">對於複製因子為 r 的 tcluster 叢集產生的聚合吞吐量，代理儲存收到的吞吐量如下：</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">這可以進一步簡化：</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">使用此公式，您可以根據 Kafka 熱層需求選擇合適的ONTAP平台。</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">下表解釋了具有不同複製因子的 A900 的預期生產者吞吐量：</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">複製因子</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">生產者吞吐量 (GPps)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3（測量）</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3.4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10.2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">在NetApp NFS 上安裝儲存層的 Kafka 叢集在 AWS 雲端進行了效能基準測試。基準測試範例在以下章節中說明。</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">AWS FSx ONTAP中的效能概述與驗證</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">在NetApp NFS 上安裝儲存層的 Kafka 叢集在 AWS FSx ONTAP中進行了效能基準測試。基準測試範例在以下章節中說明。</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">AWS FSx ONTAP中的 Apache Kafka</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">網路檔案系統 (NFS) 是一種廣泛用於儲存大量資料的網路檔案系統。在大多數組織中，資料越來越多地由 Apache Kafka 等串流應用程式產生。這些工作負載需要可擴展性、低延遲以及具有現代儲存功能的強大資料擷取架構。為了實現即時分析並提供可操作的見解，需要精心設計且高效能的基礎架構。</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">Kafka 在設計上與 POSIX 相容的檔案系統協同工作，並依賴該檔案系統來處理檔案操作，但是在 NFSv3 檔案系統上儲存資料時，Kafka 代理程式 NFS 用戶端可以以不同於 XFS 或 Ext4 等本機檔案系統的方式解釋檔案操作。一個常見的例子是 NFS Silly 重新命名，它導致 Kafka 代理在擴展叢集和重新分配分區時失敗。為了應對這項挑戰， NetApp更新了開源 Linux NFS 用戶端，這些變更現在已在 RHEL8.7、RHEL9.1 中普遍可用，並且從目前 FSx ONTAP版本ONTAP 9.12.1 開始受支援。</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">Amazon FSx ONTAP在雲端提供完全託管、可擴展且高效能的 NFS 檔案系統。  FSx ONTAP上的 Kafka 資料可以擴展以處理大量資料並確保容錯能力。  NFS 為關鍵和敏感資料集提供集中儲存管理和資料保護。</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">這些增強功能使 AWS 客戶能夠在 AWS 運算服務上執行 Kafka 工作負載時利用 FSx ONTAP 。這些好處是：* 降低 CPU 使用率以減少 I/O 等待時間* 更快的 Kafka 代理程式恢復時間。  * 可靠性和效率。  * 可擴展性和效能。  * 多可用區域可用性。  * 資料保護。</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">AWS FSx ONTAP中的 Kafka</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">使用 AWS FSx ONTAP 的Kafka 叢集在 AWS 雲端中進行了效能基準測試。以下章節描述了此基準測試。</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">建築設置</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">下表顯示了使用 AWS FSx ONTAP 的Kafka 叢集的環境配置。</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">平台組件</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">環境配置</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">卡夫卡 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 位動物園管理員 – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 個代理伺服器 – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xlarge</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x 生產者/消費者 -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">所有節點上的作業系統</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">多可用區，吞吐量 4GB/秒，IOPS 160000</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">NetApp FSx ONTAP設定</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">在我們的初步測試中，我們建立了一個容量為 2TB、吞吐量為 40000 IOP 的 FSx ONTAP檔案系統，吞吐量為 2GB/秒。</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">在我們的範例中，我們透過 AWS CLI 部署 FSx ONTAP 。您將需要根據需要在您的環境中進一步自訂命令。  FSx ONTAP還可以透過 AWS 控制台進行部署和管理，從而透過更少的命令列輸入獲得更輕鬆、更簡化的部署體驗。</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">文件在 FSx ONTAP中，我們測試區域（US-East-1）中 2GB/秒吞吐量檔案系統可實現的最大 IOPS 為 80,000 iops。  FSx ONTAP檔案系統的最大總 iops 為 160,000 iops，需要 4GB/秒的吞吐量部署才能實現，我們將在本文檔的後面進行演示。</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">有關 FSx ONTAP性能規格的更多信息，請隨時訪問此處的 AWS FSx ONTAP文件：<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> 。</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">FSx「create-file-system」的詳細命令列語法可以在這裡找到：<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">例如，您可以指定特定的 KMS 金鑰，而不是在未指定 KMS 金鑰時使用的預設 AWS FSx 主金鑰。</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">在建立 FSx ONTAP檔案系統時，請按照以下方式描述您的檔案系統，等待 JSON 返回中的「LifeCycle」狀態變為「AVAILABLE」：</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">透過使用 fsxadmin 使用者登入 FSx ONTAP SSH 來驗證憑證：Fsxadmin 是 FSx ONTAP檔案系統建立時的預設管理員帳戶。  fsxadmin 的密碼是首次在 AWS 主控台或使用 AWS CLI 建立檔案系統時所配置的密碼，如我們在步驟 1 中完成的密碼，如我們在步驟 1 中完成的密碼。</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">驗證您的憑證後，在 FSx ONTAP檔案系統上建立儲存虛擬機</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">儲存虛擬機器 (SVM) 是一個獨立的檔案伺服器，具有自己的管理憑證和端點，用於管理和存取 FSx ONTAP磁碟區中的數據，並提供 FSx ONTAP多租用戶。</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">配置好主儲存虛擬機器後，透過 SSH 進入新建立的 FSx ONTAP檔案系統，並使用下列範例命令在儲存虛擬機器中建立卷，同樣，我們為此驗證會建立 6 個磁碟區。根據我們的驗證，保留預設成分（8）或更少的成分將為 kafka 提供更好的性能。</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">我們的測試需要額外的容量。將磁碟區的大小擴展至 2TB 並安裝在連線路徑上。</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">在 FSx ONTAP中，磁碟區可以進行精簡配置。在我們的範例中，擴充磁碟區的總容量超過了檔案系統的總容量，因此我們需要擴展檔案系統的總容量以解鎖額外的預配置磁碟區容量，我們將在下一步中示範這一點。</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">接下來，為了提高效能和容量，我們將 FSx ONTAP吞吐容量從 2GB/秒擴展到 4GB/秒，IOPS 擴展到 160000，容量擴展到 5 TB</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">FSx「update-file-system」的詳細命令列語法可以在這裡找到：<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">FSx ONTAP磁碟區透過 nconnect 和 Kafka 代理程式中的預設選項進行掛載</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">下圖展示了我們基於 FSx ONTAP 的Kafka 叢集的最終架構：</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">此圖顯示了基於 FSx ONTAP的 Kafka 叢集的架構。</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">計算。我們使用了三節點 Kafka 集群，並在專用伺服器上運行三節點 zookeeper 集合。每個代理程式有六個 NFS 掛載點，分別指向 FSx ONTAP實例上的六個磁碟區。</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">監控。我們使用兩個節點來實現 Prometheus-Grafana 組合。為了產生工作負載，我們使用了一個單獨的三節點集群，該集群可以為該 Kafka 集群生產和消費。</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">貯存。我們使用了安裝了六個 2TB 磁碟區的 FSx ONTAP 。然後將該磁碟區匯出到具有 NFS 掛載的 Kafka 代理程式。 FSx ONTAP磁碟區在 Kafka 代理程式中安裝了 16 個 nconnect 會話和預設選項。</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">OpenMessage 基準測試配置。</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">我們使用了與NetApp Cloud Volumes ONTAP相同的配置，其詳細資訊請參閱此處 - link:kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">測試方法</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">根據上面描述的規範，使用 terraform 和 ansible 配置了 Kafka 叢集。  Terraform 用於使用 AWS 執行個體為 Kafka 叢集建置基礎設施，並且 ansible 在其上建置 Kafka 叢集。</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">使用上面描述的工作負載配置和同步驅動程式觸發了 OMB 工作負載。</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">使用具有相同工作負載配置的吞吐量驅動程式觸發了另一個工作負載。</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">觀察</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">使用兩種不同類型的驅動程式來產生工作負載，以對在 NFS 上執行的 Kafka 執行個體的效能進行基準測試。驅動程式之間的差異在於日誌刷新屬性。</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">對於 Kafka 複製因子 1 和 FSx ONTAP：</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">同步驅動程式持續產生的總吞吐量：~ 3218 MBps，峰值效能約為 3652 MBps。</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">吞吐量驅動程式持續產生的總吞吐量：~ 3679 MBps，峰值效能為 ~ 3908 MBps。</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">對於複製因子為 3 且具有 FSx ONTAP 的Kafka：</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">同步驅動程式持續產生的總吞吐量：~ 1252 MBps，峰值效能約為 1382 MBps。</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">吞吐量驅動程式持續產生的總吞吐量：~ 1218 MBps，峰值效能約為 1328 MBps。</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">在 Kafka 複製因子 3 中，讀寫操作在 FSx ONTAP上發生了三次，在 Kafka 複製因子 1 中，讀寫操作在 FSx ONTAP上發生了一次，因此在兩種驗證中，我們都能夠達到 4GB/秒的最大吞吐量。</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">由於日誌會立即刷新到磁碟，因此同步驅動程式可以產生一致的吞吐量，而由於日誌會批次提交到磁碟，因此吞吐量驅動程式會產生突發性的吞吐量。</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">這些吞吐量數字是針對給定的 AWS 配置產生的。對於更高的效能要求，可以擴大實例類型並進一步調整以獲得更好的吞吐量數字。總吞吐量或總速率是生產者和消費者速率的組合。</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">此圖顯示了 Kafka 與 RF1 和 RF3 的效能</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">下圖顯示了 Kafka 複製因子 3 的 2GB/秒 FSx ONTAP和 4GB/秒效能。複製因子 3 在 FSx ONTAP儲存上執行三次讀寫操作。吞吐量驅動程式的總速率為 881 MB/秒，在 2GB/秒 FSx ONTAP檔案系統上以大約 2.64 GB/秒的速度讀取和寫入 Kafka 操作，吞吐量驅動程式的總速率為 1328 MB/秒，以大約 3.98 GB/秒的速度讀取和寫入 kafka 操作。  Kafka 效能是線性的，並且基於 FSx ONTAP吞吐量可擴充。</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">此圖顯示了 2GB/秒和 4GB/秒的擴充效能。</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">下圖顯示了 EC2 執行個體與 FSx ONTAP之間的效能（Kafka 複製因子：3）</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">此圖顯示了 EC2 與 FSx ONTAP在 RF3 中的效能比較。</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">AWS 中的效能概述和驗證</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">AWS 雲端中的 Kafka 與NetApp Cloud Volumes ONTAP （高可用性對和單節點）</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">對具有NetApp Cloud Volumes ONTAP （HA 對）的 Kafka 叢集在 AWS 雲端中進行了效能基準測試。以下章節描述了此基準測試。</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">下表展示了使用NAS的Kafka叢集的環境配置。</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">NetApp Cloud Volumes ONTAP實例</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">HA 對實例 – m5dn.12xLarge x 2node 單節點實例 - m5dn.12xLarge x 1 節點</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">NetApp叢集磁碟區ONTAP設定</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">對於Cloud Volumes ONTAP HA 對，我們建立了兩個聚合，每個儲存控制器上的每個聚合上有三個磁碟區。對於單一Cloud Volumes ONTAP節點，我們在一個聚合中建立六個磁碟區。</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">該圖描繪了 aggr3 和 aggr22 的屬性。</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">該圖描繪了 aggr2 的屬性。</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">為了實現更好的網路效能，我們為 HA 對和單一節點都啟用了高速網路。</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">此圖顯示如何實現高速網路。</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">我們注意到ONTAP NVRAM具有更多的 IOPS，因此我們將Cloud Volumes ONTAP根磁碟區的 IOPS 變更為 2350。 Cloud Volumes ONTAP中的根磁碟區大小為 47GB。以下ONTAP指令適用於 HA 對，相同步驟也適用於單一節點。</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">此圖顯示如何修改磁碟區屬性。</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">下圖是基於NAS的Kafka叢集架構圖。</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*計算。 *我們使用了三節點 Kafka 集群，並在專用伺服器上運行三節點 zookeeper 集合。每個代理程式透過專用 LIF 擁有兩個指向Cloud Volumes ONTAP實例上的單一磁碟區的 NFS 掛載點。</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*監控*我們使用兩個節點來實現 Prometheus-Grafana 組合。為了產生工作負載，我們使用了一個單獨的三節點集群，該集群可以為該 Kafka 集群生產和消費。</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*貯存。 *我們使用了 HA 對 Cloud Volumes ONTAP實例，並在該實例上安裝了一個 6TB GP3 AWS-EBS 磁碟區。然後透過 NFS 掛載將該磁碟區匯出到 Kafka 代理程式。</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">該圖描繪了基於 NAS 的 Kafka 叢集的架構。</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">OpenMessage 基準測試配置</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">為了獲得更好的 NFS 效能，我們需要在 NFS 伺服器和 NFS 用戶端之間建立更多的網路連接，可以使用 nconnect 建立。透過執行下列命令，使用 nconnect 選項將 NFS 磁碟區掛載到代理節點上：</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">檢查Cloud Volumes ONTAP中的網路連線。下列ONTAP指令從單一Cloud Volumes ONTAP節點使用。相同的步驟適用於Cloud Volumes ONTAP HA 對。</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">我們使用以下 Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>在Cloud Volumes ONTAP HA 對的所有 Kafka 代理中。這<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>屬性對每個經紀人都是不同的，其餘屬性對經紀人來說是共同的。對於 broker1 來說，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>值如下：</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">對於 broker2，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>屬性值如下：</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">對於 broker3，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>屬性值如下：</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">對於單一Cloud Volumes ONTAP節點，Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block>與Cloud Volumes ONTAP HA 對相同，但<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>財產。</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">對於 broker1 來說，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>值如下：</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">對於 broker2，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>值如下：</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">OMB 中的工作負載配置有以下屬性：<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> 。</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">這<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block>根據每個用例可能會有所不同。在我們的效能測試中，我們使用了 3K。</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">我們使用了來自 OMB 的兩個不同的驅動程式（Sync 或 Throughput）來在 Kafka 叢集上產生工作負載。</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">用於同步驅動程式屬性的 yaml 檔案如下<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block>：</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">用於吞吐量驅動程式屬性的 yaml 檔案如下<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block>：</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">根據上面描述的規範，使用 Terraform 和 Ansible 配置了 Kafka 叢集。  Terraform 用於使用 AWS 執行個體為 Kafka 叢集建置基礎設施，Ansible 在其上建置 Kafka 叢集。</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">對於Cloud Volumes ONTAP HA 對：</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">同步驅動程式持續產生的總吞吐量：~1236 MBps。</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">吞吐量驅動程式產生的總吞吐量：峰值~1412 MBps。</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">對於單一Cloud Volumes ONTAP節點：</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">同步驅動程式持續產生的總吞吐量：~ 1962MBps。</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">吞吐量驅動程式產生的總吞吐量：峰值~1660MBps</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">這裡展示了四種不同的圖表。  CVO-HA 對吞吐量驅動程式。  CVO-HA 對同步驅動器。  CVO-單節點吞吐量驅動器。  CVO-單節點同步磁碟機。</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">在執行吞吐量或同步驅動程式基準測試時，請務必檢查儲存吞吐量。</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">此圖顯示了延遲、IOPS 和吞吐量的效能。</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">本節描述了愚蠢的重命名問題以及 NFS 伺服器和 NFS 用戶端為解決該問題所需的變更。</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">NetApp針對 NFS 到 Kafka 工作負載重新命名問題的解決方案</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka 的建置假設底層檔案系統符合 POSIX 標準：例如 XFS 或 Ext4。當應用程式仍在使用檔案時，Kafka 資源重新平衡會刪除這些檔案。符合 POSIX 標準的檔案系統允許取消連結繼續進行。但是，只有在對該文件的所有引用都消失後，它才會刪除該文件。如果底層檔案系統是網路連線的，那麼 NFS 用戶端會攔截取消連結呼叫並管理工作流程。由於正在取消連結的檔案上有待開啟的操作，因此 NFS 用戶端會向 NFS 伺服器發送重新命名請求，並在最後一次關閉取消連結的檔案時，會對重新命名的檔案發出刪除操作。此行為通常稱為 NFS 愚蠢重命名，由 NFS 用戶端精心策劃。</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">由於這種行為，任何使用 NFSv3 伺服器儲存的 Kafka 代理都會遇到問題。但是，NFSv4.x 協定具有解決此問題的功能，它允許伺服器負責開啟的未連結的檔案。支援此可選功能的 NFS 伺服器在開啟檔案時將所有權能力傳達給 NFS 用戶端。當有待處理的開啟操作時，NFS 用戶端將停止取消連結管理，並允許伺服器管理流程。儘管 NFSv4 規範提供了實作指南，但到目前為止，還沒有任何已知的 NFS 伺服器實作支援此選用功能。</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">為了解決這個愚蠢的重命名問題，需要對 NFS 伺服器和 NFS 用戶端進行以下更改：</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*對 NFS 用戶端 (Linux) 的變更。 *在開啟檔案時，NFS 伺服器會回應一個標誌，表示有能力處理開啟檔案的取消連結。  NFS 用戶端的變更允許 NFS 伺服器在存在標誌的情況下處理取消連結。 NetApp已根據這些變更更新了開源 Linux NFS 用戶端。更新後的 NFS 用戶端現已在 RHEL8.7 和 RHEL9.1 中普遍可用。</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*對 NFS 伺服器的變更。 * NFS 伺服器追蹤開啟的情況。現在，伺服器管理對現有開啟檔案的取消連結以符合 POSIX 語義。當最後一個開啟的檔案關閉時，NFS 伺服器將啟動檔案的實際刪除，從而避免愚蠢的重命名過程。  ONTAP NFS 伺服器在其最新版本ONTAP 9.12.1 中實作了此功能。</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">透過對 NFS 用戶端和伺服器進行上述更改，Kafka 可以安全地獲得網路附加 NFS 儲存的所有好處。</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">對於功能驗證，我們表明，使用 NFSv3 掛載儲存的 Kafka 叢集無法執行分區重新分配等 Kafka 操作，而使用修復程式掛載在 NFSv4 上的另一個叢集可以執行相同的操作而不會出現任何中斷。</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">功能驗證 - 愚蠢的重命名修復</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">驗證設定</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">該設定在 AWS 上運行。下表顯示了用於驗證的不同平台組件和環境配置。</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Confluent 平台版本 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 個動物園管理員 – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 個代理伺服器 – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 x 控制中心 – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x 生產者/消費者</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7或更高版本</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">單一節點實例 – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">下圖顯示了該解決方案的架構配置。</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">此圖顯示了 AWS 拓撲，其中包含一個 VPC，該 VPC 包含三個私有子網，分別帶有一個生產者群、Kafka 叢集和 CVO 實例。</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">建築流程</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*計算。 *我們使用了四節點 Kafka 集群，並在專用伺服器上運行三節點 zookeeper 集合。</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*監控*我們使用兩個節點來實現 Prometheus-Grafana 組合。</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*工作量*為了產生工作負載，我們使用了一個單獨的三節點集群，該集群可以從該 Kafka 集群中生產和消費。</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*貯存。 *我們使用了單節點NetApp Cloud Volumes ONTAP實例，該實例連接了兩個 500GB GP2 AWS-EBS 磁碟區。然後，這些磁碟區透過 LIF 作為單一 NFSv4.1 磁碟區公開給 Kafka 叢集。</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">所有伺服器都選擇了 Kafka 的預設屬性。對動物園管理員群也做了同樣的事情。</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">更新<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block>到kafka卷，如下：</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">創建了兩個類似的 Kafka 集群，但有以下區別：</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*集群 1.*執行生產就緒ONTAP版本 9.12.1 的後端 NFS v4.1 伺服器由NetApp CVO 執行個體所託管。代理程式上安裝了 RHEL 8.7/RHEL 9.1。</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*集群 2.*後端 NFS 伺服器是手動建立的通用 Linux NFSv3 伺服器。</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">在兩個 Kafka 叢集上都建立了一個示範主題。</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">集群 1：</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">此螢幕截圖顯示了在集群 1 上建立的演示主題。</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">集群 2：</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">此螢幕截圖顯示了在 Cluster 2 上建立的演示主題。</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">資料被載入到這兩個叢集新建立的主題。這是使用預設 Kafka 包中的生產者效能測試工具包完成的：</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">使用 telnet 對每個叢集的 broker-1 執行健康檢查：</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">遠端登入<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">遠端登入<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">下圖顯示了兩個集群上的代理的成功健康檢查：</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">此螢幕截圖顯示了兩個代理人成功進行健康檢查的讀數。</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">為了觸發導致使用 NFSv3 儲存磁碟區的 Kafka 叢集崩潰的故障條件，我們在兩個叢集上啟動了分區重新分配程序。分區重新分配是使用<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block>。具體過程如下：</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">為了重新指派 Kafka 叢集中某個主題的分區，我們產生了建議的重新指派組態 JSON（對兩個叢集都執行了此操作）。</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">產生的重新分配 JSON 隨後保存在<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block>。</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">實際的分區重新分配過程由以下命令觸發：</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">重新分配完成後幾分鐘，對代理進行的另一次健康檢查顯示，使用 NFSv3 存儲卷的集群遇到了一個愚蠢的重命名問題並崩潰了，而使用已修復的NetApp ONTAP NFSv4.1 存儲卷的集群 1 繼續運行而沒有任何中斷。</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">此螢幕截圖顯示了崩潰的代理程式的輸出。</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 處於活動狀態。</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 已死亡。</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">檢查 Kafka 日誌目錄後，很明顯，使用已修復的NetApp ONTAP NFSv4.1 儲存磁碟區的叢集 1 具有乾淨的分割區分配，而使用通用 NFSv3 儲存的叢集 2 由於愚蠢的重命名問題而沒有，從而導致崩潰。下圖顯示了叢集 2 的分區重新平衡，這導致了 NFSv3 儲存上出現了一個愚蠢的重命名問題。</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">此螢幕截圖顯示了 Cluster 2 崩潰的日誌輸出。</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">下圖顯示了使用NetApp NFSv4.1 儲存對叢集 1 進行乾淨的分區重新平衡。</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">此螢幕截圖顯示了成功為 Cluster 1 分配乾淨分區的日誌輸出，而</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">既然有了針對 Kafka 的 NFS 儲存中愚蠢重命名問題的解決方案，您就可以建立利用NetApp ONTAP儲存來處理 Kafka 工作負載的強大部署。這不僅顯著降低了營運開銷，還為您的 Kafka 叢集帶來以下好處。</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">為什麼選擇NetApp NFS 來支援 Kafka 工作負載？</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">既然有了針對 Kafka 的 NFS 儲存中愚蠢重命名問題的解決方案，您就可以建立利用NetApp ONTAP儲存來處理 Kafka 工作負載的強大部署。這不僅顯著降低了營運開銷，還為您的 Kafka 叢集帶來以下好處：</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*降低 Kafka 代理程式的 CPU 使用率。 *使用分解的NetApp ONTAP儲存將磁碟 I/O 操作與代理程式分離，從而減少其 CPU 佔用。</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*更快的經紀人恢復時間。 *由於分解的NetApp ONTAP儲存在 Kafka 代理節點之間共享，因此與傳統的 Kafka 部署相比，新的運算實例可以在很短的時間內隨時替換損壞的代理，而無需重建資料。</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*儲存效率。 *由於應用程式的儲存層現在是透過NetApp ONTAP進行配置的，因此客戶可以利用ONTAP帶來的所有儲存效率優勢，例如線內資料壓縮、重複資料刪除和壓縮。</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">這些好處在本節我們將詳細討論的測試案例中得到了測試和驗證。</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">降低 Kafka 代理的 CPU 使用率</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">我們發現，當我們在兩個技術規格相同但儲存技術不同的獨立 Kafka 叢集上運行類似的工作負載時，整體 CPU 使用率低於其 DAS 對應叢集。當 Kafka 叢集使用ONTAP儲存時，不僅整體 CPU 使用率較低，而且 CPU 使用率的增加比基於 DAS 的 Kafka 叢集表現出更平緩的梯度。</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">下表顯示了用於演示降低 CPU 使用率的環境配置。</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Kafka 3.2.3 基準測試工具：OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x 生產者/消費者 - c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 或更高版本</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">單一節點實例 – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">基準測試工具</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">開放訊息傳遞</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">本測試案例中使用的基準測試工具是<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block>框架。 OpenMessaging 與供應商無關且與語言無關；它為金融、電子商務、物聯網和大數據提供產業指南；並有助於開發跨異質系統和平台的訊息傳遞和串流應用程式。下圖描述了 OpenMessaging 用戶端與 Kafka 叢集的交互作用。</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">該圖描述了 OpenMessaging 用戶端與 Kafka 叢集的交互作用。</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*計算。 *我們使用了三節點 Kafka 集群，並在專用伺服器上運行三節點 zookeeper 集合。每個代理程式透過專用 LIF 擁有兩個 NFSv4.1 掛載點，指向NetApp CVO 實例上的單一磁碟區。</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*監控*我們使用兩個節點來實現 Prometheus-Grafana 組合。為了產生工作負載，我們有一個單獨的三節點集群，可以從該 Kafka 集群中生產和消費。</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*貯存。 *我們使用了單節點NetApp Cloud Volumes ONTAP實例，該實例上安裝了六個 250GB GP2 AWS-EBS 磁碟區。然後，這些磁碟區透過專用 LIF 作為六個 NFSv4.1 磁碟區公開給 Kafka 叢集。</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*配置。 *此測試案例中的兩個可設定元素是 Kafka 代理程式和 OpenMessaging 工作負載。</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*經紀人配置。 *為 Kafka 代理選擇了以下規格。我們對所有測量使用了 3 的重複因子，如下所示。</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">該圖描述了為 Kafka 代理選擇的規格。</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">OpenMessaging 基準 (OMB) 工作負載配置。 *提供了以下規格。我們指定了目標生產率，如下所示。</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">該圖描述了為 OpenMessaging 基準工作負載配置所選擇的規格。</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">創建了兩個類似的集群，每個集群都有自己的一組基準集群群。</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*集群 1.*基於NFS的Kafka叢集。</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*集群 2.*基於DAS的Kafka叢集。</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">使用 OpenMessaging 指令，每個叢集上都會觸發類似的工作負載。</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">生產率配置在四次迭代中增加，並使用 Grafana 記錄 CPU 使用率。生產力設定為以下水準：</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10,000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40,000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80,000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100,000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">將NetApp NFS 儲存與 Kafka 結合使用有兩個主要好處：</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*您可以將 CPU 使用率降低近三分之一。 *與 DAS SSD 相比，NFS 在類似工作負載下的整體 CPU 使用率較低；節省範圍從較低生產率的 5% 到較高生產率的 32%。</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*在較高的生產率下，CPU 使用率漂移減少了三倍。 *如預期的那樣，隨著生產力的提高，CPU 使用率呈上升趨勢。然而，使用 DAS 的 Kafka 代理的 CPU 使用率從較低生產率時的 31% 上升到較高生產率時的 70%，增幅為 39%。然而，有了 NFS 儲存後端，CPU 使用率從 26% 上升到 38%，增加了 12%。</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">該圖描述了基於 DAS 的集群的行為。</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">該圖描述了基於 NFS 的集群的行為。</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">此外，在 100,000 則訊息時，DAS 顯示的 CPU 使用率比 NFS 叢集更高。</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">此圖描述了基於 DAS 的叢集在 100,000 則訊息時的行為。</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">此圖描述了基於 NFS 的叢集在 100,000 則訊息時的行為。</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">更快的經紀人恢復</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">我們發現，當 Kafka 代理程式使用共享NetApp NFS 儲存時，復原速度更快。當 Kafka 群集中某個 Broker 崩潰時，可以用具有相同 Broker ID 的健康 Broker 取代該 Broker。在執行此測試用例時，我們發現，對於基於 DAS 的 Kafka 集群，集群會在新添加的健康 Broker 上重建數據，這非常耗時。對於基於NetApp NFS 的 Kafka 集群，替換代理將繼續從先前的日誌目錄讀取數據，並且恢復速度更快。</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x 生產者/消費者 - c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 x 備份 Kafka 節點 – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 或更高版本</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*計算。 *一個三節點 Kafka 集群，帶有一個三節點 zookeeper 集合，在專用伺服器上運行。每個代理程式透過專用 LIF 擁有兩個指向NetApp CVO 實例上的單一磁碟區的 NFS 掛載點。</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*監控* Prometheus-Grafana 組合的兩個節點。為了產生工作負載，我們使用一個單獨的三節點集群，該集群可以為該 Kafka 集群生產和消費。</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*貯存。 *單節點NetApp Cloud Volumes ONTAP實例，實例上安裝了六個 250GB GP2 AWS-EBS 磁碟區。然後，這些磁碟區透過專用 LIF 作為六個 NFS 磁碟區公開給 Kafka 叢集。</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*經紀人配置。 *此測試案例中一個可設定元素是 Kafka 代理。為 Kafka 代理選擇了以下規格。這<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block>設定為較高的值，因為這決定了特定節點從 ISR 清單中取出的速度。當您在壞節點和健康節點之間切換時，您不希望該代理 ID 被排除在 ISR 清單中。</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">此圖顯示了為 Kafka 代理程式選擇的規格。</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">創建了兩個類似的集群：</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">基於 EC2 的匯合集群。</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">基於NetApp NFS 的匯合叢集。</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">建立了一個備用 Kafka 節點，其配置與原始 Kafka 叢集中的節點相同。</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">在每個叢集上，都建立了一個範例主題，並且在每個代理程式上填入了大約 110GB 的資料。</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*基於 EC2 的集群。 *  Kafka 代理程式資料目錄對應到<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block>（下圖中 cluster1 的 Broker-1[左側終端]）。</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">*基於NetApp NFS 的叢集。 *  Kafka 代理程式資料目錄安裝在 NFS 點上<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block>（下圖中 cluster2 的 Broker-1【右側終端】）。</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">此圖顯示了兩個終端螢幕。</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">在每個叢集中，Broker-1 被終止以觸發失敗的代理恢復過程。</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">代理終止後，代理 IP 位址被指派作為備用代理的輔助 IP。這是必要的，因為 Kafka 叢集中的代理程式以以下方式標識：</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*IP 位址。 *透過將發生故障的代理 IP 重新指派給備用代理來進行分配。</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*經紀人 ID。 *這是在備用代理程式中配置的<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>。</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">分配 IP 後，備用代理程式上啟動了 Kafka 服務。</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">過了一會兒，拉取伺服器日誌來檢查在叢集中的替換節點上建立資料所花費的時間。</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">Kafka 代理的恢復速度幾乎提高了 9 倍。與在 Kafka 叢集中使用 DAS SSD 相比，使用NetApp NFS 共用儲存時恢復故障代理節點所需的時間明顯更快。對於 1TB 的主題數據，基於 DAS 的叢集的恢復時間為 48 分鐘，而基於NetApp-NFS 的 Kafka 叢集的恢復時間則不到 5 分鐘。</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">我們觀察到基於 EC2 的叢集花費 10 分鐘在新代理節點上重建 110GB 數據，而基於 NFS 的叢集在 3 分鐘內完成復原。我們也在日誌中觀察到，EC2 分區的消費者偏移量為 0，而在 NFS 叢集上，消費者偏移量是從前一個代理程式取得的。</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">基於DAS的集群</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">備份節點於 08:55:53,730 啟動。</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">此圖顯示基於 DAS 的叢集的日誌輸出。</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">資料重建過程於 09:05:24,860 結束。處理 110GB 的資料大約需要 10 分鐘。</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">基於NFS的集群</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">備份節點於 09:39:17,213 啟動。下面突出顯示了起始日誌條目。</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">此圖顯示基於 NFS 的叢集的日誌輸出。</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">資料重建過程於 09:42:29,115 結束。處理 110GB 的資料大約需要 3 分鐘。</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">對包含約 1TB 資料的代理程式重複了測試，對於 DAS 大約需要 48 分鐘，對於 NFS 大約需要 3 分鐘。結果如下圖所示。</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">此圖顯示了代理恢復所需的時間，具體取決於基於 DAS 的群集或基於 NFS 的群集的代理上載入的資料量。</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">儲存效率</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">由於 Kafka 叢集的儲存層是透過NetApp ONTAP配置的，因此我們獲得了ONTAP的所有儲存效率功能。這是透過在Cloud Volumes ONTAP上配置 NFS 儲存的 Kafka 叢集上產生大量資料進行的測試。我們可以看到，由於ONTAP功能，空間顯著減少。</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">單一節點實例 – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*計算。 *我們使用了三節點 Kafka 集群，並在專用伺服器上運行三節點 zookeeper 集合。每個代理程式透過專用 LIF 擁有兩個指向NetApp CVO 實例上的單一磁碟區的 NFS 掛載點。</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*貯存。 *我們使用了單節點NetApp Cloud Volumes ONTAP實例，該實例上安裝了六個 250GB GP2 AWS-EBS 磁碟區。然後，這些磁碟區透過專用 LIF 作為六個 NFS 磁碟區公開給 Kafka 叢集。</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*配置。 *此測試案例中的可設定元素是 Kafka 代理。</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">生產者端的壓縮被關閉，從而使生產者能夠產生高吞吐量。儲存效率由運算層處理。</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">已按照上述規格配置了 Kafka 叢集。</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">在叢集上，使用 OpenMessaging Benchmarking 工具產生了約 350GB 的資料。</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">工作負載完成後，使用ONTAP系統管理器和 CLI 收集儲存效率統計資料。</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">對於使用 OMB 工具產生的數據，我們發現空間節省了約 33%，儲存效率比為 1.70:1。如下圖所示，產生的資料所使用的邏輯空間為420.3GB，用於保存資料的實體空間為281.7GB。</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">此圖展示了 VMDISK 中的空間節省。</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">螢幕截圖</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">本文檔概述了使用分層儲存基準測試套件對NetApp ONTAP上的 Confluent 平台進行的效能基準測試。</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941：與NetApp ONTAP儲存控制器融合</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam、Joe Scott、 NetApp Rankesh Kumar、Confluence</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">為了讓 Confluent 平台更具可擴充性和彈性，它必須能夠非常快速地擴展和平衡工作負載。分層儲存透過減少這種操作負擔，使得在 Confluent 中儲存大量資料變得易於管理。</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">其基本思想是將資料儲存與資料處理分開，這使得獨立擴展變得更加容易。</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">NetApp ONTAP資料管理軟體搭載業界領先的創新技術，無論資料位於何處，都能為 Confluent 帶來許多優勢。</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">我們使用NetApp StorageGRID設定對三到四個節點的生產和消費者工作負載進行了分層儲存測試。</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">具有可擴展性的效能測試</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">我們使用NetApp StorageGRID設定對三到四個節點的生產者和消費者工作負載進行了分層儲存測試。根據我們的測試，完成時間和效能結果與StorageGRID節點的數量成正比。  StorageGRID設定至少需要三個節點。</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">當儲存節點數量增加時，完成生產和消費作業的時間呈線性減少。</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">s3 檢索操作的效能根據StorageGRID節點的數量線性增加。  StorageGRID支援最多 200 個 StorgeGRID 節點。</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">此測試基於自平衡叢集功能，可根據叢集拓撲變化或不均勻負載自動重新平衡。</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">融合自平衡集群</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">如果您以前曾管理過 Kafka 集群，那麼您可能熟悉手動將分區重新分配給不同代理以確保整個集群的工作負載平衡所帶來的挑戰。對於部署大量 Kafka 的組織來說，重新整理大量資料可能是一項艱鉅、繁瑣且有風險的任務，尤其是在叢集之上建立關鍵任務應用程式時。然而，即使對於最小的 Kafka 用例，該過程也很耗時且容易出現人為錯誤。</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">在我們的實驗室中，我們測試了 Confluent 自平衡叢集功能，該功能可以根據叢集拓撲變化或不均勻負載自動重新平衡。 Confluent 重新平衡測試有助於測量節點發生故障或擴展節點需要在代理之間重新平衡資料時新增代理的時間。在經典的 Kafka 配置中，需要重新平衡的資料量會隨著叢集的成長而成長，但在分層儲存中，重新平衡僅限於少量資料。根據我們的驗證，在經典的 Kafka 架構中，分層儲存中的重新平衡需要幾秒鐘或幾分鐘，並且隨著叢集的增長而線性增長。</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">在自平衡叢集中，分區重新平衡完全自動化，以優化 Kafka 的吞吐量，加速代理擴展，並減少運行大型叢集的營運負擔。在穩定狀態下，自平衡叢集監控代理之間的資料偏差，並不斷重新分配分區以優化叢集效能。當擴大或縮小平台規模時，自平衡群集會自動識別新代理的存在或舊代理的刪除，並觸發後續分區重新分配。這使您能夠輕鬆地新增和停用代理，從而使您的 Kafka 叢集從根本上更加有彈性。這些好處不需要任何人工幹預、複雜的數學運算或分區重新分配通常帶來的人為錯誤風險。因此，資料重新平衡可以在更短的時間內完成，您可以自由地專注於更高價值的事件流項目，而不需要不斷監督您的叢集。</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">在此設定中，我們向您展示如何使用 Kafka s3 接收器連接器直接從 Kafka 讀取和寫入物件儲存中的主題。對於此測試，我們使用了獨立的 Confluent 集群，但此設定適用於分散式集群。</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Confluent S3連接器</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 Sink 連接器將資料從 Apache Kafka 主題匯出到 Avro、JSON 或 Bytes 格式的 S3 物件。 Amazon S3 接收器連接器定期從 Kafka 輪詢數據，然後將其上傳到 S3。分區器用於將每個 Kafka 分區的資料分成區塊。每個資料塊都表示為一個 S3 物件。鍵名會對主題、Kafka 分區和該資料區塊的起始偏移量進行編碼。</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">從 Confluent 網站下載 Confluent Kafka。</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">將包解壓縮到伺服器上的資料夾。</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">導出兩個變數。</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">對於獨立的 Confluent Kafka 設置，叢集會在<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block>。它還創建 Zookeeper、Kafka、模式註冊表、連接、ksql-server 和控制中心資料夾，並從複製它們各自的配置文件<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block>。請參閱以下範例：</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">配置 Zookeeper。如果使用預設參數，則無需更改任何內容。</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">在上面的配置中，我們更新了<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block>財產。預設情況下，您需要三個 Zookeeper 來選擇 Kafka 領導者。</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">我們在<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block>具有唯一 ID：</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">我們將最後一個 IP 位址數用於 myid 檔案。我們對 Kafka、connect、control-center、Kafka、Kafka-rest、ksql-server 和 schema-registry 配置使用了預設值。</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">啟動 Kafka 服務。</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">每個配置都有一個日誌資料夾，有助於解決問題。在某些情況下，服務需要更多時間才能啟動。確保所有服務均已啟動並正在運行。</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">使用以下方式安裝 Kafka connect<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block> 。</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">您也可以使用以下方式安裝特定版本<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block>。</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">預設情況下，<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>安裝在<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block>。</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">使用新的<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>。</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">停止 Confluent 服務並重新啟動它們。</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">在<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block>文件。</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">驗證儲存桶是否可存取。</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">為 s3 和 bucket 配置配置 s3-sink 屬性檔。</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">將一些記錄匯入到 s3 儲存桶。</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">載入 s3-sink 連接器。</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">檢查 s3-sink 狀態。</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">檢查日誌以確保 s3-sink 已準備好接受主題。</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">檢查 Kafka 中的主題。</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">檢查 s3 儲存桶中的物件。</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">若要驗證內容，請執行以下命令將每個檔案從 S3 複製到本機檔案系統：</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Apache 檔案</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">若要列印記錄，請使用 avro-tools-1.11.0.1.jar（可在<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>）。</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">本頁介紹了提高此解決方案效能的最佳實踐。</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">性能最佳實踐指南</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">對於ONTAP，如果可能，請使用 &gt;=1MB 的 GET 大小。</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">增加<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block>和<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block>在<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>在代理節點上，您可以將增加的分層活動推送到 S3 層。這些結果與<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block>和<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block>設定為 32。</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3 儲存桶應該針對每個成員聚合的八個組成部分。</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">驅動 S3 流量的乙太網路連結在儲存和用戶端上都應盡可能使用 9k 的 MTU。</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">這項驗證測試在配備NetApp ONTAP儲存控制器的 Confluent 上達到了 31.74GBps 的分層吞吐量。</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">這項驗證測試在配備NetApp ONTAP儲存控制器的 Confluent 上達到了 31.74GBps 的分層吞吐量。</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">什麼是 Confluent？</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">ONTAP中的 S3 最佳實踐</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3 物件儲存管理</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">本頁描述了 Confluent 在該解決方案參數範圍內的效能驗證。</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Confluent 效能驗證</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">我們已經使用 Confluent Platform 對NetApp ONTAP上的分層儲存進行了驗證。  NetApp和 Confluent 團隊共同進行了此次驗證並運行了所需的測試案例。</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Confluent 設定</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">在設定中，我們使用了三個 Zookeeper、五個代理和五個測試伺服器，配備 256GB RAM 和 16 個 CPU。對於NetApp存儲，我們使用了具有AFF A900 HA 對的ONTAP 。儲存和代理程式透過 100GbE 連線進行連線。</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">下圖為分層儲存驗證所配置的網路拓樸圖。</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">該圖顯示了用於分層儲存驗證的配置的網路拓撲。</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">工具伺服器充當應用程式用戶端，向 Confluent 節點發送事件或從 Confluent 節點接收事件。</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">我們使用了以下測試參數：</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">為了驗證，我們使用了具有 HTTP 協定的ONTAP ，但 HTTPS 也可以運行。存取密鑰和密鑰儲存在<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block>範圍。</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">NetApp儲存控制器 – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">我們在ONTAP中配置了單一 HA 對配置以進行驗證。</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">該圖描述如何將環境配置為單一 HA 對以進行驗證。</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">驗證結果</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">我們完成了以下五個測試案例進行驗證。前兩個是功能測試，其餘三個是效能測試。</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">此測試使用 API 呼叫對用於分層儲存的物件儲存執行取得、放置和刪除等基本操作。</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">此測試檢查物件儲存的端對端功能。它建立一個主題，為新建立的主題產生一個事件流，等待代理將段存檔到物件存儲，使用事件流，並驗證使用的流是否與產生的流相符。我們已經在有和沒有物件儲存故障注入的情況下執行了此測試。我們透過停止ONTAP中某個節點的服務管理器服務來模擬節點故障，並驗證端對端功能是否與物件儲存相容。</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">生產-消費性工作負載產生器</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">此測試透過段的歸檔間接在物件儲存上產生寫入工作負載。當消費者群體取得段時，從物件儲存產生讀取工作負載（讀取的段）。此工作負載由 TOCC 腳本產生。該測試檢查了並行執行緒對物件儲存的讀寫效能。我們對分層功能正確性測試進行了測試，測試了有和沒有物件儲存故障注入的情況。</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">保留工作量產生器</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">此測試檢查了物件儲存在高主題保留工作負載下的刪除效能。保留工作負載是使用 TOCC 腳本產生的，該腳本與測試主題並行產生許多訊息。測試主題是使用基於大小和基於時間的激進保留設定進行配置，這會導致事件流不斷從物件儲存中清除。然後將這些片段存檔。這導致代理在物件儲存中進行多次刪除，並收集物件儲存刪除操作的效能。</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">匯合</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">有關驗證詳細信息，請參閱<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block>網站。</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">我們在生產-消費性工作負載期間使用一個AFF A900 HA 對NetApp儲存控制器對五個或八個代理節點執行了分層儲存測試。根據我們的測試，完成時間和效能結果隨著代理節點的數量而變化，直到AFF A900資源利用率達到百分之百。  ONTAP儲存控制器設定至少需要一個 HA 對。</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">使用生產-消費性工作負載產生器進行效能測試</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">S3 檢索操作的效能根據 Confluent 代理節點的數量線性增加。  ONTAP儲存控制器在單一部署中支援最多 12 個 HA 對。</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">下圖顯示了具有五個或八個代理節點的組合 S3 分層流量。我們最大限度地提高了AFF A900單 HA 對的性能。</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">此資料圖顯示了具有五個或八個代理節點的組合 S3 分層流量。</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">下圖顯示 Kafka 吞吐量約為 31.74GBps。</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">此數據圖顯示 Kafka 吞吐量約為 31.74GBps。</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">我們也觀察到ONTAP儲存控制器的吞吐量也類似<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block>報告。</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">本節介紹使用NetApp ONTAP進行分層儲存的 Confluent Platform 部署中用於效能驗證的硬體和軟體。下表涵蓋了解決方案架構和基本組件。</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Confluent 和由ONTAP提供支援的NetApp AFF A900儲存控制器是專為資料流設計的分散式系統。兩者都具有水平可擴展性和容錯性，並且在負載下提供出色的性能。它們在分散式資料流和串流處理方面相互補充，採用資料縮減技術來最大限度地減少資料佔用空間，從而降低儲存成本。 AFF A900儲存控制器提供出色的效能，同時允許運算和資料儲存資源分離。這簡化了系統管理並允許獨立擴展資源。</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">描述解決方案概覽的圖像。</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confluent 平台版本 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3名動物園管理員</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 個經紀伺服器</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 個工具伺服器</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 個 Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x 控制中心</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP用於熱儲存桶</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 個AFF A900高可用性 (HA) 對</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 個 CPU；總共 16 個實體核心</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">英特爾至強</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256GB物理內存</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">100GbE 雙端口</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">本頁介紹了此解決方案中使用的技術。</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">技術概述</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAP儲存控制器</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP是一款高效能企業級儲存作業系統。</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 引進了對 Amazon Simple Storage Service (S3) API 的支援。  ONTAP支援 Amazon Web Services (AWS) S3 API 操作的子集，並允許將資料表示為跨雲端提供者（AWS、Azure 和 GCP）和本地的基於ONTAP的系統中的物件。</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">NetApp StorageGRID軟體是NetApp 的旗艦物件儲存解決方案。  ONTAP透過在邊緣提供攝取和預處理點、擴展由NetApp支援的物件資料資料結構以及增加NetApp產品組合的價值來補充StorageGRID 。</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">透過授權使用者和客戶端應用程式可以存取 S3 儲存桶。下圖顯示了應用程式存取 S3 儲存桶的情況。</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">此圖顯示了存取 S3 儲存桶的應用程式。</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">主要用例</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">支援 S3 API 的主要目的是提供ONTAP上的物件存取。  ONTAP統一儲存架構現在支援檔案（NFS 和 SMB）、區塊（FC 和 iSCSI）和物件（S3）。</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">原生 S3 應用程式</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">越來越多的應用程式能夠利用ONTAP支援透過 S3 進行物件存取。儘管非常適合高容量存檔工作負載，但原生 S3 應用程式對高效能的需求正在快速成長，包括：</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">分析</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">人工智慧</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">從邊緣到核心的採集</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">客戶現在可以使用熟悉的管理工具（例如ONTAP系統管理器）來快速配置高效能物件存儲，以用於ONTAP中的開發和運營，同時充分利用ONTAP儲存的效率和安全性。</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPool端點</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">從ONTAP 9.8 開始， FabricPool支援對ONTAP中的儲存桶進行分層，從而允許ONTAP到ONTAP分層。對於希望將現有FAS基礎架構重新用作物件儲存端點的客戶來說，這是一個絕佳的選擇。</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool透過兩種方式支援分層到ONTAP ：</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">本地集群分層。非活動資料透過叢集 LIF 分層到位於本地叢集上的儲存桶中。</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">遠端集群分層。非活動資料以類似傳統FabricPool雲層的方式分層到位於遠端叢集上的儲存桶中，使用FabricPool客戶端上的 IC LIF 和ONTAP物件儲存上的資料 LIF。</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">如果您希望在現有叢集上使用 S3 功能而無需額外的硬體和管理，則ONTAP S3 是合適的。對於大於 300TB 的部署， NetApp StorageGRID軟體仍然是NetApp物件儲存的旗艦解決方案。使用ONTAP或StorageGRID作為雲層時不需要FabricPool授權。</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP for Confluent 分層存儲</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">每個資料中心都需要保持關鍵業務應用程式的運作以及重要資料的可用和安全。全新NetApp AFF A900系統採用ONTAP Enterprise Edition 軟體與高彈性設計。我們全新的閃電般快速的 NVMe 儲存系統可消除對關鍵任務操作的中斷、最大限度地減少效能調整併保護您的資料免受勒索軟體攻擊。</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">從初始部署到擴展 Confluent 集群，您的環境需要快速適應對您的關鍵業務應用程式無幹擾的變化。  ONTAP企業資料管理、服務品質 (QoS) 和效能使您能夠規劃和適應您的環境。</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">將NetApp ONTAP與 Confluent 分層儲存結合使用，可利用ONTAP作為橫向擴充儲存目標，從而簡化 Apache Kafka 叢集的管理，並支援 Confluent 運算和儲存資源的獨立擴充。</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">ONTAP S3 伺服器建立在ONTAP成熟的橫向擴充儲存功能之上。透過擴展 S3 儲存桶以使用新添加到ONTAP叢集的節點，可以無縫地擴展ONTAP叢集。</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">使用ONTAP系統管理員進行簡單管理</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP系統管理器是一個基於瀏覽器的圖形介面，可讓您在單一管理平台中配置、管理和監控全球分佈位置的ONTAP儲存控制器。</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">此圖顯示了ONTAP系統管理器工作區。</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">您可以使用系統管理員和ONTAP CLI 設定和管理ONTAP S3。當您使用系統管理員啟用 S3 並建立儲存桶時， ONTAP會提供最佳實務預設設定以簡化配置。如果您從 CLI 設定 S3 伺服器和儲存桶，您仍然可以根據需要使用系統管理員管理它們，反之亦然。</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">當您使用系統管理員建立 S3 儲存桶時， ONTAP會設定係統上可用的最高預設效能服務等級。例如，在AFF系統上，預設設定是 Extreme。效能服務等級是預先定義的自適應 QoS 策略群組。您可以指定自訂 QoS 策略群組或不指定策略群組，而不是指定預設服務等級之一。</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">預先定義的自適應 QoS 策略群組包括以下內容：</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*極端。 *用於需要最低延遲和最高效能的應用程式。</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*表現。 *適用於具有中等性能需求和延遲的應用程式。</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*價值。 *用於吞吐量和容量比延遲更重要的應用程式。</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*風俗。 *指定自訂 QoS 策略或不指定 QoS 策略。</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">如果選擇“*用於分層*”，則不會選擇任何效能服務級別，系統會嘗試為分層資料選擇具有最佳效能的低成本媒體。</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP嘗試在具有最合適磁碟的本機層上配置此儲存桶，以滿足所選的服務等級。但是，如果您需要指定要包含在儲存桶中的磁碟，請考慮透過指定本機層（聚合）從 CLI 配置 S3 物件儲存。如果您從 CLI 設定 S3 伺服器，您仍然可以根據需要使用系統管理員進行管理。</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">如果您希望能夠指定用於儲存桶的聚合，則只能使用 CLI 來實作。</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent 平台是一個全方位的資料流平台，可讓您輕鬆地以連續的即時串流形式存取、儲存和管理資料。 Confluent 由 Apache Kafka 的原始創建者構建，它透過企業級功能擴展了 Kafka 的優勢，同時消除了 Kafka 管理或監控的負擔。如今，財富 100 強企業中超過 80% 的企業採用資料流技術，其中大多數使用 Confluent。</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">為什麼選擇 Confluent？</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">透過將歷史資料和即時資料整合到單一的中央事實來源，Confluent 可以輕鬆建立全新類別的現代事件驅動應用程序，獲得通用資料管道，並解鎖具有完全可擴展性、效能和可靠性的強大新用例。</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Confluent 的用途是什麼？</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent 平台讓您專注於如何從資料中獲得商業價值，而不必擔心底層機制，例如如何在不同的系統之間傳輸或整合資料。具體來說，Confluent Platform 簡化了資料來源與 Kafka 的連接、串流應用程式的建置以及 Kafka 基礎設施的保護、監控和管理。如今，Confluent 平台已廣泛應用於眾多產業，從金融服務、全通路零售、自動駕駛汽車到詐欺偵測、微服務和物聯網。</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">下圖展示了 Confluent Platform 的元件。</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">該圖顯示了 Confluent 平台的元件。</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Confluent 事件流技術概述</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">卡夫卡</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Confluent 平台的核心是<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>，最受歡迎的開源分散式串流平台。  Kafka 的主要功能包括：</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">發布和訂閱記錄流。</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">以容錯的方式儲存記錄流。</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">處理記錄流程。</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">開箱即用的 Confluent Platform 還包括 Schema Registry、REST Proxy、總共 100 多個預先建置的 Kafka 連接器和 ksqlDB。</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Confluent 平台企業功能概述</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*匯合控制中心。 *用於管理和監控 Kafka 的基於 UI 的系統。它允許您輕鬆管理 Kafka Connect 以及建立、編輯和管理與其他系統的連接。</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*適用於 Kubernetes 的 Confluent。 *  Confluent for Kubernetes 是一位 Kubernetes 操作員。 Kubernetes 操作員透過為特定平台應用程式提供獨特的功能和要求來擴展 Kubernetes 的編排功能。對於 Confluent 平台，這包括大幅簡化 Kafka 在 Kubernetes 上的部署流程，並自動執行典型的基礎架構生命週期任務。</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">Kafka Connect 連接器。連接器使用 Kafka Connect API 將 Kafka 連接到其他系統，例如資料庫、鍵值儲存、搜尋索引和檔案系統。 Confluent Hub 具有適用於最受歡迎的資料來源和接收器的可下載連接器，包括使用 Confluent Platform 對這些連接器進行全面測試和支援的版本。更多詳情請見<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*自平衡集群。 *提供自動負載平衡、故障偵測和自我修復。它還支援根據需要添加或停用代理，無需手動調整。</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*匯合簇連接。 *直接將集群連接在一起，並透過連結橋將主題從一個集群鏡像到另一個集群。集群連結簡化了多資料中心、多集群和混合雲部署的設定。</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*匯合自動數據平衡器。 *監控叢集中的代理數量、分區大小、分區數量以及叢集內的領導者數量。它允許您轉移資料以在整個叢集中創建均勻的工作負載，同時限制重新平衡流量以最大限度地減少重新平衡時對生產工作負載的影響。</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*匯合複製器。 *讓在多個資料中心維護多個 Kafka 叢集變得比以往更加簡單。</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*分層儲存。 *提供使用您最喜歡的雲端供應商儲存大量 Kafka 資料的選項，從而減少營運負擔和成本。透過分層存儲，您可以將資料保存在經濟高效的物件儲存中，並且僅在需要更多運算資源時才擴展代理程式。</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">Confluent JMS 用戶端。 Confluent Platform 包含一個與 JMS 相容的 Kafka 用戶端。此 Kafka 用戶端實作了 JMS 1.1 標準 API，使用 Kafka 代理作為後端。如果您有使用 JMS 的遺留應用程式並且想要用 Kafka 取代現有的 JMS 訊息代理，這將非常有用。</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Confluent MQTT 代理。 *提供一種從 MQTT 設備和網關直接向 Kafka 發布資料的方法，無需中間的 MQTT 代理。</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Confluent 安全插件。 * Confluent 安全外掛程式用於為各種 Confluent 平台工具和產品添加安全功能。目前，有一個可用於 Confluent REST 代理程式的插件，可協助驗證傳入的請求並將經過驗證的主體傳播到對 Kafka 的請求。這使得 Confluent REST 代理客戶端能夠利用 Kafka 代理的多租戶安全功能。</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetAppStorageGRID</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID是一個高效能、經濟高效的物件儲存平台。透過使用分層存儲，Confluent Kafka 上儲存在本機儲存或代理程式的 SAN 儲存中的大部分資料都被卸載到遠端物件儲存。此配置可減少重新平衡、擴展或收縮群集或更換故障代理的時間和成本，從而顯著改善操作。物件儲存在管理駐留在物件儲存層的資料方面發揮著重要作用，因此選擇正確的物件儲存非常重要。</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID使用分散式、基於節點的網格架構提供智慧、策略驅動的全域資料管理。它透過其無所不在的全域物件命名空間與複雜的資料管理功能結合，簡化了 PB 級非結構化資料和數十億個物件的管理。單次呼叫物件存取可跨站點擴展，並簡化高可用性架構，同時確保持續的物件訪問，無論站點或基礎設施是否中斷。</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">多租戶允許在同一網格內安全地為多個非結構化雲端和企業資料應用程式提供服務，從而提高NetApp StorageGRID的投資報酬率和用例。您可以使用元資料驅動的物件生命週期策略建立多個服務級別，從而優化跨多個地區的耐用性、保護性、效能和位置性。使用者可以調整資料管理策略並監控和應用流量限制，以便在不斷變化的 IT 環境中隨著需求的變化而無中斷地重新調整資料格局。</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">使用網格管理器進行簡單管理</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager 是一個基於瀏覽器的圖形介面，可讓您在單一玻璃窗格中設定、管理和監控全球分散位置的StorageGRID系統。</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">您可以使用StorageGRID Grid Manager 介面執行下列任務：</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">管理全球分佈的 PB 級物件儲存庫，例如影像、影片和記錄。</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">監控網格節點和服務以確保物件可用性。</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">使用資訊生命週期管理 (ILM) 規則來管理物件資料隨時間推移的放置。這些規則控制著物件資料被攝取後會發生什麼、如何防止資料遺失、物件資料儲存在何處以及儲存多長時間。</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">監控系統內的交易、效能和操作。</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">資訊生命週期管理政策</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">StorageGRID具有靈活的資料管理策略，包括保留對象的副本以及使用 EC（擦除編碼）方案（例如 2+1 和 4+2 等）來儲存對象，具體取決於特定的效能和資料保護要求。由於工作負載和需求隨時間而變化，ILM 策略通常也必須隨時間而變化。修改 ILM 策略是一項核心功能，可讓StorageGRID客戶快速輕鬆地適應不斷變化的環境。</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">表現</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712、SG5760、SG6060 或 SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID透過增加更多儲存節點來擴展效能，這些節點可以是虛擬機器、裸機或專用設備，例如<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>。在我們的測試中，我們使用 SGF6024 設備以最小尺寸的三節點網格超越了 Apache Kafka 的關鍵效能要求。當客戶使用額外的代理來擴展他們的 Kafka 叢集時，他們可以添加更多的儲存節點來提高效能和容量。</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">負載平衡器和端點配置</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRID中的管理節點提供網格管理器 UI（使用者介面）和 REST API 端點來檢視、設定和管理您的StorageGRID系統，以及稽核日誌來追蹤系統活動。為了為 Confluent Kafka 分層儲存提供高可用性 S3 端點，我們實作了StorageGRID負載平衡器，它作為管理節點和網關節點上的服務運作。此外，負載平衡器還管理本地流量並與 GSLB（全域伺服器負載平衡）對話以協助進行災難復原。</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">為了進一步增強端點配置， StorageGRID提供了內建於管理節點的流量分類策略，讓您監控工作負載流量，並對您的工作負載套用各種服務品質 (QoS) 限制。流量分類策略應用於網關節點和管理節點的StorageGRID負載平衡器服務上的端點。這些策略可以幫助流量整形和監控。</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRID中的流量分類</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID內建 QoS 功能。流量分類策略可以幫助監控來自客戶端應用程式的不同類型的 S3 流量。然後，您可以建立並套用策略來根據輸入/輸出頻寬、讀取/寫入並發請求數或讀取/寫入請求率限制此流量。</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka 是一個用 Java 和 Scala 編寫的使用流處理的軟體匯流排的框架實作。其目的是提供一個統一、高吞吐量、低延遲的平台來處理即時資料饋送。  Kafka可以透過Kafka Connect連接外部系統進行資料匯出和匯入，並提供Java流處理庫Kafka Streams。 Kafka 使用針對效率進行了最佳化的二進位、基於 TCP 的協議，並依賴「訊息集」抽象，該抽象自然地將訊息組合在一起，以減少網路往返的開銷。這使得更大的順序磁碟操作、更大的網路封包和連續的記憶體區塊成為可能，從而使 Kafka 能夠將突發的隨機訊息寫入流轉換為線性寫入。下圖描述了Apache Kafka的基本資料流。</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka 儲存來自任意數量的進程（稱為生產者）的鍵值訊息。資料可以劃分到不同主題內的不同分區。在分區內，訊息嚴格按照其偏移量（訊息在分區內的位置）排序，並與時間戳一起索引和儲存。其他稱為消費者的進程可以從分區讀取訊息。對於流程處理，Kafka 提供了 Streams API，允許編寫 Java 應用程式使用來自 Kafka 的資料並將結果寫回 Kafka。  Apache Kafka 還可以與外部串流處理系統（如 Apache Apex、Apache Flink、Apache Spark、Apache Storm 和 Apache NiFi）協同工作。</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka 在一個或多個伺服器（稱為代理）的叢集上運行，所有主題的分區分佈在叢集節點上。此外，分區被複製到多個代理程式。這種架構使得 Kafka 能夠以容錯的方式傳遞大量訊息流，並使其能夠取代一些傳統的訊息傳遞系統，如 Java 訊息服務 (JMS)、高階訊息佇列協定 (AMQP) 等。自 0.11.0.0 版本以來，Kafka 提供事務寫入功能，可使用 Streams API 提供一次串流處理。</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka 支援兩種類型的主題：常規主題和壓縮主題。常規主題可以配置保留時間或空間界限。如果有記錄超過指定的保留時間或超出了分割區的空間限制，則允許 Kafka 刪除舊資料以釋放儲存空間。預設情況下，主題的保留時間配置為 7 天，但也可以無限期地儲存資料。對於壓縮主題，記錄不會根據時間或空間界限而過期。相反，Kafka 將後續訊息視為具有相同金鑰的舊訊息的更新，並保證永遠不會刪除每個金鑰的最新訊息。使用者可以透過寫入具有特定鍵的空值的所謂墓碑訊息來徹底刪除訊息。</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka 中有五個主要 API：</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">生產者 API。允許應用程式發布記錄流。</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*消費者 API。 *允許應用程式訂閱主題並處理記錄流。</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">連接器 API。執行可重複使用的生產者和消費者 API，將主題連結到現有應用程式。</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">流 API。此 API 將輸入流轉換為輸出並產生結果。</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*管理 API。 *用於管理 Kafka 主題、代理人和其他 Kafka 物件。</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">消費者和生產者 API 建立在 Kafka 訊息傳遞協定之上，並為 Java 中的 Kafka 消費者和生產者用戶端提供參考實作。底層訊息傳遞協定是一種二進位協議，開發人員可以使用任何程式語言編寫自己的消費者或生產者用戶端。這使得 Kafka 從 Java 虛擬機器 (JVM) 生態系統中解放出來。  Apache Kafka wiki 中維護了可用的非 Java 用戶端清單。</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka 用例</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka 最受歡迎的用途是訊息傳遞、網站活動追蹤、指標、日誌聚合、流處理、事件來源和提交日誌記錄。</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka 提高了吞吐量、內建分區、複製和容錯能力，使其成為大規模訊息處理應用程式的良好解決方案。</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka 可以將追蹤管道中的使用者活動（頁面瀏覽量、搜尋量）重建為一組即時發布-訂閱源。</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka 經常用於營運監控數據。這涉及匯總來自分散式應用程式的統計資料以產生集中的操作資料。</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">許多人使用 Kafka 來取代日誌聚合解決方案。日誌聚合通常從伺服器上收集實體日誌檔案並將它們放在一個中心位置（例如，檔案伺服器或 HDFS）進行處理。 Kafka 抽象檔案詳細資料並將日誌或事件資料以訊息流的形式提供更清晰的抽象。這允許更低延遲的處理並且更容易支援多個資料來源和分散式資料消費。</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">許多 Kafka 使用者在由多個階段組成的處理管道中處理數據，其中從 Kafka 主題中使用原始輸入數據，然後聚合、豐富或以其他方式轉換為新主題以供進一步使用或後續處理。例如，用於推薦新聞文章的處理管道可能會從 RSS 提要中抓取文章內容並將其發佈到「文章」主題。進一步的處理可能會規範化或重複化該內容，並將清理後的文章內容發佈到新主題，最後的處理階段可能會嘗試將該內容推薦給使用者。這樣的處理管道根據各個主題創建即時資料流程圖。</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">事件溯源是一種應用程式設計風格，其中狀態變化被記錄為按時間順序排列的記錄序列。  Kafka 對非常大的儲存日誌資料的支援使其成為以這種風格構建的應用程式的優秀後端。</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka 可以作為分散式系統的一種外部提交日誌。日誌有助於在節點之間複製數據，並充當故障節點恢復其數據的重新同步機制。  Kafka 中的日誌壓縮功能有助於支援這種用例。</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent 平台是一個企業級平台，它為 Kafka 提供了先進的功能，旨在幫助加速應用程式開發和連接、透過串流處理實現轉換、簡化企業大規模營運並滿足嚴格的架構要求。 Confluent 由 Apache Kafka 的原始創建者構建，它透過企業級功能擴展了 Kafka 的優勢，同時消除了 Kafka 管理或監控的負擔。如今，財富 100 強企業中有超過 80% 都採用資料流技術，其中大多數都使用 Confluent。</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent 平台讓您專注於如何從資料中獲得商業價值，而不必擔心底層機制，例如如何在不同的系統之間傳輸或整合資料。具體來說，Confluent Platform 簡化了資料來源與 Kafka 的連接、串流應用程式的建置以及 Kafka 基礎設施的保護、監控和管理。如今，Confluent 平台已廣泛應用於眾多產業，從金融服務、全通路零售、自動駕駛汽車到詐欺偵測、微服務和物聯網。</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">下圖顯示了 Confluent Kafka 平台元件。</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Confluent 事件流技術概述</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Confluent 平台的核心是<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>，最受歡迎的開源分散式串流平台。  Kafka 的主要功能如下：</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Confluent 平台企業功能概述</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*匯合控制中心。 *用於管理和監控 Kafka 的基於 GUI 的系統。它允許您輕鬆管理 Kafka Connect 以及建立、編輯和管理與其他系統的連接。</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*將連接器匯合至 Kafka。 *連接器使用 Kafka Connect API 將 Kafka 連接到其他系統，例如資料庫、鍵值儲存、搜尋索引和檔案系統。 Confluent Hub 具有適用於最受歡迎的資料來源和接收器的可下載連接器，包括使用 Confluent Platform 對這些連接器進行全面測試和支援的版本。更多詳情請見<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*自平衡集群。 *提供自動負載平衡、故障偵測和自我修復。它支援根據需要新增或停用代理，無需手動調整。</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*匯合自動數據平衡器。 *監控叢集中的代理數量、分區大小、分區數量以及叢集內的領導者數量。它允許您轉移資料以在整個叢集中創建均勻的工作負載，同時限制重新平衡流量以最大限度地減少重新平衡時對生產工作負載的影響。</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY：採用NetApp儲存解決方案的 Apache Spark 工作負載</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY 描述了 Apache Spark SQL 在NetApp NFS AFF儲存系統上的效能和功能驗證。它回顧了基於各種場景的配置、架構和效能測試，以及將 Spark 與NetApp ONTAP資料管理軟體結合使用的建議。它還涵蓋了基於一組磁碟（JBOD）與NetApp AFF A800儲存控制器的測試結果。</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">現代數據分析—針對不同分析策略的不同解決方案</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">本白皮書介紹了NetApp現代資料分析解決方案策略。它包括有關業務成果、客戶挑戰、技術趨勢、競爭遺留架構、現代工作流程、用例、行業、雲端、技術合作夥伴、資料移動器、 NetApp Active IQ Digital Advisor Digital Advisor）、 NetApp DataOps Toolkit、Hadoop to Spark、使用NetApp Trident Protect 的軟體定義儲存、容器、企業資料管理、歸檔和實現的詳細資訊，以實現的詳細資訊，定義 AI和分析的目標，以及NetApp和客戶如何共同實現其資料架構的現代化。</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">本 TR 中使用了以下參考文獻：</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Spark 架構和元件</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Apache Spark 用例</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">BERT</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">用於廣告點擊預測的深度和交叉網絡</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">串流 ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">NetApp E系列Hadoop解決方案</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">NetApp現代資料分析解決方案</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">數據分析解決方案</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">BlueXP複製和同步</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">DataOps 工具包</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">本頁更詳細地描述了主要的 AI、ML 和 DL 用例和架構。</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">主要的 AI、ML 和 DL 用例和架構</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">主要的 AI、ML 和 DL 用例和方法可分為以下幾部分：</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Spark NLP 管道和 TensorFlow 分散式推理</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">以下列表包含資料科學界在不同發展層次下採用的最受歡迎的開源 NLP 庫：</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">自然語言工具包（NLTK）</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> 。所有 NLP 技術的完整工具包。它自 21 世紀初以來一直得到維護。</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">文字區塊</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> 。基於 NLTK 和 Pattern 建立的易於使用的 NLP 工具 Python API。</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">史丹佛核心 NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> 。史丹佛 NLP 小組開發的 Java NLP 服務和套件。</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> 。人類主題建模最初是捷克數位數學圖書館計畫的 Python 腳本集合。</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">SpaCy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> 。使用 Python 和 Cython 實現端對端工業 NLP 工作流程，並為 Transformer 提供 GPU 加速。</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">快文</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> 。Facebook 的 AI 研究 (FAIR) 實驗室創建的免費、輕量級、開源 NLP 庫，用於學習單字嵌入和句子分類。</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark 機器學習</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">Spark NLP 是針對所有 NLP 任務和要求的單一、統一的解決方案，可為實際生產用例提供可擴展、高效能和高精度的 NLP 軟體。它利用遷移學習並在研究和跨行業中實施最新的最先進的演算法和模型。由於 Spark 缺乏對上述函式庫的全面支持，Spark NLP 建立在<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block>利用 Spark 的通用記憶體分散式資料處理引擎作為關鍵任務生產工作流程的企業級 NLP 庫。它的註釋器利用基於規則的演算法、機器學習和 TensorFlow 來支援深度學習的實作。這涵蓋了常見的 NLP 任務，包括但不限於標記化、詞形還原、詞幹提取、詞性標註、命名實體識別、拼字檢查和情緒分析。</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">來自 Transformer 的雙向編碼器表示 (BERT) 是一種基於 Transformer 的 NLP 機器學習技術。它推廣了預訓練和微調的概念。 BERT 中的 Transformer 架構源自機器翻譯，它比基於循環神經網路 (RNN) 的語言模型更好地模擬長期依賴關係。它還引入了掩蔽語言建模 (MLM) 任務，其中隨機 15% 的所有標記被掩蔽，並且模型對其進行預測，從而實現真正的雙向性。</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">路透社 TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">金融短語庫</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">解釋文檔 DL</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">由於該領域的專業語言和缺乏標記數據，金融情緒分析具有挑戰性。 FinBERT 是一種基於預訓練 BERT 的語言模型，已在以下領域進行了調整：<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> ，一個金融語料庫，並使用標記資料進行微調（<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ) 用於金融情緒分類。研究人員從包含金融術語的新聞文章中提取了 4,500 個句子。然後，16位具有金融背景的專家和碩士生將這些句子標記為肯定、中性和否定。我們建立了一個端到端的 Spark 工作流程，使用 FinBERT 和其他兩個預先訓練的流程來分析 2016 年至 2020 年納斯達克十大公司收益電話會議記錄的情緒，<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ）來自 Spark NLP。</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Spark NLP 的底層深度學習引擎是 TensorFlow，這是一個端到端的開源機器學習平台，可以輕鬆建立模型、在任何地方進行強大的 ML 生產以及進行強大的研究實驗。因此，在 Spark 中執行管道時<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block>模式，我們本質上是在運行分散式 TensorFlow，資料和模型在一個主節點和多個工作節點上並行化，並在叢集上安裝網路附加儲存。</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod分散式訓練</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">NetApp E系列Hadoop解決方案</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">與 MapReduce 相關的效能的核心 Hadoop 驗證是使用 TeraGen、TeraSort、TeraValidate 和 DFSIO（讀寫）執行的。  TeraGen 和 TeraSort 驗證結果如下<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block>以及AFF的「儲存分層」部分。</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Spark 上的 Hovorod</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">根據客戶要求，我們認為使用 Spark 進行分散式訓練是各種用例中最重要的用例之一。在本文檔中，我們使用了<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block>使用NetApp All Flash FAS (AFF) 儲存控制器、 Azure NetApp Files和StorageGRID來驗證 Spark 與NetApp本地端、雲端原生和混合雲端解決方案的效能。</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Horovod on Spark 套件為 Horovod 提供了一個便捷的包裝器，使得在 Spark 叢集中運行分散式訓練工作負載變得簡單，從而實現了緊密的模型設計循環，其中資料處理、模型訓練和模型評估都在訓練和推理資料所在的 Spark 中完成。</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kaggle Rossmann 商店銷售</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">有兩個用於在 Spark 上運行 Horovod 的 API：高級 Estimator API 和低階 Run API。儘管兩者都使用相同的底層機制在 Spark 執行器上啟動 Horovod，但 Estimator API 抽象化了資料處理、模型訓練循環、模型檢查點、指標收集和分散式訓練。我們使用 Horovod Spark Estimators、TensorFlow 和 Keras 進行端到端資料準備和分散式訓練工作流程，基於<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block>競賽。</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">腳本<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>可以在以下部分找到<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block>它包含三個部分：</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">第一部分對 Kaggle 提供並由社群收集的一組初始 CSV 檔案執行各種資料預處理步驟。輸入資料被分成一個訓練集，<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block>子集和測試資料集。</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">第二部分定義了一個具有對數 S 型激活函數和 Adam 優化器的 Keras 深度神經網路 (DNN) 模型，並使用 Spark 上的 Horovod 對模型進行分散式訓練。</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">第三部分使用最小化驗證集總體平均絕對誤差的最佳模型對測試資料集進行預測。然後創建一個輸出 CSV 檔案。</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">機器學習</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">請參閱<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block>用於各種運行時比較結果。</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">使用 Keras 進行多任務深度學習以進行 CTR 預測</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">隨著機器學習平台和應用的最新進展，人們將大量注意力放在了大規模學習上。點擊率（CTR）定義為每百次線上廣告展示的平均點擊次數（以百分比表示）。它被廣泛採用為各行業垂直領域和用例的關鍵指標，包括數位行銷、零售、電子商務和服務提供者。有關 CTR 和分佈式訓練表現結果的應用的更多詳細信息，請參閱<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block>部分。</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo Terabyte 點選日誌資料集</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">在本技術報告中，我們使用了<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block>（參見 TR-4904）用於多工作者分散式深度學習，使用 Keras 建立具有深度和交叉網路 (DCN) 模型的 Spark 工作流程，並將其對數損失誤差函數方面的效能與基線 Spark ML 邏輯回歸模型進行比較。  DCN 有效地捕捉有界度的有效特徵交互，學習高度非線性交互，不需要手動特徵工程或窮舉搜索，且計算成本低。</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">網路規模推薦系統的資料大多是離散的和分類的，導致特徵空間龐大且稀疏，這對於特徵探索來說是一個挑戰。這使得大多數大型系統僅限於邏輯迴歸等線性模型。然而，識別經常預測的特徵並同時探索看不見的或罕見的交叉特徵是做出良好預測的關鍵。線性模型簡單、可解釋、易於擴展，但其表達能力有限。</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">另一方面，交叉特徵已被證明對提高模型的表現力具有重要意義。不幸的是，通常需要手動特徵工程或詳盡搜尋來識別這些特徵。推廣到看不見的特徵互動通常很困難。使用像 DCN 這樣的交叉神經網路可以透過以自動方式明確應用特徵交叉來避免特定於任務的特徵工程。交叉網路由多層組成，其中最高程度的交互作用可由層深度決定。每一層都會在現有交互的基礎上產生更高階的交互，並保留前幾層的交互。</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">深度神經網路 (DNN) 有望捕捉跨特徵的非常複雜的交互作用。然而，與 DCN 相比，它需要的參數幾乎多一個數量級，無法明確地形成交叉特徵，並且可能無法有效地學習某些類型的特徵交叉。交叉網路記憶體效率高且易於實現。聯合訓練交叉和 DNN 元件可以有效地捕捉預測特徵交互作用並在 Criteo CTR 資料集上提供最先進的效能。</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">深度點擊率</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">DCN 模型從嵌入和堆疊層開始，然後並行連接交叉網路和深度網路。接下來是最終的組合層，它將兩個網路的輸出組合在一起。您的輸入資料可以是具有稀疏和密集特徵的向量。在 Spark 中，庫包含類型<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>。因此，使用者區分兩者並在呼叫各自的函數和方法時要小心，這一點很重要。在 CTR 預測等網路規模推薦系統中，輸入大多是分類特徵，例如<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block>。這些特徵通常被編碼為獨熱向量，例如，<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> 。獨熱編碼（OHE）<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>在處理詞彙不斷變化和增長的真實世界資料集時很有用。我們修改了範例<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block>處理大型詞彙表，在 DCN 的嵌入和堆疊層中建立嵌入向量。</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo 展示廣告資料集</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">這<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block>預測廣告點擊率。它有 13 個整數特徵和 26 個分類特徵，其中每個類別都有很高的基數。對於該資料集，由於輸入規模較大，對數損失 0.001 的改進實際上具有顯著意義。對於龐大的用戶群，預測準確度的微小提升都可能帶來公司收入的大幅增加。該資料集包含 7 天內 11GB 的使用者日誌，相當於約 4,100 萬筆記錄。我們使用了 Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block>隨機分割資料用於訓練（80%）、交叉驗證（10%），剩餘 10% 用於測試。</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN 是使用 Keras 在 TensorFlow 上實現的。使用DCN實現模型訓練過程主要有四個部分：</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*資料處理和嵌入。 *透過應用對數變換對實值特徵進行規範化。對於分類特徵，我們將特徵嵌入到維度為 6×(類別基數)1/4 的密集向量中。連接所有嵌入將產生一個維度為 1026 的向量。</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*最佳化.*我們利用 Adam 優化器進行了小批量隨機優化。批次大小設定為 512。將深度網路進行批量歸一化，梯度裁剪範數設為100。</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*正則化。 *我們採用了早期停止的方法，因為 L2 正規化或 dropout 被發現無效。</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">超參數。我們報告基於對隱藏層數量、隱藏層大小、初始學習率和交叉層數量的網格搜尋的結果。隱藏層的數量範圍為 2 至 5，隱藏層大小範圍為 32 至 1024。對於DCN，交叉層的數量為1至6。初始學習率從 0.0001 調整到 0.001，增量為 0.0001。所有實驗均在訓練步驟 150,000 時提前停止，超過該步驟後就會開始出現過度擬合。</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">自動輸入</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">除了 DCN 之外，我們還測試了其他流行的深度學習模型來進行 CTR 預估，包括<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>，<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> ， 和<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>。</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">用於驗證的架構</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">為了進行此驗證，我們使用了四個工作節點和一個主節點以及一個AFF-A800 HA 對。所有群集成員都透過 10GbE 網路交換器連接。</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">為了驗證NetApp Spark 解決方案，我們使用了三種不同的儲存控制器：E5760、E5724 和AFF-A800。  E系列儲存控制器透過12Gbps SAS連線連接到五個資料節點。  AFF HA 對儲存控制器透過 10GbE 連線向 Hadoop 工作節點提供匯出的 NFS 磁碟區。  Hadoop 叢集成員透過 E 系列、 AFF和StorageGRID Hadoop 解決方案中的 10GbE 連線進行連線。</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">用於驗證的架構。</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">現代企業資料中心是一種混合雲，它透過具有一致操作模式的連續資料管理平面在本地和/或多個公有雲中連接多個分散式基礎架構環境。為了充分利用混合雲，您必須能夠在本地和多雲環境之間無縫移動數據，而無需進行任何數據轉換或應用程式重構。</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">混合雲解決方案</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">客戶表示，他們開始混合雲端之旅的方法是將二級儲存遷移到雲端用於資料保護等用例，或將不太重要的業務工作負載（如應用程式開發和 DevOps）遷移到雲端。然後他們轉向處理更重要的工作。 Web 和內容託管、DevOps 和應用程式開發、資料庫、分析和容器化應用程式是最受歡迎的混合雲工作負載。企業 AI 專案的複雜性、成本和風險歷來阻礙 AI 從實驗階段走向生產階段。</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">透過NetApp混合雲端解決方案，客戶可以透過單一控制面板享受整合的安全性、資料治理和合規性工具，用於跨分散式環境的資料和工作流程管理，同時根據其消費情況優化整體擁有成本。下圖是一個雲端服務合作夥伴的範例解決方案，該合作夥伴負責為客戶的大數據分析資料提供多雲連接。</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">雲端服務合作夥伴的範例解決方案。</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">在這種情況下，AWS 從不同來源接收的 IoT 資料儲存在NetApp私有儲存 (NPS) 的中心位置。 NPS 儲存連接到位於 AWS 和 Azure 中的 Spark 或 Hadoop 集群，使在多個雲端中運行的大數據分析應用程式能夠存取相同的資料。此用例的主要要求和挑戰包括以下內容：</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">必須透過不同的感測器和集線器從不同來源（例如本地和雲端環境）接收資料。</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">該解決方案必須高效且具有成本效益。</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">主要挑戰是建立一個經濟高效的解決方案，在不同的內部部署和雲端環境之間提供混合分析服務。</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">我們的資料保護和多雲連接解決方案解決了跨多個超大規模運算平台的雲端分析應用程式的痛點。如上圖所示，來自感測器的資料透過 Kafka 串流並輸入到 AWS Spark 叢集中。資料儲存在 NPS 中的 NFS 共用中，NPS 位於 Equinix 資料中心內的雲端供應商之外。</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">由於NetApp NPS 分別透過 Direct Connect 和 Express Route 連線連接到 Amazon AWS 和 Microsoft Azure，因此客戶可以利用 In-Place Analytics Module 存取來自 Amazon 和 AWS 分析叢集的資料。因此，由於本地儲存和 NPS 儲存都運行ONTAP軟體，<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block>可以將NPS資料鏡像到本地集群，提供跨本地和多雲的混合雲分析。</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">為了獲得最佳效能， NetApp通常建議使用多個網路介面和直接連接或快速路由來存取雲端實例的資料。我們還有其他數據移動解決方案，包括<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block>和<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block>幫助客戶建立應用程式感知、安全且經濟高效的混合雲 Spark 叢集。</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">以下三個 Python 腳本對應測試的三個主要用例。首先是<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block>。</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">第二個腳本是<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>。</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">第三個腳本是<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>。</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp有三個儲存產品組合： FAS/ AFF、E 系列和Cloud Volumes ONTAP。我們已經透過 Apache Spark 驗證了適用於 Hadoop 解決方案的AFF和具有ONTAP儲存系統的 E 系列。  NetApp支援的資料結構整合了資料管理服務和應用程式（構建塊），用於資料存取、控制、保護和安全。</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">NetApp Spark 解決方案概述</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp有三個儲存產品組合： FAS/ AFF、E 系列和Cloud Volumes ONTAP。我們已經透過 Apache Spark 驗證了適用於 Hadoop 解決方案的AFF和具有ONTAP儲存系統的 E 系列。</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">資料結構提供資料管理服務和應用程式。</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* NetApp NFS 直接存取。 *為最新的 Hadoop 和 Spark 叢集提供對NetApp NFS 磁碟區的直接訪問，無需額外的軟體或驅動程式要求。</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* NetApp SnapMirror技術。 *在本機和ONTAP Cloud 或 NPS 實例之間提供資料保護功能。</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">下圖描述了採用NetApp儲存的 Spark 解決方案。</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">採用NetApp儲存的 Spark 解決方案。</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">ONTAP Spark 解決方案使用NetApp NFS 直接存取協定進行就地分析以及透過存取現有生產資料來實現 AI、ML 和 DL 工作流程。 Hadoop 節點可用的生產資料被匯出以執行就地分析和 AI、ML 和 DL 作業。您可以使用NetApp NFS 直接存取或不使用 NetApp NFS 直接存取來存取 Hadoop 節點中要處理的資料。在 Spark 中，使用獨立或<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block>叢集管理器，您可以使用設定 NFS 卷<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block>。我們用不同的資料集驗證了三個用例。這些驗證的詳細資訊在「測試結果」部分中介紹。  （外部參照）</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">下圖描述了NetApp Apache Spark/Hadoop 儲存定位。</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">NetApp Apache Spark/Hadoop儲存定位。</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">我們確定了 E 系列 Spark 解決方案、 AFF/ FAS ONTAP Spark 解決方案和StorageGRID Spark 解決方案的獨特功能，並進行了詳細的驗證和測試。根據我們的觀察， NetApp建議對於綠地安裝和新的可擴展部署使用 E 系列解決方案，對於使用現有 NFS 資料的就地分析、AI、ML 和 DL 工作負載使用AFF/ FAS解決方案，對於需要物件儲存時的 AI、ML、DL 和現代資料分析使用StorageGRID 。</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">推薦用於 Spark 的NetApp解決方案。</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">資料湖是原生形式的大型資料集的儲存庫，可用於分析、AI、ML 和 DL 作業。我們為 E 系列、 AFF/ FAS和StorageGRID SG6060 Spark 解決方案建置了一個資料湖儲存庫。 E 系列系統提供對 Hadoop Spark 叢集的 HDFS 訪問，而現有生產資料則透過 NFS 直接存取協定存取 Hadoop 叢集。對於駐留在物件儲存中的資料集， NetApp StorageGRID提供 S3 和 S3a 安全存取。</block>
  <block id="881214767967db331c99550277ceb793" category="summary">本頁介紹了 Splunk 架構，包括關鍵定義、Splunk 分散式部署、Splunk SmartStore、資料流、硬體和軟體需求、單一站點和多站點要求等。</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunk 架構</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">本節介紹 Splunk 架構，包括關鍵定義、Splunk 分散式部署、Splunk SmartStore、資料流、硬體和軟體需求、單一站點和多站點需求等。</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">關鍵定義</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">接下來的兩個表格列出了分散式 Splunk 部署中使用的 Splunk 和NetApp元件。</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">此表列出了分散式 Splunk Enterprise 配置的 Splunk 硬體元件。</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunk 元件</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">任務</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">索引器</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Splunk Enterprise 資料儲存庫</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">通用轉發器</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">負責提取資料並將資料轉發給索引器</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">搜尋頭</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">用於在索引器中搜尋資料的使用者前端</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">叢集主節點</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">管理索引器和搜尋頭的 Splunk 安裝</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">監控控制台</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">整個部署中使用的集中監控工具</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">許可證主控</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">許可證管理員處理 Splunk Enterprise 許可</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">部署伺服器</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">更新配置並將應用程式分發到處理組件</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">儲存組件</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">用於管理熱層資料的全快閃儲存。也稱為本地儲存。</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">用於管理熱層資料的 S3 物件儲存。 SmartStore 使用它在熱層和溫層之間移動資料。也稱為遠端儲存。</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">下表列出了 Splunk 儲存架構中的元件。</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">負責組件</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">智慧商店</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">為索引器提供將資料從本機儲存分層到物件儲存的能力。</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">熱的</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">通用轉發器放置新寫入資料的著陸點。儲存是可寫的，資料是可搜尋的。此資料層通常由 SSD 或快速 HDD 組成。</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">快取管理器</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">管理索引資料的本地緩存，在搜尋時從遠端儲存中獲取熱數據，並從快取中逐出最不常用的數據。</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">溫暖的</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">資料按邏輯捲動到儲存桶，首先從熱層重新命名為暖層。此層內的資料受到保護，與熱層一樣，可以由更大容量的 SSD 或 HDD 組成。使用常見的資料保護解決方案支援增量備份和完整備份。</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Splunk 分散式部署</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">為了支援資料來自多台機器的更大環境，您需要處理大量資料。如果許多使用者需要搜尋數據，您可以透過在多台機器上分發 Splunk Enterprise 實例來擴展部署。這被稱為分散式部署。</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">在典型的分散式部署中，每個 Splunk Enterprise 執行個體執行一項專門的任務，並駐留在與主要處理功能相對應的三個處理層之一上。</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">下表列出了 Splunk Enterprise 處理層。</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">層級</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">成分</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">描述</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">資料輸入</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">貨運代理</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">轉發器消費數據，然後將數據轉發給一組索引器。</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">索引</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">索引器對通常從一組轉發器接收的傳入資料進行索引。索引器將資料轉換為事件並將事件儲存在索引中。索引器也會根據搜尋頭的搜尋請求搜尋索引資料。</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">搜尋管理</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">搜尋頭是搜尋的中心資源。叢集中的搜尋頭是可互換的，並且可以從搜尋頭叢集的任何成員存取相同的搜尋、儀表板、知識對像等。</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">下表列出了在分散式 Splunk Enterprise 環境中使用的重要元件。</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">責任</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">索引集群主節點</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">協調索引器集群的活動和更新</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">索引管理</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">索引集群</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">配置為相互複製資料的 Splunk Enterprise 索引器組</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">搜尋頭部署器</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">處理叢集主控的部署與更新</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">搜尋頭管理</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">搜尋頭集群</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">一組搜尋頭，作為搜尋的中心資源</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">負載平衡器</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">由叢集元件使用，以處理搜尋頭、索引器和 S3 目標不斷增長的需求，從而在叢集元件之間分配負載。</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">叢集元件的負載管理</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">請參閱 Splunk Enterprise 分散式部署的以下優點：</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">存取多樣化或分散的資料來源</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">提供處理任何規模和複雜程度的企業資料需求的功能</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">透過資料複製和多站點部署實現高可用性並確保災難復原</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore 是一種索引器功能，它使遠端物件儲存（如 Amazon S3）能夠儲存索引資料。隨著部署的資料量增加，對儲存的需求通常會超過對運算資源的需求。  SmartStore 可讓您透過單獨擴充這些資源來經濟高效地管理索引器儲存和運算資源。</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore 引入了遠端儲存層和快取管理器。這些功能允許資料駐留在本機索引器上或遠端儲存層。快取管理器管理索引器和索引器上配置的遠端儲存層之間的資料移動。</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">使用 SmartStore，您可以將索引器儲存佔用空間降至最低，並選擇針對 I/O 最佳化的運算資源。大多數資料駐留在遠端儲存上。索引器維護一個包含最少量資料的本地快取：熱儲存桶、參與活動或最近搜尋的熱儲存桶副本以及儲存桶元資料。</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Splunk SmartStore 資料流</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">當來自各個來源的資料到達索引器時，資料會被索引並本地保存在熱存儲桶中。索引器還將熱存儲桶資料複製到目標索引器。到目前為止，資料流與非 SmartStore 索引的資料流相同。</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">當熱桶變暖時，資料流就會分叉。來源索引器將熱儲存桶複製到遠端物件儲存（遠端儲存層），同時將現有副本保留在其快取中，因為搜尋往往會遇到最近索引的資料。但是，目標索引器會刪除其副本，因為遠端儲存無需維護多個本機副本即可提供高可用性。儲存桶的主副本現在位於遠端儲存中。</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">下圖顯示了 Splunk SmartStore 資料流。</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">索引器上的快取管理器是 SmartStore 資料流的核心。它根據需要從遠端儲存中獲取儲存桶的副本來處理搜尋請求。它還會從快取中逐出較舊或搜尋較少的儲存桶副本，因為它們參與搜尋的可能性會隨著時間的推移而降低。</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">快取管理器的工作是優化可用快取的使用，同時確保搜尋可以立即存取所需的儲存桶。</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">下表列出了實施該解決方案所需的軟體元件。解決方案實施過程中所使用的軟體元件可能會根據客戶要求而有所不同。</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">產品系列</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">產品名稱</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">產品版本</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">作業系統</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRID物件存儲</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">無</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise 與 SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">單站點和多站點要求</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">在企業 Splunk 環境（中型和大型部署）中，資料源自多台機器，許多使用者需要搜尋數據，您可以透過在單一和多個網站上分發 Splunk Enterprise 實例來擴展部署。</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">下表列出了在分散式 Splunk Enterprise 環境中使用的元件。</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">配置為相互複製資料的 Splunk Enterprise 索引器組</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">負載平衡器</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">叢集元件的負載管理</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">該圖描繪了單站點分散式部署的範例。</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">該圖描繪了多站點分散式部署的範例。</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">下表列出了實施該解決方案所需的最少硬體組件數量。解決方案具體實施中使用的硬體組件可能會根據客戶要求而有所不同。</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">無論您在單一網站或多個網站部署了 Splunk SmartStore 和StorageGRID ，所有系統都透過StorageGRID GRID Manager 在單一玻璃窗格中進行管理。有關更多詳細信息，請參閱“使用網格管理器進行簡單管理”部分。</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">該表列出了單一站點使用的硬體。</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">磁碟</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">可用容量</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">筆記</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">管理節點和負載平衡器</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48，8TB（NL-SAS 硬碟）</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">遠端儲存</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">下表列出了用於多站點配置（每個站點）的硬體。</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">管理節點和負載平衡器</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRID負載平衡器：SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">物件儲存需要使用負載平衡器來呈現雲端儲存命名空間。  StorageGRID支援來自 F5 和 Citrix 等領先供應商的第三方負載平衡器，但許多客戶選擇企業級StorageGRID平衡器以實現簡單性、彈性和高效能。  StorageGRID負載平衡器可作為虛擬機器、容器或專用設備使用。</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000 有助於使用高可用性 (HA) 群組和 S3 資料路徑連接的智慧負載平衡。沒有其他內部部署物件儲存系統提供客製化的負載平衡器。</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">SG1000 設備提供以下功能：</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">StorageGRID系統的負載平衡器和管理節點（選用）功能</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">StorageGRID Appliance Installer 可簡化節點部署與配置</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">簡化 S3 端點和 SSL 的配置</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">專用頻寬（而不是與其他應用程式共用第三方負載平衡器）</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">高達 4 x 100Gbps 聚合乙太網路頻寬</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">下圖顯示了 SG1000 網關服務設備。</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">StorageGRID SG6060 設備包括一個運算控制器（SG6060）和一個儲存控制器架（E 系列 E2860），其中包含兩個儲存控制器和 60 個磁碟機。本設備具有以下功能：</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">在單一命名空間中擴展到 400PB。</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">高達 4x 25Gbps 的聚合乙太網路頻寬。</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">包括StorageGRID Appliance Installer，以簡化節點部署和配置。</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">每個 SG6060 設備可以有一個或兩個額外的擴充架，總共可容納 180 個驅動器。</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">兩個 E 系列 E2800 控制器（雙工配置）提供儲存控制器故障轉移支援。</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">五抽屜驅動器架，可容納 60 個 3.5 吋驅動器（兩個固態驅動器和 58 個 NL-SAS 驅動器）。</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">下圖顯示了 SG6060 設備。</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Splunk 設計</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">下表列出了單一網站的 Splunk 配置。</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">核心</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">作業系統</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 核</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB 內存</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">管理用戶數據</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">用戶前端在索引器中搜尋數據</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">處理搜尋頭集群的更新</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">管理 Splunk 安裝和索引器</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">監控控制台和許可證主控器</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">對整個 Splunk 部署進行集中監控並管理 Splunk 許可證</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">下表描述了多站點配置的 Splunk 配置。</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">下表列出了多站點配置（站點 A）的 Splunk 配置。</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">負責提取資料並將資料轉發給索引器。</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">對整個 Splunk 部署進行集中監控並管理 Splunk 許可證。</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">下表列出了多站點配置（站點 B）的 Splunk 配置。</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">Splunk Enterprise 是市場領先的 SIEM 解決方案，可推動安全、IT 和 DevOps 團隊取得成果。</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">Splunk Enterprise 是市場領先的 SIEM 解決方案，可推動安全、IT 和 DevOps 團隊取得成果。我們客戶組織中 Splunk 的使用量已顯著增加。因此，需要增加更多資料來源，同時保留更長的數據，從而給 Splunk 基礎設施帶來壓力。</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Splunk SmartStore 和NetApp StorageGRID的結合旨在為組織提供可擴展的架構，以透過 SmartStore 和StorageGRID物件儲存實現更高的攝取效能，並提高跨多個地理區域的 Splunk 環境的可擴展性。</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">NetApp StorageGRID文件資源</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Splunk Enterprise 文檔</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise 關於 SmartStore</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Splunk Enterprise 分散式部署手冊</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise 管理索引器和索引器集群</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">本技術報告概述了NetApp為 Splunk SmartStore 解決方案帶來的優勢，同時示範了在您的環境中設計和調整 Splunk SmartStore 大小的框架。最終結果是一個簡單、可擴展且有彈性的解決方案，可提供極具吸引力的 TCO。</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869： NetApp StorageGRID與 Splunk SmartStore</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">Splunk Enterprise 是市場領先的安全資訊和事件管理 (SIEM) 解決方案，可推動安全、IT 和 DevOps 團隊取得成果。</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">概況</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">數據量持續以指數級增長，為能夠利用這一巨大資源的企業創造了巨大的機會。 Splunk Enterprise 在更廣泛的使用案例中被廣泛採用。隨著用例的成長，Splunk Enterprise 提取和處理的資料量也在增加。 Splunk Enterprise 的傳統架構是分散式橫向擴展設計，提供出色的資料存取和可用性。然而，使用這種架構的企業面臨著與擴展相關的成本不斷增長的問題，以滿足快速增長的資料量。</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">採用NetApp StorageGRID的 Splunk SmartStore 透過提供計算和儲存分離的新部署模型解決了這個難題。該解決方案還允許客戶跨單一和多個站點進行擴展，從而為 Splunk Enterprise 環境提供無與倫比的規模和彈性，同時透過允許運算和儲存獨立擴展並為經濟高效的基於雲端的 S3 物件儲存添加智慧分層來降低成本。</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">該解決方案在保持搜尋效能的同時優化了本地儲存的資料量，允許按需擴展運算和儲存。  SmartStore 會自動評估資料存取模式，以確定哪些資料需要即時分析，哪些資料應該駐留在成本較低的 S3 物件儲存中。</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">本技術報告概述了NetApp為 Splunk SmartStore 解決方案帶來的優勢，同時示範了在您的環境中設計和調整 Splunk SmartStore 大小的框架。最終結果是一個簡單、可擴展且有彈性的解決方案，可提供極具吸引力的 TCO。  StorageGRID提供可擴展且經濟高效的基於 S3 協定/API 的物件儲存（也稱為遠端儲存），使組織能夠以較低的成本擴展其 Splunk 解決方案，同時提高彈性。</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore 將物件儲存稱為遠端儲存或遠端儲存層。</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">關於NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID是一種軟體定義的物件儲存解決方案，適用於大型檔案、媒體儲存庫和 Web 資料儲存。借助StorageGRID， NetApp利用二十年來提供業界領先的創新和資料管理解決方案的經驗，同時幫助組織管理和最大化其內部以及公共、私有或混合雲部署中的資訊價值。</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID為大規模非結構化資料提供安全、持久的儲存。整合的、元資料驅動的生命週期管理策略可最佳化資料在整個生命週期中的儲存位置。將內容放置在正確的位置、正確的時間以及正確的儲存層以降低成本。單一命名空間允許透過單一呼叫存取數據，而不管StorageGRID儲存的地理位置如何。客戶可以在資料中心之間和雲端基礎設施中部署和管理多個StorageGRID實例。</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">StorageGRID系統由全球分佈、冗餘、異質的節點組成，可與現有和下一代用戶端應用程式整合。</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape 最近在最新報告《IDC MarketScape：2019 年全球基於物件的儲存供應商評估》中將NetApp評為領導者。  StorageGRID擁有近 20 年在要求最嚴格的行業中進行生產部署的經驗，是非結構化資料領域公認的領導者。</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">使用StorageGRID，您可以實現以下目標：</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">部署多個StorageGRID實例，透過可輕鬆擴展到數百 PB 的單一命名空間存取資料中心和雲端之間任何位置的資料。</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">提供跨基礎設施部署和集中管理的靈活性。</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">利用分層擦除編碼 (EC) 提供無與倫比的耐用性，耐用性達到 15 個 9。</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">透過與 Amazon S3 Glacier 和 Azure Blob 進行驗證的集成，實現更多混合多雲功能。</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">透過防篡改資料保留滿足監管義務並促進合規性，無需專有 API 或供應商鎖定。</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRID主頁</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">有關StorageGRID如何幫助您解決最複雜的非結構化資料管理問題的更多信息，請參閱<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>。</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">關於Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise 是一個將資料轉化為行動的平台。日誌檔案、網站、裝置、感測器和應用程式等各種來源產生的資料會傳送到 Splunk Indexer 並由其解析，使您可以從資料中獲得豐富的見解。它可能識別資料外洩、指出客戶和產品趨勢、尋找優化基礎架構的機會或在各種用例中創建可操作的見解。</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">關於Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore 擴展了 Splunk 架構的優勢，同時簡化了其經濟高效擴展的能力。計算和儲存資源的分離導致索引器節點針對 I/O 進行了最佳化，並且儲存需求顯著減少，因為它們僅將一部分資料儲存為快取。當只需要其中一種資源時，您不必添加額外的計算或存儲，從而可以實現顯著的成本節約。您可以使用經濟高效且易於擴展的基於 S3 的物件存儲，這進一步簡化了環境、降低了成本並允許您維護更龐大的資料集。</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore 為組織帶來巨大價值，包括：</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">透過將熱數據移至成本優化的 S3 物件儲存來降低儲存成本</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">透過分離儲存和運算實現無縫擴展</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">利用彈性雲原生儲存簡化業務連續性</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">本頁介紹了NetApp StorageGRID控制器上的 Splunk SmartStore 效能。</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">單站點 SmartStore 效能</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">本節介紹 Splunk SmartStore 在NetApp StorageGRID控制器上的效能。  Splunk SmartStore 將熱資料移至遠端存儲，在本例中是效能驗證中的StorageGRID物件儲存。</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">我們使用 EF600 作為熱/快取存儲，使用StorageGRID 6060 作為遠端儲存。我們使用以下架構進行效能驗證。我們使用了兩個搜尋頭、四個重型轉發器將數據轉發到索引器、七個 Splunk 事件產生器（Eventgens）來產生即時數據，以及 18 個索引器來儲存數據。</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">配置</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">下表列出了用於 SmartStorage 效能驗證的硬體。</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">重型貨運代理</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 核</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">用戶前端在索引器中搜尋數據</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">SmartStore遠端商店效能驗證</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">在本次效能驗證中，我們在所有索引器的本機儲存中配置了 SmartStore 緩存，以保存 10 天的資料。我們啟用了<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block>（750MB 儲存桶大小）在 Splunk 叢集管理器中並將變更推送到所有索引器。為了測量上傳效能，我們在 10 天內每天攝取 10TB 的數據，並同時將所有熱儲存桶轉為熱儲存桶，並從 SmartStore 監控控制台儀表板擷取每個實例和整個部署的峰值和平均吞吐量。</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">此圖顯示了一天內攝取的數據。</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">我們從叢集主節點執行以下命令（索引名稱是<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block>）。然後，我們透過 SmartStore 監控控制台儀表板捕獲每個實例和整個部署的峰值和平均上傳吞吐量。</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">群集主機對所有索引器（rtp-idx0001…rtp-idx0018）均採用無密碼身份驗證。</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">為了測量下載效能，我們使用以下命令執行兩次 evict CLI，從快取中逐出所有資料。</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">我們從叢集主機執行以下命令，並從搜尋頭基於來自StorageGRID的遠端儲存的 10 天資料運行搜尋。然後，我們透過 SmartStore 監控控制台儀表板捕獲每個實例和整個部署的峰值和平均上傳吞吐量。</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">索引器配置是從 SmartStore 叢集主機推送的。群集主機對索引器有以下配置。</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">我們在搜尋頭上執行了以下搜尋查詢來收集效能矩陣。</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">我們從叢集主機收集了效能資訊。峰值性能為61.34GBps。</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">平均效能約 29GBps。</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">StorageGRID性能</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">事件生成</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">SmartStore 的效能是基於從大量資料中搜尋特定的模式和字串。在此驗證中，事件是使用<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block>透過搜尋頭在特定的 Splunk 索引（eventgen-test）上進行搜索，並且請求對於大多數查詢轉到StorageGRID 。下圖顯示了查詢資料的命中和未命中情況。命中資料來自本機磁碟，未命中資料來自StorageGRID控制器。</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">綠色顯示命中數據，橘色顯示未命中數據。</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">當在StorageGRID上執行搜尋查詢時， StorageGRID的 S3 擷取率的時間如下圖所示。</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">StorageGRID硬體使用量</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">StorageGRID實例有一個負載平衡器和三個StorageGRID控制器。所有三個控制器的 CPU 使用率均為 75% 至 100%。</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">採用NetApp儲存控制器的 SmartStore - 為客戶帶來好處</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*將計算和存儲分離。 *  Splunk SmartStore 將運算和儲存分離，幫助您獨立擴展它們。</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*按需提供資料。 *  SmartStore 使資料接近按需運算，並提供運算和儲存彈性和成本效率，以實現更長時間的大規模資料保留。</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*符合 AWS S3 API。 *  SmartStore 使用 AWS S3 API 與復原儲存進行通信，恢復儲存是符合 AWS S3 和 S3 API 的物件存儲，例如StorageGRID。</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*減少儲存需求和成本。 * SmartStore 減少了老化資料（暖/冷）的儲存要求。它只需要一份資料副本，因為NetApp儲存提供資料保護並處理故障和高可用性。</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*硬體故障。 *  SmartStore 部署中的節點故障不會導致資料無法訪問，並且索引器從硬體故障或資料不平衡中恢復的速度更快。</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">應用程式和資料感知快取。</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">按需新增或刪除索引器以及設定或拆除叢集。</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">儲存層不再與硬體相關。</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">此解決方案允許添加運算、熱儲存或 S3 資源，以滿足單一站點和多站點部署中使用者數量或攝取率不斷增長的需求。</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">此解決方案的優勢</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*表現。 *  Splunk SmartStore 和NetApp StorageGRID的結合使用物件儲存在熱儲存桶和溫儲存桶之間實現資料的快速遷移。  StorageGRID透過為大型物件工作負載提供快速效能來加速遷移過程。</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*多站點就緒。 *  StorageGRID分散式架構允許 Splunk SmartStore 透過單一全域命名空間擴展跨單一和多個站點的部署，無論資料位於何處，都可以從任何網站存取資料。</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*提高了可擴展性。 *獨立於運算資源擴展儲存資源，以滿足 Splunk 環境中不斷變化的需求，從而提供更好的 TCO。</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*容量。 *使用StorageGRID將單一命名空間擴展到 560PB 以上，滿足 Splunk 部署中快速成長的容量。</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*數據可用性。 *使用元資料驅動的策略來優化資料可用性、效能、地理分佈、保留、保護和儲存成本，這些策略可以隨著資料的業務價值的發展而動態調整。</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Splunk 提供的指南</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">使用 SmartStore 快取提高效能，它是索引器的一個元件，負責處理本地（熱）儲存和遠端（溫）儲存之間的儲存桶副本傳輸。此解決方案的 Splunk 規模基於<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>。此解決方案允許添加運算、熱儲存或 S3 資源，以滿足單一站點和多站點部署中使用者數量或攝取率不斷增長的需求。</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">本頁介紹了完成此解決方案所使用的元件，包括NetApp StorageGRID、Splunk Enterprise 和 Splunk SmartStore。</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">解決方案概述</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID是一個高效能且經濟高效的物件儲存平台。它使用分散式、基於節點的網格架構提供智慧、策略驅動的全球資料管理。它透過其無所不在的全域物件命名空間與複雜的資料管理功能結合，簡化了 PB 級非結構化資料和數十億個物件的管理。單次呼叫物件存取可跨站點擴展，並簡化高可用性架構，同時確保無論站點或基礎設施是否中斷，都能持續進行物件存取。</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">多租戶允許多個雲端和企業非結構化資料應用程式在同一網格內安全地服務，從而增加了StorageGRID的投資回報率和用例。可以使用元資料驅動的物件生命週期策略來建立多個服務級別，從而優化跨多個地區的耐用性、保護性、效能和局部性。隨著需求的變化，使用者可以調整策略並且無中斷地重新調整資料格局。</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore 利用StorageGRID作為遠端儲存層，並允許客戶部署多個地理分佈的站點，以實現強大的可用性和耐用性，並以單一物件命名空間的形式呈現。這使得 Splunk SmartStore 能夠利用StorageGRID的高效能、高密度容量以及使用單一 URL 與物件互動擴展到多個實體網站上的數百個節點的能力。此單一 URL 還允許在不中斷的情況下進行儲存擴充、升級和修復，甚至超越單一網站。  StorageGRID獨特的資料管理策略引擎提供了最佳化的效能和耐用性水平，並符合資料局部性要求。</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk 是機器生成資料收集和分析的領導者，透過其營運分析功能幫助簡化和現代化 IT。它還擴展到商業分析、安全性和物聯網用例。儲存是成功部署 Splunk 軟體的關鍵因素。</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">機器產生的數據是成長最快的大數據類型。其格式難以預測，並且來自許多不同的來源，通常速率很高且數量巨大。這些工作負載特徵通常被稱為數位排氣。  Splunk SmartStore 有助於理解這些資料並提供智慧資料分層，以便在最具成本效益的儲存層上優化放置熱資料和溫資料。</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore 是一種索引器功能，它使用物件儲存（也稱為遠端儲存或遠端儲存層）例如StorageGRID透過 S3 協定儲存熱資料。</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">隨著部署的資料量增加，對儲存的需求通常會超過對電腦資源的需求。  SmartStore 可讓您透過分別擴展運算和儲存來經濟高效地管理索引器儲存和運算資源。</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore 引入了使用 S3 協定的遠端儲存層和快取管理器。這些功能允許資料駐留在本機索引器或遠端儲存上。快取管理器位於索引器上，負責管理索引器和遠端儲存層之間的資料移動。資料與儲存桶元資料一起儲存在儲存桶（熱和溫）中。</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">使用 SmartStore，您可以將索引器儲存佔用空間降至最低，並選擇 I/O 最佳化的運算資源，因為大多數資料都駐留在遠端儲存層上。索引器維護一個本地緩存，代表返回請求和預測結果所需的最少資料量。本地快取包含熱儲存桶、參與活動或最近搜尋的熱儲存桶副本以及儲存桶元資料。</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">具有StorageGRID的 Splunk SmartStore 使客戶能夠透過高效能且經濟高效的遠端儲存逐步擴展環境，同時為整體解決方案提供高度的彈性。這使得客戶可以在任何給定時間添加任何給定數量的任何組件（熱存儲和/或溫 S3 存儲），無論他們是需要更多索引器、更改資料保留，還是在不造成任何中斷的情況下增加攝取率。</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">StorageGRID具有多種功能，使用者可以利用這些功能並根據不斷變化的環境進行自訂。</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">適用於 Splunk SmartStore 的靈活StorageGRID功能</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">StorageGRID具有多種功能，使用者可以利用這些功能並根據不斷變化的環境進行自訂。從部署到擴展您的 Splunk SmartStore，您的環境需要快速適應變化，並且不應對 Splunk 造成乾擾。  StorageGRID靈活的資料管理策略 (ILM) 和流量分類器 (QoS) 讓您可以規劃並適應您的環境。</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager 是基於瀏覽器的圖形介面，可讓您在單一玻璃窗格中配置、管理和監控全球分佈位置的StorageGRID系統，如下圖所示。</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">使用網格管理器介面執行以下任務：</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">適用於 Splunk 的NetApp StorageGRID應用程式</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">NetApp StorageGRID App for Splunk 是專用於 Splunk Enterprise 的應用程式。此應用程式與 Splunk 的NetApp StorageGRID附加元件搭配使用。它提供對StorageGRID健康狀況、帳戶使用資訊、安全審計詳細資訊、資源使用情況和監控等方面的可見性。</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">下圖顯示了適用於 Splunk 的StorageGRID應用程式。</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILM 策略</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">StorageGRID具有靈活的資料管理策略，包括保留對象的多個副本，並使用 2+1 和 4+2（以及許多其他）等 EC（擦除編碼）方案來儲存對象，具體取決於特定的效能和資料保護要求。由於工作負載和需求隨時間而變化，ILM 策略通常也必須隨時間而變化。修改 ILM 策略是一項核心功能，可讓StorageGRID客戶快速輕鬆地適應不斷變化的環境。</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID透過增加更多節點來擴展效能，這些節點可以是虛擬機器、裸機或專用設備，如 SG5712、SG5760、SG6060 或 SGF6024。在我們的測試中，我們使用 SG6060 設備以最小尺寸的三節點網格超出了 SmartStore 關鍵效能要求。當客戶使用附加索引器擴展其 Splunk 基礎架構時，他們可以添加更多儲存節點來提高效能和容量。</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">負載平衡器和端點配置</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">StorageGRID中的管理節點提供網格管理器 UI（使用者介面）和 REST API 端點來檢視、設定和管理您的StorageGRID系統，以及稽核日誌來追蹤系統活動。為了為 Splunk SmartStore 遠端儲存提供高可用性 S3 端點，我們實作了StorageGRID負載平衡器，它作為管理節點和網關節點上的服務運作。此外，負載平衡器還管理本地流量並與 GSLB（全域伺服器負載平衡）對話以協助進行災難復原。</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">為了進一步增強端點配置， StorageGRID提供了內建於管理節點的流量分類策略，讓您監控工作負載流量，並對工作負載套用各種服務品質 (QoS) 限制。流量分類策略應用於網關節點和管理節點的StorageGRID負載平衡器服務上的端點。這些策略可以幫助限制和監控流量。</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">當客戶意識到 Splunk 數據分析的強大功能和易用性時，他們自然希望索引不斷增長的數據量。隨著資料量的增長，服務資料所需的運算和儲存基礎設施也在增長。</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">智慧分層和成本節約</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">當客戶意識到 Splunk 數據分析的強大功能和易用性時，他們自然希望索引不斷增長的數據量。隨著資料量的增長，服務資料所需的運算和儲存基礎設施也在增長。由於舊資料的引用頻率較低，因此投入相同數量的運算資源並消耗昂貴的主儲存變得越來越低效。為了大規模運營，客戶可以將熱數據移動到更具成本效益的層，從而釋放熱數據的運算和主儲存。</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">具有StorageGRID 的Splunk SmartStore 為組織提供了可擴展、高效且經濟高效的解決方案。由於 SmartStore 具有資料感知能力，它會自動評估資料存取模式，以確定哪些資料需要即時分析（熱資料），哪些資料應該駐留在低成本的長期儲存中（溫資料）。  SmartStore 動態且智慧地使用業界標準的 AWS S3 API，將資料放置在StorageGRID提供的 S3 儲存體中。  StorageGRID靈活的橫向擴展架構允許熱資料層根據需要以經濟高效的方式進行成長。  StorageGRID基於節點的架構確保效能和成本需求最佳滿足。</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">下圖說明了 Splunk 和StorageGRID分層。</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">Splunk SmartStore 與NetApp StorageGRID的業界領先組合透過全端解決方案提供了解耦架構的優勢。</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623： NetApp E 系列 E5700 和 Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">NetApp的 Mitch Blackburn</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 描述了NetApp E 系列和 Splunk 設計的整合架構。此設計針對節點儲存均衡、可靠性、效能、儲存容量、密度等進行了最佳化，採用了Splunk聚集索引節點模型，具有更高的可擴展性和更低的TCO。將儲存與計算分離可以分別擴展，從而節省過度配置其中一個或另一個的成本。此外，本文檔也總結了透過Splunk機器日誌事件模擬工具所獲得的效能測試結果。</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">NetApp AI 功能可實現跨 AI 管道的無縫資料管理和資料移動，以進行訓練、再訓練、微調、推理和監控生成 AI 模型。</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">生成式人工智慧和NetApp價值</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">對產生人工智慧 (AI) 的需求正在推動各行業的顛覆，增強商業創造力和產品創新。</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">許多組織正在使用生成式人工智慧來建立新的產品功能、提高工程生產力和原型人工智慧應用程序，以提供更好的結果和消費者體驗。生成式人工智慧（例如生成式預訓練轉換器 (GPT)）使用神經網路來創建新內容，包括文字、音訊和視訊等多種內容。鑑於大型語言模型 (LLM) 涉及的極端規模和大量資料集，在公司設計 AI 解決方案之前，建立強大的 AI 基礎架構至關重要，該基礎架構可以利用內部部署、混合和多雲部署選項的強大資料儲存功能，並降低與資料移動性、資料保護和治理相關的風險。本文介紹了這些考慮因素以及相應的NetApp AI 功能，這些功能支援跨 AI 資料管道進行無縫資料管理和資料移動，以訓練、再訓練、微調和推理生成 AI 模型。</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">執行摘要</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">最近，自 2022 年 11 月推出 GPT-3 的衍生產品 ChatGPT 以來，用於根據用戶提示生成文字、程式碼、圖像甚至治療性蛋白質的新型 AI 工具獲得了極大的聲譽。這表明用戶可以使用自然語言提出請求，人工智慧將解釋和生成文本，例如反映用戶請求的新聞文章或產品描述，或使用基於現有數據訓練的演算法生成程式碼、音樂、語音、視覺效果和 3D 資產。因此，穩定擴散、幻覺、快速工程和價值一致性等短語正在人工智慧系統的設計中迅速湧現。這些自監督或半監督機器學習 (ML) 模型正作為預先訓練的基礎模型 (FM) 透過雲端服務提供者和其他 AI 公司供應商得到廣泛應用，各行各業的各種商業機構正在採用這些模型來執行廣泛的下游 NLP (自然語言處理) 任務。正如麥肯錫等研究分析公司所言——“生成式人工智慧對生產力的影響可能會為全球經濟增加數萬億美元的價值。”當企業將人工智慧重新想像為人類的思想夥伴，而設施管理者也同時拓展企業和機構利用生成性人工智慧的能力時，管理大量資料的機會將持續成長。本文檔介紹了生成式人工智慧以及與NetApp功能相關的設計概念，這些功能為NetApp客戶（包括本地和混合或多雲環境）帶來了價值。</block>
  <block id="8bcfe22a3d7c5edf904444893704a8de" category="paragraph">*那麼，客戶在其 AI 環境中使用NetApp有什麼好處呢？ *  NetApp幫助組織應對快速資料和雲端成長、多雲管理以及採用 AI 等下一代技術所帶來的複雜性。 NetApp將各種功能整合到智慧資料管理軟體和儲存基礎架構中，並與針對 AI 工作負載最佳化的高效能實現了良好的平衡。像 LLM 這樣的生成式 AI 解決方案需要多次讀取和處理從儲存到記憶體的來源資料集以促進智慧。  NetApp一直是邊緣到核心到雲端生態系統中資料移動性、資料治理和資料安全技術的領導者，幫助企業客戶建立大規模 AI 解決方案。  NetApp憑藉著強大的合作夥伴網絡，一直致力於幫助首席資料長、AI 工程師、企業架構師和資料科學家設計自由流動的資料管道，以完成 AI 模型訓練和推理的資料準備、資料保護和策略資料管理職責，從而優化 AI/ML 生命週期的效能和可擴展性。 NetApp資料技術和功能（例如用於深度學習資料管道的NetApp ONTAP AI、用於在儲存端點之間無縫高效地傳輸資料的NetApp SnapMirror以及用於在資料流從批次轉變為即時且資料工程即時發生時進行即時渲染的NetApp FlexCache）為即時生成 AI 模型的部署帶來了價值。隨著各類企業採用新的人工智慧工具，他們面臨從邊緣到資料中心再到雲端的資料挑戰，需要可擴展、負責任且可解釋的人工智慧解決方案。作為混合和多雲領域的資料權威， NetApp致力於建立合作夥伴和聯合解決方案網絡，以幫助建立資料管道和資料湖的各個方面，以進行生成式 AI 模型訓練（預訓練）、微調、基於上下文的推理和 LLM 的模型衰減監控。</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">什麼是生成式人工智慧？</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">生成式人工智慧正在改變我們創造內容、產生新設計概念和探索新穎構圖的方式。它展示了生成對抗網路 (GAN)、變分自動編碼器 (VAE) 和生成預訓練變壓器 (GPT) 等神經網路框架，它們可以生成文字、程式碼、圖像、音訊、視訊和合成資料等新內容。 OpenAI 的 Chat-GPT、Google 的 Bard、Hugging Face 的 BLOOM 和 Meta 的 LLaMA 等基於 Transformer 的模型已成為支撐大型語言模型諸多進步的基礎技術。同樣，OpenAI 的 Dall-E、Meta 的 CM3leon 和 Google 的 Imagen 都是文本到圖像擴散模型的例子，它們為客戶提供了前所未有的照片級真實感，可以從頭開始創建新的複雜圖像，或編輯現有圖像以生成高質量的上下文感知圖像，使用數據集增強和鏈接文本和視覺語義的文本到圖像合成。數位藝術家開始將 NeRF（神經輻射場）等渲染技術與生成式人工智慧結合，將靜態 2D 影像轉換為沉浸式 3D 場景。一般來說，LLM 大致由四個參數來表徵：（1）模型的大小（通常有數十億個參數）；（2）訓練資料集的大小；（3）訓練成本；（4）訓練後的模型表現。  LLM 也主要分為三種變壓器架構。 （i）僅編碼器模型。例如 BERT（Google，2018）；（ii）編碼器-解碼器，例如 BART（Meta，2020）和（iii）僅解碼器模型。例如LLaMA（Meta，2023 年）、PaLM-E（Google，2023 年）。根據業務需求，無論公司選擇哪種架構，訓練資料集中的模型參數數量（N）和標記數量（D）通常決定訓練（預訓練）或微調 LLM 的基準成本。</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">企業用例與下游 NLP 任務</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">各行各業的企業都發現人工智慧有越來越多的潛力，可以從現有數據中提取並產生新的價值形式，用於業務運營、銷售、行銷和法律服務。根據 IDC（國際數據公司）關於全球生成式人工智慧用例和投資的市場情報，軟體開發和產品設計中的知識管理受到的影響最大，其次是行銷的故事情節創作和開發人員的程式碼生成。在醫療保健領域，臨床研究組織正在開闢醫學新領域。 ProteinBERT 等預訓練模型結合了基因本體 (GO) 註釋，可以快速設計藥物的蛋白質結構，這代表了藥物發現、生物資訊學和分子生物學領域的一個重要里程碑。生物技術公司已啟動生成性人工智慧藥物的人體試驗，旨在治療肺纖維化（IPF）等疾病，這是一種導致肺組織不可逆瘢痕形成的肺部疾病。</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">圖 1：驅動生成式人工智慧的用例</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">生成式人工智慧推動的自動化應用的增加也正在改變許多職業的工作活動的供需。根據麥肯錫的數據，美國勞動市場（下圖）經歷了快速轉型，考慮到人工智慧的影響，這種轉型可能還會持續下去。</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">資料來源：麥肯錫公司</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">圖2：資料來源：麥肯錫公司</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">儲存在生成式人工智慧中的作用</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512MB</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">LLM 主要依賴深度學習、GPU 和運算。然而，當GPU緩衝區填滿時，資料需要快速寫入記憶體。雖然一些 AI 模型足夠小，可以在記憶體中執行，但 LLM 需要高 IOPS 和高吞吐量儲存才能快速存取大型資料集，特別是當它涉及數十億個令牌或數百萬個影像時。對於 LLM 的典型 GPU 記憶體需求，訓練具有 10 億個參數的模型所需的記憶體可能高達 80GB @32 位元全精度。在這種情況下，Meta 的 LLaMA 2（一系列 LLM，規模從 70 億到 700 億個參數）可能需要 70x80、約 5600GB 或 5.6TB 的 GPU RAM。此外，您需要的記憶體量與您想要產生的最大令牌數量成正比。例如，如果你想產生最多 512 個 token（約 380 個單字）的輸出，你需要<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block>。這看起來似乎無關緊要——但是，如果您想運行更大的批次，它就會開始累積。因此，對於組織來說，在記憶體中訓練或微調 LLM 的成本非常高，從而使儲存成為生成 AI 的基石。</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">攻讀法學碩士學位的三種主要途徑</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">《哈佛商業評論》</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">對於大多數企業而言，根據目前的趨勢，部署 LLM 的方法可以概括為 3 種基本情境。正如最近<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block>文章：（1）從頭開始訓練（預訓練）法學碩士——成本高昂，並且需要專業的 AI/ML 技能；（2）使用企業資料微調基礎模型——複雜但可行；（3）使用檢索增強生成 (RAG) 查詢包含公司資料的文件儲存庫、API 和向量資料庫。在實施過程中，每種方法都需要在工作量、迭代速度、成本效率和模型準確性之間進行權衡，以解決不同類型的問題（下圖）。</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">圖 3：問題類型</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">基礎模型</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">基礎模型 (FM) 也稱為基礎模型，是一種大型 AI 模型 (LLM)，使用大規模自我監督對大量未標記資料進行訓練，通常適用於廣泛的下游 NLP 任務。由於訓練資料沒有經過人工標記，因此模型是自然產生的，而不是明確編碼的。這意味著該模型無需明確編程即可產生自己的故事或敘述。因此FM的一個重要特徵是同質化，即在許多領域使用相同的方法。然而，透過個人化和微調技術，如今出現的產品中整合的 FM 不僅擅長生成文字、文字轉圖像和文字轉程式碼，而且還擅長解釋特定領域的任務或偵錯程式碼。例如，OpenAI 的 Codex 或 Meta 的 Code Llama 等 FM 可以根據程式設計任務的自然語言描述產生多種程式語言的程式碼。這些模型精通十幾種程式語言，包括 Python、C#、JavaScript、Perl、Ruby 和 SQL。它們理解使用者的意圖並產生完成所需任務的特定程式碼，這對於軟體開發、程式碼最佳化和程式設計任務的自動化很有用。</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">微調、領域特異性與再訓練</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">Meta 的駱駝 2</block>
  <block id="3983fea9bc2f220141201994aa6cf9de" category="paragraph">在資料準備和資料預處理之後進行 LLM 部署的常見做法之一是選擇已經在大型多樣化資料集上訓練過的預訓練模型。在微調的背景下，這可以是一個開源的大型語言模型，例如<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block>對 700 億個參數和 2 兆個標記進行訓練。一旦選擇了預訓練模型，下一步就是根據特定領域的資料微調。這涉及調整模型的參數並根據新數據對其進行訓練以適應特定的領域和任務。例如，BloombergGPT 是一門專有的法學碩士課程，接受過廣泛金融數據的培訓，服務於金融業。針對特定任務設計和訓練的領域特定模型通常在其範圍內具有更高的準確性和性能，但在其他任務或領域之間的可轉移性較低。當業務環境和資料在一段時間內發生變化時，與測試期間的表現相比，FM 的預測準確性可能會開始下降。這時，重新訓練或微調模型就變得至關重要。傳統 AI/ML 中的模型再訓練是指使用新資料更新已部署的 ML 模型，通常是為了消除發生的兩種類型的漂移。  （1）概念漂移－當輸入變數和目標變數之間的聯繫隨時間而改變時，由於我們想要預測的描述發生了變化，模型可能會產生不準確的預測。 (2) 資料漂移－當輸入資料的特徵發生變化時發生，例如客戶習慣或行為隨時間變化，因此模型無法對此類變化做出反應。類似地，再培訓也適用於 FM/LLM，但成本可能要高得多（數百萬美元），因此大多數組織可能不會考慮。它正處於積極的研究中，在 LLMOps 領域中仍然處於新興階段。因此，當微調 FM 中出現模型衰減時，企業可以選擇使用較新的資料集再次進行微調（便宜得多），而不是重新訓練。從成本角度來看，以下列出了 Azure-OpenAI 服務的模型價格表示例。對於每個任務類別，客戶可以在特定資料集上微調和評估模型。</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">來源：Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">快速工程和推理</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">即時工程是指如何與 LLM 通訊以執行所需任務而無需更新模型權重的有效方法。人工智慧模型訓練和微調對於 NLP 應用非常重要，推理也同樣重要，訓練後的模型可以回應使用者的提示。推理的系統需求通常更多地取決於 AI 儲存系統的讀取性能，該系統將資料從 LLM 輸送到 GPU，因為它需要能夠應用數十億個儲存的模型參數來產生最佳響應。</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps、模型監控和向量存儲</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">與傳統的機器學習操作 (MLOps) 一樣，大型語言模型操作 (LLMOps) 也需要資料科學家和 DevOps 工程師的協作，並使用生產環境中 LLM 管理的工具和最佳實踐。然而，法學碩士的工作流程和技術堆疊在某些方面可能會有所不同。例如，使用 LangChain 等框架建立的 LLM 管道將多個 LLM API 呼叫串聯到外部嵌入端點（例如向量儲存或向量資料庫）。嵌入端點和向量儲存作為下游連接器（如向量資料庫）的使用代表了資料儲存和存取方式的重大發展。與從頭開始開發的傳統 ML 模型相比，LLM 通常依賴遷移學習，因為這些模型從 FM 開始，並使用新資料進行微調以提高在更特定領域的效能。因此，LLMOps 提供風險管理和模型衰減監測功能至關重要。</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">生成人工智慧時代的風險與倫理</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">「ChatGPT——雖然很巧妙，但仍然會輸出一些無意義的信息。」——《麻省理工科技評論》。垃圾進，垃圾出，一直是計算領域的難題。生成式人工智慧的唯一區別在於，它擅長使垃圾高度可信，從而導致不準確的結果。法學碩士 (LLM) 傾向於捏造事實來適應其所建構的敘述。因此，那些將生成式人工智慧視為利用人工智慧降低成本的絕佳機會的公司需要有效地檢測深度偽造、減少偏見並降低風險，以保持系統的誠實和道德。在負責任且可解釋的生成式人工智慧模型的設計中，擁有強大人工智慧基礎設施的自由流動資料管道至關重要，該管道透過端到端加密和人工智慧護欄支援資料移動性、資料品質、資料治理和資料保護。</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">客戶場景和NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">圖 3：機器學習/大型語言模型工作流程</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*我們是在訓練還是微調？ *問題是（a）是否從頭開始訓練 LLM 模型、微調預先訓練的 FM，或使用 RAG 從基礎模型以外的文件儲存庫中檢索資料並增強提示，以及（b）是否利用開源 LLM（例如 Llama 2）或專有 FM（例如 ChatGPT、Bard、AWS Bedrock），對於組織來說是一個策略決策。每種方法都需要在成本效率、資料引力、操作、模型準確性和 LLM 管理之間進行權衡。</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">NetApp公司在其工作文化以及產品設計和工程工作方法中都採用了人工智慧。例如，NetApp 的自主勒索軟體防護是使用人工智慧和機器學習建構的。它提供檔案系統異常的早期檢測，以幫助在威脅影響操作之前識別它們。其次， NetApp將預測性 AI 用於其業務運營，例如銷售和庫存預測，並使用聊天機器人協助客戶提供呼叫中心產品支援服務、技術規格、保固、服務手冊等。第三， NetApp透過產品和解決方案為 AI 資料管道和 ML/LLM 工作流程帶來客戶價值，幫助客戶建立預測性 AI 解決方案，例如需求預測、醫學影像、情緒分析和生成性 AI 解決方案，例如用於ONTAP工業影像異常檢測和銀行及金融服務中反洗錢和詐欺檢測的 GAN ，NetApp NetApp 、 AppApp SnapMirror 、 NetApp FlexCache並</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">NetApp功能</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">聊天機器人、程式碼生成、圖像生成或基因組模型表達等生成式人工智慧應用中的資料移動和管理可以跨越邊緣、私有資料中心和混合多雲生態系統。例如，一個即時人工智慧機器人可以透過 ChatGPT 等預先訓練模型的 API 公開的終端用戶應用程式來幫助乘客將機票升級到商務艙，但由於乘客資訊並未在網路上公開，因此該機器人無法自行完成該任務。該 API 需要存取乘客的個人資訊和航空公司的機票信息，這些資訊可能存在於混合或多雲生態系統中。類似的情況可能適用於科學家透過最終用戶應用程式共享藥物分子和患者數據，該應用程式使用 LLM 完成涉及一對多生物醫學研究機構的藥物發現臨床試驗。傳遞給 FM 或 LLM 的敏感資料可能包括 PII、財務資訊、健康資訊、生物特徵資料、位置資料、通訊資料、線上行為和法律資訊。在即時渲染、快速執行和邊緣推理的情況下，資料會透過開源或專有 LLM 模型從最終用戶應用程式移動到儲存端點，再移動到內部資料中心或公有雲平台。在所有這些場景中，資料移動性和資料保護對於依賴大量訓練資料集及其移動的 LLM 的 AI 操作至關重要。</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">圖 4：生成式 AI - LLM 資料管道</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">圖 4：生成式 AI-LLM 資料管道</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">NetApp 的儲存基礎架構、資料和雲端服務產品組合由智慧資料管理軟體提供支援。</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*資料準備*：LLM 技術棧的第一個支柱與舊的傳統 ML 棧基本沒有變化。人工智慧管道中的資料預處理是必要的，以便在訓練或微調之前對資料進行標準化和清理。此步驟包括連接器，用於提取位於任何位置的數據，無論數據是以 Amazon S3 層的形式駐留在本地存儲系統（例如文件存儲或NetApp StorageGRID之類的對象存儲）中。</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP* 是 NetApp 在資料中心和雲端的關鍵儲存解決方案的基礎技術。  ONTAP包含各種資料管理和保護特性和功能，包括針對網路攻擊的自動勒索軟體保護、內建資料傳輸功能以及適用於本機、混合、NAS、SAN、物件和軟體定義儲存 (SDS) 等多種架構的儲存效率功能。 LLM 部署的情況。</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* NetApp ONTAP AI* 用於深度學習模型訓練。對於擁有ONTAP儲存叢集和NVIDIA DGX 運算節點的NetApp客戶， NetApp ONTAP支援使用 NFS over RDMA 實作NVIDIA GPU 直接儲存。它以經濟高效的性能多次讀取和處理來自存儲的源數據集到內存中以促進智能，使組織能夠對 LLM 進行培訓、微調和擴展訪問。</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache* 是一種遠端快取功能，可簡化檔案分發並僅快取主動讀取的資料。這對於 LLM 訓練、再訓練和微調非常有用，為具有即時渲染和 LLM 推理等業務需求的客戶帶來價值。</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror* 是ONTAP 的一項功能，可在任兩個ONTAP系統之間複製磁碟區快照。此功能可最佳地將邊緣資料傳輸到您的本機資料中心或雲端。當客戶希望使用包含企業資料的 RAG 在雲端中開發生成性 AI 時， SnapMirror可用於在本地和超大規模雲端之間安全且有效率地移動資料。它有效地僅傳輸更改，節省頻寬並加快複製速度，從而在 FM 或 LLM 的訓練、再訓練和微調操作期間帶來必要的資料移動功能。</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* NetApp SnapLock* 為基於ONTAP的儲存系統帶來不可變磁碟功能，用於資料集版本控制。微核架構旨在透過 FPolicy Zero Trust 引擎保護客戶資料。當攻擊者以特別耗費資源的方式與 LLM 互動時， NetApp可透過抵禦拒絕服務 (DoS) 攻擊來確保客戶資料可用。</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* NetApp Cloud Data Sense* 有助於識別、映射和分類企業資料集中的個人信息，制定政策，滿足本地或雲端的隱私要求，幫助改善安全態勢並遵守法規。</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">* NetApp BlueXP* 分類，由 Cloud Data Sense 提供支援。客戶可以自動掃描、分析、分類和處理資料資產中的數據，偵測安全風險，優化儲存並加速雲端部署。它透過統一的控制平面結合了儲存和資料服務，客戶可以使用 GPU 執行個體進行運算，並使用混合多雲環境進行冷儲存分層以及存檔和備份。</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">* NetApp檔案物件二元性*。 NetApp ONTAP支援 NFS 和 S3 的雙協定存取。透過此解決方案，客戶可以透過NetApp Cloud Volumes ONTAP的 S3 儲存桶存取來自 Amazon AWS SageMaker 筆記本的 NFS 資料。這為需要輕鬆存取異質資料來源並能夠從 NFS 和 S3 共享資料的客戶提供了靈活性。例如，在 SageMaker 上透過存取檔案物件儲存桶來微調 FM，例如 Meta 的 Llama 2 文字生成模型。</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">* NetApp Cloud Sync* 服務提供了一種簡單、安全的方式將資料遷移到雲端或本地的任何目標。  Cloud Sync在本機或雲端儲存、NAS 和物件儲存之間無縫傳輸和同步資料。</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP* 是一款用戶端軟體，可實現快速可靠的任意到NetApp和NetApp到NetApp 的資料遷移。  XCP 還提供將大量資料從 Hadoop HDFS 檔案系統高效移動到ONTAP NFS、S3 或StorageGRID 的功能，並且 XCP 檔案分析可提供檔案系統的可見性。</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit* 是一個 Python 函式庫，它使資料科學家、DevOps 和資料工程師能夠輕鬆執行各種資料管理任務，例如近乎即時地配置、複製或快照資料磁碟區或 JupyterLab 工作區，這些任務由高效能橫向擴展NetApp儲存支援。</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*NetApp 的產品安全*。 LLM 可能會在回答中無意中洩露機密數據，因此研究利用 LLM 的 AI 應用程式相關漏洞的 CISO 對此表示擔憂。正如 OWASP（開放式全球應用安全專案）所概述的，資料中毒、資料外洩、拒絕服務和 LLM 中的提示注入等安全性問題可能會影響企業，防止資料暴露給未經授權的攻擊者。資料儲存需求應包括結構化、半結構化和非結構化資料的完整性檢查和不可變快照。 NetApp Snapshots 和SnapLock用於資料集版本控制。它帶來嚴格的基於角色的存取控制（RBAC）、安全協定和行業標準加密，以保護靜態和傳輸中的資料。  Cloud Insights和 Cloud Data Sense 共同提供功能，協助您透過法醫手段識別威脅來源並確定需要復原的資料的優先順序。</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* 搭載 DGX BasePOD 的ONTAP AI *</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">採用NVIDIA DGX BasePOD 的NetApp ONTAP AI 參考架構是一種適用於機器學習 (ML) 和人工智慧 (AI) 工作負載的可擴展架構。對於 LLM 的關鍵訓練階段，資料通常會定期從資料儲存複製到訓練叢集。此階段使用的伺服器使用 GPU 來並行運算，產生龐大的資料需求。滿足原始 I/O 頻寬需求對於維持高 GPU 利用率至關重要。</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* ONTAP AI 與NVIDIA AI Enterprise*</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise 是一款端到端、雲端原生的 AI 和資料分析軟體套件，經過NVIDIA優化、認證和支持，可在具有NVIDIA認證系統的 VMware vSphere 上運行。該軟體有助於在現代混合雲環境中簡單、快速地部署、管理和擴展 AI 工作負載。由NetApp和 VMware 提供支援的NVIDIA AI Enterprise 以簡化、熟悉的軟體包提供企業級 AI 工作負載和資料管理。</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*1P雲端平台*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">完全託管的雲端儲存產品在 Microsoft Azure 上以Azure NetApp Files (ANF) 的形式原生提供，在 AWS 上以Amazon FSx for NetApp ONTAP (FSx ONTAP) 的形式提供，在 Google 上以Google Cloud NetApp Volumes (GNCV ) 的形式提供。  1P 是一種託管的高效能檔案系統，可讓客戶在公有雲中運行高可用性 AI 工作負載並提高資料安全性，以便使用 AWS SageMaker、Azure-OpenAI Services 和 Google 的 Vertex AI 等雲端原生 ML 平台對 LLM/FM 進行微調。</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">NetApp合作夥伴解決方案套件</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">除了核心資料產品、技術和功能外， NetApp還與強大的 AI 合作夥伴網路密切合作，為客戶帶來附加價值。</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* 人工智慧系統中的NVIDIA Guardrails* 作為保障措施，確保以合乎道德和負責任的方式使用人工智慧技術。  AI 開發人員可以選擇定義 LLM 驅動的應用程式在特定主題上的行為，並阻止它們參與不想要的話題的討論。  Guardrails 是一個開源工具包，它能夠將 LLM 無縫安全地連接到其他服務，從而建立值得信賴、安全可靠的 LLM 對話系統。</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab* 提供多功能的企業級工具，用於構建和產品化生成式人工智慧 - 無論您在人工智慧旅程中的哪個階段，都能快速、安全且經濟地實現。借助 Domino 的企業 MLOps 平台，資料科學家可以使用首選工具和所有數據，在任何地方輕鬆訓練和部署模型，並有效地管理風險和成本——所有這些都可以透過一個控制中心完成。</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*Modzy 用於 Edge AI*。  NetApp和 Modzy 攜手合作，為任何類型的資料（包括圖像、音訊、文字和表格）提供大規模 AI。  Modzy 是一個用於部署、整合和運行 AI 模型的 MLOps 平台，為資料科學家提供模型監控、漂移偵測和可解釋性的功能，並提供無縫 LLM 推理的整合解決方案。</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run:AI* 和NetApp合作展示了NetApp ONTAP AI 解決方案與 Run:AI 叢集管理平台的獨特功能，以簡化 AI 工作負載的編排。它自動分割和合併 GPU 資源，旨在將您的資料處理管道擴展到數百台機器，並為 Spark、Ray、Dask 和 Rapids 內建整合框架。</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">只有在大量高品質資料上訓練模型時，生成式人工智慧才能產生有效的結果。雖然 LLM 已經取得了顯著的里程碑，但認識到其局限性、設計挑戰以及與資料移動性和資料品質相關的風險至關重要。 LLM 依賴來自異質資料來源的大量且不同的訓練資料集。模型產生的不準確結果或偏見的結果可能會使企業和消費者都陷入危險。這些風險可能對應於 LLM 可能因與資料品質、資料安全性和資料移動性相關的資料管理挑戰而產生的限制。 NetApp幫助組織應對快速資料成長、資料移動性、多雲管理和 AI 採用所帶來的複雜性。大規模的人工智慧基礎設施和高效的數據管理對於定義生成人工智慧等人工智慧應用的成功至關重要。至關重要的是，客戶要涵蓋所有部署場景，同時又不能影響企業根據需要擴展的能力，同時還要保持成本效益、資料治理和道德的人工智慧實踐。  NetApp一直致力於幫助客戶簡化和加速他們的 AI 部署。</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DESIGN： NetApp AIPod與聯想合作，支援NVIDIA OVX</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">Bobby Oommen、Abhinav Singh、Roney Daniel、 NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">此參考架構將搭載NVIDIA L40S GPU 的NVIDIA認證 OVX Lenovo ThinkSystem 伺服器與NVIDIA Spectrum 網路配對，以提供最佳化和部署 LLM（大型語言模型）的最佳基礎設施解決方案。本文檔旨在提供與 OVX 配置儲存相關的指導。該平台適用於各種生成式人工智慧工作負載，包括 RAG（檢索增強生成）、微調和輕量級模型訓練。</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN：適用於NVIDIA OVX 的NetApp AIPod與聯想設計指南</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NetApp AIPod與NVIDIA DGX 系統 - 架構</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">NVA-1173 NetApp AIPod與NVIDIA DGX H100 系統 - 解決方案架構</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">本節重點在於採用NVIDIA DGX 系統的NetApp AIPod的架構。</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">搭載 DGX 系統的NetApp AIPod</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">此參考架構利用單獨的結構進行計算叢集互連和儲存訪問，並在計算節點之間實現 400Gb/s InfiniBand (IB) 連接。下圖展示了NetApp AIPod與 DGX H100 系統的整體解決方案拓撲。</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">NetApp AIpod 解決方案拓撲</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">網路設計</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">在此配置中，計算叢集結構使用一對 QM9700 400Gb/s IB 交換機，它們連接在一起以實現高可用性。每個 DGX H100 系統使用八個連接連接到交換機，其中偶數連接埠連接到一個交換機，奇數連接埠連接到另一個交換器。</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">對於儲存系統存取、帶內管理和用戶端訪問，使用一對 SN4600 乙太網路交換器。交換器之間透過交換器間連結連接，並配置多個VLAN來隔離各種流量類型。在特定 VLAN 之間啟用基本 L3 路由，以在同一交換器上的用戶端和儲存介面之間以及交換器之間啟用多條路徑，從而實現高可用性。對於更大的部署，可以透過根據需要為主幹交換器添加額外的交換器對以及為其他葉子交換器添加額外的交換器對，將以太網網路擴展為葉子-主幹配置。</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">部署詳細信息</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">除了計算互連和高速乙太網路之外，所有實體設備還連接到一個或多個 SN2201 乙太網路交換機，以進行帶外管理。請參閱<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block>頁面以取得有關網路配置的更多資訊。</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">DGX H100 系統的儲存存取概述</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">每個 DGX H100 系統都配備了兩個雙埠 ConnectX-7 轉接器用於管理和儲存流量，並且對於此解決方案，每個卡上的兩個連接埠都連接到同一個交換器。然後將每個卡的一個連接埠配置為 LACP MLAG 綁定，並將一個連接埠連接到每個交換機，並且在帶內管理、用戶端存取和用戶級儲存存取的 VLAN 都託管在此綁定上。</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">每張卡上的另一個連接埠用於連接AFF A90儲存系統，並且可以根據工作負載要求以多種配置使用。對於使用 NFS over RDMA 來支援NVIDIA Magnum IO GPUDirect Storage 的配置，連接埠單獨使用，且 IP 位址位於單獨的 VLAN 中。對於不需要 RDMA 的部署，儲存介面也可以配置 LACP 綁定，以提供高可用性和額外的頻寬。無論是否使用 RDMA，用戶端都可以使用 NFS v4.1 pNFS 和會話中繼掛載儲存系統，以實現對叢集中所有儲存節點的平行存取。請參閱<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block>頁面以取得有關客戶端配置的更多資訊。</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">NVIDIA BasePOD 文檔</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">有關 DGX H100 系統連接的詳細信息，請參閱<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block>。</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">儲存系統設計</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">每個AFF A90儲存系統使用每個控制器的六個 200 GbE 連接埠進行連接。每個控制器的四個連接埠用於從 DGX 系統存取工作負載數據，每個控制器的兩個連接埠配置為 LACP 介面群組，以支援從管理平面伺服器存取叢集管理工件和使用者主目錄。儲存系統的所有資料存取均透過 NFS 提供，其中有一個專用於 AI 工作負載存取的儲存虛擬機器 (SVM) 和一個專用於叢集管理用途的單獨 SVM。</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">管理 SVM 只需要一個 LIF，該 LIF 託管在每個控制器上配置的 2 連接埠介面組上。其他FlexGroup磁碟區在管理 SVM 上進行配置，以容納叢集管理構件，如叢集節點映像、系統監控歷史資料和最終使用者主目錄。下圖顯示了儲存系統的邏輯配置。</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">NetApp A90 儲存叢集邏輯配置</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">管理平面伺服器</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">此參考架構還包括五個基於 CPU 的伺服器，用於管理平面。其中兩個系統用作NVIDIA Base Command Manager 的頭節點，用於叢集部署和管理。其他三個系統用於提供額外的叢集服務，例如 Kubernetes 主節點或利用 Slurm 進行作業排程的部署的登入節點。利用 Kubernetes 的部署可以利用NetApp Trident CSI 驅動程式為AFF A900儲存系統上的管理和 AI 工作負載提供具有持久性儲存的自動設定和資料服務。</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">每台伺服器都實體連接到 IB 交換器和乙太網路交換機，以實現叢集部署和管理，並透過管理 SVM 配置 NFS 掛載到儲存系統，以儲存前面所述的叢集管理工件。</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NetApp AIPod與NVIDIA DGX 系統 - 更多資訊取得途徑</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NVA-1173 NetApp AIPod與NVIDIA DGX 系統 - 結論及其他訊息</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">本節包含更多關於具有NVIDIA DGX 系統的NetApp AIPod的資訊的參考。</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">DGX BasePOD 架構是下一代深度學習平台，需要同樣先進的儲存和資料管理功能。透過將 DGX BasePOD 與NetApp AFF系統結合， NetApp AIPod與 DGX 系統架構幾乎可以在任何規模上實現。結合NetApp ONTAP卓越的雲端整合和軟體定義功能， AFF可為成功的 DL 專案提供涵蓋邊緣、核心和雲端的全方位資料管道。</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">附加資訊</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">要了解有關本文檔中描述的信息的更多信息，請參閱以下文檔和/或網站：</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAP資料管理軟體 — ONTAP資訊庫</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">NetApp AFF A90儲存系統-</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">NetApp ONTAP RDMA 資訊-</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">NetApp Trident</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">NetApp GPUDirect 儲存部落格-</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">NVIDIA DGX H100 系統</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">NVIDIA網絡</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">NVIDIA Magnum IO&amp;#8482; GPUDirect&amp;#174; 存儲</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">NVIDIA基本指令</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">NVIDIA基礎指令管理器</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AI 企業版</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">本文檔由NetApp解決方案和ONTAP工程團隊（David Arnette、Olga Kornievskaia、Dustin Fischer、Srikanth Kaligotla、Mohit Kumar 和 Raghuram Sudhaakar）編寫。作者也要感謝NVIDIA和NVIDIA DGX BasePOD工程團隊的持續支持。</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NetApp AIPod與NVIDIA DGX 系統 - 部署</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NVA-1173 NetApp AIPod與NVIDIA DGX 系統 - 部署詳情</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">本節介紹驗證此解決方案期間所使用的部署細節。使用的 IP 位址僅供參考，請依部署環境進行修改。有關此配置的實現中使用的特定命令的更多信息，請參閱相應的產品文檔。</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">下圖顯示了 1 個 DGX H100 系統和 1 個 HA 對AFF A90控制器的詳細網路和連接資訊。以下部分中的部署指南是基於此圖中的詳細資訊。</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">NetApp AIpod 網路配置</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">下表顯示了最多 16 個 DGX 系統和 2 個AFF A90 HA 對的範例佈線分配。</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">交換器和連接埠</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">裝置</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">設備連接埠</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">交換器1埠1-16</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01 至 -16</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0，插槽1埠1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">交換器1埠17-32</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1，插槽1埠2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">交換器1埠33-36</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01 至 -04</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">端口 e6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">交換器1埠37-40</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">端口 e11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">交換器1埠41-44</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">端口 e2a</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">交換器1埠57-64</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISL 到交換器 2</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">埠 57-64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">交換器2埠1-16</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0，插槽2埠1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">交換器2埠17-32</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1，插槽 2 埠 2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">交換器2埠33-36</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">埠 e6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">交換器2埠37-40</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">埠 e11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">交換器2埠41-44</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">埠 e2b</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">交換器2埠57-64</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISL 到交換器 1</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">下表顯示了本次驗證中使用的各個組件的軟體版本。</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">軟體版本</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">NVIDIA SN4600 交換機</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">Cumulus Linux v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">NVIDIA DGX 系統</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">DGX 作業系統 v6.2.1（Ubuntu 22.04 LTS）</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">Mellanox OFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24.01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">儲存網路配置</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">NVIDIA Cumulus Linux 文檔</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">本節概述乙太網路儲存網路配置的關鍵細節。有關配置 InfiniBand 計算網路的信息，請參閱<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block>。有關交換器配置的詳細信息，請參閱<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block>。</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">設定 SN4600 交換器的基本步驟概述如下。此程序假定佈線和基本交換器設定（管理 IP 位址、許可證等）已完成。</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">配置交換器之間的 ISL 綁定以啟用多鏈路聚合 (MLAG) 和故障轉移流量</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">本次驗證使用了 8 條鏈路，為測試的儲存配置提供了足夠的頻寬</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">有關啟用 MLAG 的具體說明，請參閱 Cumulus Linux 文件。</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">為兩台交換器上的每對用戶端連接埠和儲存連接埠配置 LACP MLAG</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">每個交換器上的連接埠 swp17 用於 DGX-H100-01（enp170s0f1np1 和 enp41s0f1np1），連接埠 swp18 用於 DGX-H100-02，等等（bond1-16）</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">每個交換器上的連接埠 swp41 用於AFF-A90-01（e2a 和 e2b），連接埠 swp42 用於AFF-A90-02，等等（bond17-20）</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv 設定介面 bondX 鍵成員 swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv 設定介面 bondx 綁定 mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">將所有連接埠和 MLAG 綁定新增至預設橋接域</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv 設定 int swp1-16,33-40 橋接域 br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv 設定 int bond1-20 橋接域 br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">在每台交換器上啟用 RoCE</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv 設定 roce 模式無損</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">配置 VLAN - 2 個用於客戶端端口，2 個用於儲存端口，1 個用於管理，1 個用於 L3 交換器到交換機</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">開關 1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">VLAN 3 用於在用戶端 NIC 發生故障時進行 L3 交換器到交換器的路由</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">每個 DGX 系統上的儲存連接埠 1 的 VLAN 101（enp170s0f0np0，slot1 連接埠 1）</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">每個AFF A90儲存控制器上的連接埠 e6a 和 e11a 的 VLAN 102</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">VLAN 301 用於使用 MLAG 介面對每個 DGX 系統和儲存控制器進行管理</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">開關 2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">每個 DGX 系統上的儲存連接埠 2 的 VLAN 201（enp41s0f0np0，slot2 連接埠 1）</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">每個AFF A90儲存控制器上的連接埠 e6b 和 e11b 的 VLAN 202</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">根據需要將實體連接埠指派給每個 VLAN，例如客戶端 VLAN 中的用戶端連接埠和儲存 VLAN 中的儲存連接埠</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv 設定 int &lt;swpX&gt; 橋接域 br_default 存取 &lt;vlan id&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">MLAG 連接埠應保持為中繼端口，以根據需要在綁定介面上啟用多個 VLAN。</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">在每個 VLAN 上設定交換器虛擬介面 (SVI) 以充當網關並啟用 L3 路由</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv 設定 int vlan3 ip 位址 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv 設定 int vlan101 ip 位址 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv 設定 int vlan102 ip 位址 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv 設定 int vlan3 ip 位址 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv 設定 int vlan201 ip 位址 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv 設定 int vlan202 ip 位址 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">建立靜態路由</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">同一交換器上的子網路將自動建立靜態路由</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">當客戶端連結發生故障時，交換器到交換器的路由需要額外的靜態路由</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv 設定 VRF 預設路由器靜態 100.127.128.0/17 通過 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv 設定 VRF 預設路由器靜態 100.127.0.0/17 透過 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">儲存系統配置</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">ONTAP 文件</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">本節介紹此解決方案的 A90 儲存系統配置的關鍵細節。有關ONTAP系統配置的更多詳細信息，請參閱<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block>。下圖顯示了儲存系統的邏輯配置。</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">配置儲存系統的基本步驟概述如下。此過程假設基本儲存叢集安裝已經完成。</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">在每個控制器上配置 1 個聚合，所有可用分割區減去 1 個備用分割區</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr create -node &lt;節點&gt; -aggregate &lt;節點&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">在每個控制器上配置 ifgrps</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">網路連接埠 ifgrp create -node &lt;節點&gt; -ifgrp a1a -mode multimode_lacp -distr-function port</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">網路連接埠 ifgrp add-port -node &lt;節點&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;節點&gt;:e2a,&lt;節點&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">在每個控制器上的 ifgrp 上設定 mgmt vlan 端口</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">網路連接埠 vlan 建立 -節點 aff-a90-01 -連接埠 a1a -vlan-id 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">網路連接埠 vlan 建立 -節點 aff-a90-02 -連接埠 a1a -vlan-id 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">網路連接埠 vlan 建立 -節點 aff-a90-03 -連接埠 a1a -vlan-id 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">網路連接埠 vlan 建立 -節點 aff-a90-04 -連接埠 a1a -vlan-id 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">建立廣播域</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">廣播域創建-廣播域vlan21-mtu 9000-連接埠aff-a90-01：e6a，aff-a90-01：e11a，aff-a90-02：e6a，aff-a90-02：e11a，aff-a90-03：e6a，aff-a90-03：e11a，aff-a90-03：e6a，aff-a90-03：e11a，affa：96a-6a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">廣播域創建-廣播域vlan22-mtu 9000-埠aaff-a90-01：e6b，aff-a90-01：e11b，aff-a90-02：e6b，aff-a90-02：e11b，aff-a90-03：e6b，aff-a90-02：e11b，aff-a90-03：e6b，aff-a90-03：e11baff-a90-03：e6b，aff-a90-03：e11b，affa</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">廣播域創建-廣播域vlan31-mtu 9000-端口aff-a90-01:a1a-31，aff-a90-02:a1a-31，aff-a90-03:a1a-31，aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">建立管理 SVM *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">配置管理 SVM</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">創建 LIF</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -home-node aff-a90-01 -home-port a1a-31 -address 192.168.31.X -netmask 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">創建FlexGroup磁碟區-</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">卷創建-vserver basepod-mgmt-volume home-size 10T-auto-provision-as flexgroup-junction-path /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">卷創建-vserver basepod-mgmt-volume cm-size 10T-auto-provision-as flexgroup-junction-path /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">制定出口政策</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">匯出政策規則建立-vserver basepod-mgmt-policy default-client-match 192.168.31.0/24-rorule sys-rwrule sys-superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">建立資料SVM*</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">配置資料 SVM</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">配置 SVM 以支援 RDMA</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs 修改-vserver basepod-data -rdma 已啟用</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">創建 LIF</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -home-node aff-a90-01 -home-port e6a -address 100.127.102.101 -netmask 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -home-node aff-a90-01 -home-port e6a -address 100.127.102.102 -netmask 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -home-node aff-a90-01 -home-port e6b -address 100.127.202.101 -netmask 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -home-node aff-a90-01 -home-port e6b -address 100.127.202.102 -netmask 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -home-node aff-a90-01 -home-port e11a -address 100.127.102.103 -netmask 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -home-node aff-a90-01 -home-port e11a -address 100.127.102.104 -netmask 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create-vserver basepod-data-lif c1-11b-lif1-home-node aff-a90-01-home-port e11b-address 100.127.202.103-netmask 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -home-node aff-a90-01 -home-port e11b -address 100.127.202.104 -netmask 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -home-node aff-a90-02 -home-port e6a -address 100.127.102.105 -netmask 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -home-node aff-a90-02 -home-port e6a -address 100.127.102.106 -netmask 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -home-node aff-a90-02 -home-port e6b -address 100.127.202.105 -netmask 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -home-node aff-a90-02 -home-port e6b -address 100.127.202.106 -netmask 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -home-node aff-a90-02 -home-port e11a -address 100.127.102.107 -netmask 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create-vserver basepod-data-lif c2-11a-lif2-home-node aff-a90-02-home-port e11a-address 100.127.102.108-netmask 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -home-node aff-a90-02 -home-port e11b -address 100.127.202.107 -netmask 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create-vserver basepod-data-lif c2-11b-lif2-home-node aff-a90-02-home-port e11b-address 100.127.202.108-netmask 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">配置 LIF 以進行 RDMA 訪問</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">對於使用ONTAP 9.15.1 的部署，實體資訊的 RoCE QoS 設定需要ONTAP CLI 中不可用的作業系統層級指令。請聯絡NetApp支援以取得 RoCE 支援連接埠配置的協助。  NFS over RDMA 功能正常</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">從ONTAP 9.16.1 開始，實體介面將自動配置適當的設定以實現端對端 RoCE 支援。</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int 修改-vserver basepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">在資料 SVM 上配置 NFS 參數</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">nfs 修改 -vserver basepod-data -v4.1 已啟用 -v4.1-pnfs 已啟用 -v4.1-trunking 已啟用 -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">創建FlexGroup卷</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">卷創建-vserver basepod-data-volume資料-size 100T-auto-provision-as flexgroup-junction-path /data</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">建立導出策略</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">匯出政策規則建立-vserver basepod-data-policy default-client-match 100.127.101.0/24-rorule sys-rwrule sys-superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">匯出政策規則建立-vserver basepod-data-policy default-client-match 100.127.201.0/24-rorule sys-rwrule sys-superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">創建路線</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">路由新增-vserver basepod_data-目的地100.127.0.0/17-網關100.127.102.1度量20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">路由新增-vserver basepod_data-目的地100.127.0.0/17-網關100.127.202.1度量30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">路由新增-vserver basepod_data-目的地100.127.128.0/17-網關100.127.202.1度量20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">路由新增-vserver basepod_data-目的地100.127.128.0/17-網關100.127.102.1度量30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">用於 RoCE 儲存存取的 DGX H100 配置</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">BCM 文件</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">本節介紹 DGX H100 系統配置的關鍵細節。許多配置項目可以包含在部署到 DGX 系統的 OS 映像中，或在啟動時由 Base Command Manager 實作。這裡列出它們以供參考，有關在 BCM 中配置節點和軟體映像的更多信息，請參閱<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block>。</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">安裝其他軟體包</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">ipmitool</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">python3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">安裝 Python 套件</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">波羅米科</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">matplotlib</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">軟體包安裝後重新配置 dpkg</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg——配置-a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">安裝 MOFED</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">設定 mst 值以進行效能調整</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; 設定 ADVANCED_PCI_SETTINGS=1 NUM_OF_VFS=0 MAX_ACC_OUT_READ=44</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">修改設定後重置適配器</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y 重置</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">在 PCI 裝置上設定 MaxReadReq</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">設定 RX 和 TX 環形緩衝區大小</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; rx 8192 tx 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">使用 mlnx_qos 設定 PFC 和 DSCP</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --cable_len=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">為網路連接埠上的 RoCE 流量設定 ToS</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">echo 106 &gt; /sys/class/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/traffic_class</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">在適當的子網路上為每個儲存 NIC 設定一個 IP 位址</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">100.127.101.0/24 用於儲存 NIC 1</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">100.127.201.0/24 用於儲存 NIC 2</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">配置帶內網路連接埠進行 LACP 綁定（enp170s0f1np1、enp41s0f1np1）</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">為每個儲存子網路的主路徑和次路徑配置靜態路由</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">路由新增 –net 100.127.0.0/17 gw 100.127.101.1 metric 20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">路由新增 –net 100.127.0.0/17 gw 100.127.201.1 metric 30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">路由新增 –net 100.127.128.0/17 gw 100.127.201.1 公制 20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">路由新增 –net 100.127.128.0/17 gw 100.127.101.1 公制 30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">掛載 /home 卷</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">安裝-o vers = 3，nconnect = 16，rsize = 262144，wsize = 262144 192.168.31.X：/home /home</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">掛載/資料卷</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">安裝資料卷時使用了以下安裝選項-</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # 啟用 pNFS 來並行存取多個儲存節點</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # 將傳輸協定設為 RDMA，而不是預設的 TCP</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 #啟用 NFS 會話中繼來聚合儲存連接埠頻寬</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # 提高緩衝寫入的寫入效能</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # 將 I/O 傳輸大小設為 256k</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">搭載NVIDIA DGX 系統的NetApp AIPod - 硬體組件</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">搭載NVIDIA DGX 系統的 NVA-1173 NetApp AIPod - 硬體組件</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">本節重點介紹具有NVIDIA DGX 系統的NetApp AIPod的硬體組件。</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">NetApp AFF儲存系統</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">NetApp AFF最先進的儲存系統使 IT 部門能夠透過業界領先的效能、卓越的靈活性、雲端整合和一流的資料管理來滿足企業儲存需求。  AFF系統專為快閃記憶體設計，有助於加速、管理和保護關鍵業務資料。</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">AFF A90儲存系統</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">由NetApp ONTAP資料管理軟體提供支援的NetApp AFF A90提供內建資料保護、可選的反勒索軟體功能以及支援最關鍵業務工作負載所需的高效能和彈性。它消除了對關鍵任務操作的中斷，最大限度地減少了效能調整，並保護您的資料免受勒索軟體攻擊。它提供：• 業界領先的效能 • 不折不扣的資料安全性 • 簡化的無中斷升級</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">NetApp AFF A90儲存系統</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">業界領先的性能</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">AFF A90可輕鬆管理深度學習、人工智慧和高速分析等新一代工作負載以及 Oracle、SAP HANA、Microsoft SQL Server 和虛擬化應用程式等傳統企業資料庫。它使關鍵業務應用程式保持最高速度運行，每個 HA 對高達 2.4M IOPS，延遲低至 100µs，並且性能比以前的NetApp型號提高高達 50%。借助 NFS over RDMA、pNFS 和會話中繼，客戶可以使用現有的資料中心網路基礎設施實現下一代應用程式所需的高水準網路效能。客戶還可以透過對 SAN、NAS 和物件儲存的統一多協定支援進行擴展和成長，並透過統一的單一ONTAP資料管理軟體為本地或雲端資料提供最大的靈活性。此外，還可以透過Active IQ和Cloud Insights提供的基於 AI 的預測分析來優化系統健康狀況。</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">不妥協的資料安全</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">AFF A90系統包含一整套NetApp整合和應用程式一致的資料保護軟體。它提供內建資料保護和尖端反勒索軟體解決方案，用於預防和攻擊後復原。可以阻止惡意檔案寫入磁碟，並且可以輕鬆監控儲存異常以取得洞察。</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">簡化的無中斷升級</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">對於現有的 A800 客戶來說， AFF A90可以作為無中斷機殼內升級。 NetApp憑藉其先進的可靠性、可用性、可維護性和可管理性 (RASM) 功能，可輕鬆更新並消除關鍵任務操作的中斷。此外，由於ONTAP軟體會自動為所有系統元件應用韌體更新， NetApp進一步提高了營運效率並簡化了 IT 團隊的日常活動。</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">對於最大的部署， AFF A1K系統提供最高的效能和容量選項，而其他NetApp儲存系統（如AFF A70和AFF C800）則以較低的成本為較小的部署提供選項。</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD是由NVIDIA硬體和軟體元件、MLOps 解決方案以及第三方儲存組成的整合解決方案。利用NVIDIA產品和經過驗證的合作夥伴解決方案的橫向擴展系統設計最佳實踐，客戶可以實現高效且易於管理的 AI 開發平台。圖 1 突顯了NVIDIA DGX BasePOD的各個元件。</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">NVIDIA DGX BasePOD 解決方案</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">NVIDIA DGX H100 系統</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">NVIDIA DGX H100™ 系統是 AI 的強大引擎，由NVIDIA H100 Tensor Core GPU 的突破性效能加速。</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">NVIDIA DGX H100 系統</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">DGX H100 系統的主要規格如下：• 八個NVIDIA H100 GPU。  • 每個 GPU 配備 80 GB GPU 內存，總計 640GB。  • 四個NVIDIA NVSwitch 晶片。  • 雙 56 核心 Intel Xeon Platinum 8480 處理器，支援 PCIe 5.0。  • 2 TB DDR5 系統記憶體。  • 四個 OSFP 端口，服務八個單端口NVIDIA ConnectX™-7（InfiniBand/乙太網路）適配器和兩個雙端口NVIDIA ConnectX-7（InfiniBand/乙太網路）適配器。  • 兩個 1.92 TB M.2 NVMe 硬碟用於 DGX OS，八個 3.84 TB U.2 NVMe 硬碟用於儲存/快取。  • 最大功率10.2 kW。 DGX H100 CPU 托盤的後連接埠如下所示。四個 OSFP 連接埠為 InfiniBand 計算結構的八個 ConnectX-7 適配器提供服務。每對雙連接埠 ConnectX-7 適配器為儲存和管理結構提供平行路徑。帶外端口用於BMC存取。</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_NVIDIA DGX H100 後面板_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">NVIDIA Quantum-2 QM9700 交換機</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">_NVIDIA Quantum-2 QM9700 InfiniBand 交換器_</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">具有 400Gb/s InfiniBand 連接的NVIDIA Quantum-2 QM9700 交換器為NVIDIA Quantum-2 InfiniBand BasePOD 配置中的運算結構提供動力。 ConnectX-7 單埠適配器用於 InfiniBand 計算結構。每個NVIDIA DGX 系統與每個 QM9700 交換器都有雙重連接，從而在系統之間提供多條高頻寬、低延遲路徑。</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">NVIDIA Spectrum-3 SN4600 交換機</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">_NVIDIA Spectrum-3 SN4600 交換器_</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">NVIDIA Spectrum™-3 SN4600 交換器總共提供 128 個連接埠（每個交換器 64 個），為 DGX BasePOD 的帶內管理提供冗餘連接。 NVIDIA SN4600 交換器可提供 1 GbE 到 200 GbE 之間的速度。對於透過乙太網路連接的儲存設備，也使用NVIDIA SN4600 交換器。  NVIDIA DGX 雙埠 ConnectX-7 轉接器上的連接埠用於內建管理和儲存連線。</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">NVIDIA Spectrum SN2201 交換機</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">NVIDIA Spectrum SN2201 交換機</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">NVIDIA Spectrum SN2201 交換器提供 48 個端口，可為帶外管理提供連接。帶外管理為 DGX BasePOD 中的所有元件提供整合的管理連線。</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">NVIDIA ConnectX-7 轉接器</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">_NVIDIA ConnectX-7 適配器_</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">NVIDIA ConnectX-7 轉接器可提供 25/50/100/200/400G 的吞吐量。  NVIDIA DGX 系統使用單埠和雙埠 ConnectX-7 轉接器，為具有 400Gb/s InfiniBand 和乙太網路的 DGX BasePOD 部署提供靈活性。</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">採用NVIDIA DGX 系統的NetApp AIPod是一種企業級參考架構，基於NVIDIA BasePOD，用於深度學習和人工智慧，使用NetApp ONTAP AFF儲存系統以及NVIDIA網路和 DGX 系統。</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NVA-1173 NetApp AIPod與NVIDIA DGX 系統 - 簡介</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200,錯誤：缺少圖形圖像</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">NetApp解決方案工程</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">NetApp™ AIPod配備NVIDIA DGX™ 系統和NetApp雲端連接儲存系統，透過消除設計複雜性和猜測，簡化了機器學習 (ML) 和人工智慧 (AI) 工作負載的基礎設施部署。基於NVIDIA DGX BasePOD™ 設計，旨在為下一代工作負載提供卓越的運算效能，搭載NVIDIA DGX 系統的AIPod增加了NetApp AFF儲存系統，使客戶能夠從小規模開始並無中斷地發展，同時智慧地管理從邊緣到核心再到雲端的資料。  NetApp AIPod是NetApp AI 解決方案產品組合的一部分，如下圖所示。</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_NetApp 人工智慧解決方案組合_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">本文檔描述了AIPod參考架構的關鍵組件、系統連接和配置資訊、驗證測試結果和解決方案規模指導。本文檔適用於有興趣為 ML/DL 和分析工作負載部署高效能基礎架構的NetApp和合作夥伴解決方案工程師以及客戶策略決策者。</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NetApp AIPod與NVIDIA DGX 系統 - 軟體元件</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NVA-1173 NetApp AIPod與NVIDIA DGX 系統 - 軟體元件</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">本節重點介紹具有NVIDIA DGX 系統的NetApp AIPod的軟體元件。</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">NVIDIA軟體</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command™ 為每個 DGX BasePOD 提供支持，使組織能夠充分利用NVIDIA軟體創新的最佳成果。企業可以透過經過驗證的平台充分發揮其投資潛力，該平台包括企業級編排和叢集管理、加速運算、儲存和網路基礎設施的程式庫以及針對 AI 工作負載優化的作業系統 (OS)。</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_NVIDIA BaseCommand 解決方案_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU 雲端 (NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">NVIDIA NGC 提供的軟體可滿足具有不同 AI 專業水平的資料科學家、開發人員和研究人員的需求。 NGC 上託管的軟體會針對一組常見漏洞和暴露 (CVE)、加密和私鑰進行掃描。它經過測試和設計，可擴展到多個 GPU，在許多情況下，可擴展到多節點，確保用戶最大限度地利用其在 DGX 系統上的投資。</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_NVIDIA GPU 雲端_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise 是一個端對端軟體平台，可讓每個企業都能夠使用生成式 AI，為在NVIDIA DGX 平台上優化的生成式 AI 基礎模型提供最快、最高效的運行時。憑藉生產級的安全性、穩定性和可管理性，它簡化了生成式 AI 解決方案的開發。  NVIDIA AI Enterprise 包含在 DGX BasePOD 中，企業開發人員可以存取預訓練模型、最佳化框架、微服務、加速庫和企業支援。</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">NetApp軟體</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9 是NetApp最新一代儲存管理軟體，它支援企業實現基礎架構現代化並過渡到雲端就緒資料中心。 ONTAP利用業界領先的數據管理功能，只需一套工具即可管理和保護數據，無論數據位於何處。您也可以將資料自由移動到任何需要的地方：邊緣、核心或雲端。  ONTAP 9 包含眾多功能，可簡化資料管理、加速和保護關鍵數據，並支援跨混合雲架構的下一代基礎架構功能。</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">加速並保護數據</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP提供卓越等級的效能和資料保護，並透過以下方式擴展這些功能：</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">性能和更低的延遲。  ONTAP以最低的延遲提供最高的吞吐量，包括支援使用 NFS over RDMA、平行 NFS (pNFS) 和 NFS 會話中繼的NVIDIA GPUDirect Storage (GDS)。</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">資料保護。  ONTAP提供內建資料保護功能和業界最強大的反勒索軟體保障，並在所有平台上實現通用管理。</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp磁碟區加密 (NVE)。  ONTAP提供原生磁碟區級加密，同時支援板載和外部金鑰管理。</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">儲存多租戶和多因素身份驗證。  ONTAP支援以最高等級的安全性共用基礎架構資源。</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">簡化資料管理</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">資料管理對於企業 IT 營運和資料科學家至關重要，以便將適當的資源用於 AI 應用程式和訓練 AI/ML 資料集。以下有關NetApp技術的附加資訊超出了本次驗證的範圍，但可能與您的部署相關。</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">ONTAP資料管理軟體包括以下功能，可簡化操作並降低總營運成本：</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">快照和複製支援 ML/DL 工作流程的協作、平行實驗和增強資料治理。</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror可在混合雲和多站點環境中實現無縫資料移動，並在所需的時間和地點提供資料。</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">內聯資料壓縮和擴展重複資料刪除。資料壓縮減少了儲存區塊內部浪費的空間，重複資料刪除顯著增加了有效容量。這適用於本地儲存的資料和分層到雲端的資料。</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">最小、最大和自適應服務品質 (AQoS)。細粒度的服務品質 (QoS) 控制有助於維持高度共享環境中關鍵應用程式的效能水準。</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">NetApp FlexGroups 支援在儲存叢集中的所有節點上分散數據，為超大資料集提供龐大的容量和更高的效能。</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598： FabricPool最佳實踐</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool。提供冷資料到公有和私有雲儲存選項的自動分層，包括 Amazon Web Services (AWS)、Azure 和NetApp StorageGRID儲存解決方案。有關FabricPool的更多信息，請參閱<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>。</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">NetApp FlexCache。提供遠端磁碟區快取功能，可簡化檔案分發、減少 WAN 延遲並降低 WAN 頻寬成本。  FlexCache支援跨多個站點的分散式產品開發，以及從遠端位置加速存取公司資料集。</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">面向未來的基礎設施</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP具有以下功能，可協助滿足嚴苛且不斷變化的業務需求：</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">無縫擴展和無中斷操作。 ONTAP支援在線為現有控制器和橫向擴展叢集新增容量。客戶可以升級到最新技術，例如 NVMe 和 32Gb FC，而無需昂貴的資料遷移或中斷。</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">雲端連線。  ONTAP是與雲端連接最緊密的儲存管理軟體，在所有公有雲中均提供軟體定義儲存（ONTAP Select）和Google Cloud NetApp Volumes Volumes ）的選項。</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">與新興應用程式的整合。  ONTAP使用支援現有企業應用的相同基礎架構，為下一代平台和應用（如自動駕駛汽車、智慧城市和工業 4.0）提供企業級資料服務。</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">NetApp DataOps Toolkit 是一款基於 Python 的工具，可簡化由高效能、橫向擴展NetApp儲存支援的開發/培訓工作區和推理伺服器的管理。 DataOps Toolkit 可以作為獨立實用程式運行，並且在利用NetApp Trident自動化儲存作業的 Kubernetes 環境中更有效。主要功能包括：</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">快速配置由高效能、橫向擴充NetApp儲存支援的新的高容量 JupyterLab 工作區。</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">快速配置由企業級NetApp儲存支援的全新NVIDIA Triton 推理伺服器實例。</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">近乎即時地克隆高容量的 JupyterLab 工作區，以實現實驗或快速迭代。</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">用於備份和/或可追溯性/基準的高容量 JupyterLab 工作區的近乎即時的快照。</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">近乎即時地配置、複製和快照高容量、高效能資料磁碟區。</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">Trident是一個完全支援的開源儲存編排器，適用於容器和 Kubernetes 發行版（包括 Anthos）。Trident可與整個NetApp儲存產品組合搭配使用，包括NetApp ONTAP，並且還支援 NFS、NVMe/TCP 和 iSCSI 連線。Trident允許最終用戶從其NetApp儲存系統配置和管理存儲，而無需儲存管理員的干預，從而加速 DevOps 工作流程。</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NetApp AIPod與NVIDIA DGX 系統 - 解決方案驗證與規模調整指南</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NVA-1173 NetApp AIPod與NVIDIA DGX 系統 - 解決方案驗證與規模調整指南</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">本節重點介紹採用NVIDIA DGX 系統的NetApp AIPod的解決方案驗證與尺寸調整指引。</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">解決方案驗證</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">使用開源工具 FIO 透過一系列合成工作負載驗證了此解決方案中的儲存配置。這些測試包括讀寫 I/O 模式，旨在模擬執行深度學習訓練作業的 DGX 系統產生的儲存工作負載。使用同時運行 FIO 工作負載的 2 插槽 CPU 伺服器叢集來驗證儲存配置，以模擬 DGX 系統叢集。每個客戶端都配置了前面描述的相同網路配置，並添加了以下詳細資訊。</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">以下安裝選項用於此驗證：</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">版本=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">啟用 pNFS 來並行存取多個儲存節點</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">原型=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">將傳輸協定設為 RDMA，而不是預設的 TCP</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">連接埠=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">為 RDMA NFS 服務指定正確的連接埠</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">最大連線數=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">啟用 NFS 會話中繼來聚合儲存連接埠頻寬</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">寫=渴望</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">提高緩衝寫入的寫入效能</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">rsize=262144,wsize=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">將 I/O 傳輸大小設定為 256k</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">此外，客戶端的 NFS max_session_slots 值配置為 1024。由於此解決方案是使用 NFS over RDMA 進行測試的，因此儲存網路連接埠配置了主動/被動結合。本次驗證使用了以下債券參數：</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">模式=主動備份</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">將綁定設定為主動/被動模式</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">primary=&lt;介面名稱&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">所有客戶端的主介面分佈在交換器上</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">mii-監控間隔=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">指定監控間隔為100ms</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">故障轉移 mac 策略=活動</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">指定活動鏈路的 MAC 位址是綁定的 MAC。這是 RDMA 透過綁定介面正確運行所必需的。</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">儲存系統配置如下，包括兩個 A900 HA 對（4 個控制器），每個 HA 對連接兩個 NS224 磁碟架，每個磁碟架有 24 個 1.9TB NVMe 磁碟機。如架構部分所述，所有控制器的儲存容量使用FlexGroup磁碟區進行組合，並且所有用戶端的資料分佈在叢集中的所有控制器上。</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">儲存系統規模指南</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">NetApp已成功完成 DGX BasePOD 認證，經測試的兩個 A90 HA 對可以輕鬆支援由 16 個 DGX H100 系統組成的叢集。對於具有更高儲存效能需求的大型部署，可以將額外的AFF系統新增至NetApp ONTAP叢集中，單一叢集中最多可包含 12 個 HA 對（24 個節點）。使用本解決方案中所述的FlexGroup技術，24 節點叢集可以在單一命名空間中提供超過 79 PB 和高達 552 GBps 的吞吐量。其他NetApp儲存系統（例如AFF A400、A250 和 C800）以較低的成本為較小規模的部署提供較低的效能和/或更高的容量選項。由於ONTAP 9 支援混合模型集群，客戶可以從較小的初始佔用空間開始，並隨著容量和效能需求的增長向集群添加更多或更大的儲存系統。下表粗略估計了每個AFF型號支援的 A100 和 H100 GPU 的數量。</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">NetApp 儲存系統規模調整指南</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">NetApp上的 BeeGFS 與 E 系列存儲</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">NetApp上具有 E 系列儲存的 BeeGFS 是一種經過驗證的整合解決方案，具有簡單、可靠、可擴展且經濟高效的 HPC 基礎架構，可滿足您最極端的工作負載的需求。</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY：Quantum StorNext 與NetApp E 系列系統部署指南</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">NetApp的 Ryan Rodine</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">本文檔詳細介紹如何使用NetApp E 系列儲存系統部署 StorNext 平行檔案系統解決方案。此解決方案涵蓋NetApp EF280 全快閃陣列、 NetApp EF300 全快閃 NVMe 陣列、 NetApp EF600 全快閃 NVMe 陣列和NetApp E5760 混合系統。它提供基於 Frametest 基準測試的效能表徵，Frametest 是一種廣泛用於媒體和娛樂產業測試的工具。</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN：Quantum StorNext 與NetApp E 系列系統設計指南</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">本文檔詳細介紹如何使用NetApp E 系列儲存系統設計 StorNext 平行檔案系統解決方案。此解決方案涵蓋NetApp EF280 全快閃陣列、 NetApp EF300 全快閃 NVMe 陣列、EF600 全快閃 NVMe 陣列和NetApp E5760 混合系統。它提供基於 Frametest 基準測試的效能表徵，Frametest 是一種廣泛用於媒體和娛樂產業測試的工具。</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859：使用NetApp E 系列儲存部署 IBM Spectrum Scale - 安裝與驗證</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">NetApp的 Chris Seirer</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859 描述了基於 IBM 的 Spectrum Scale 軟體堆疊部署完整平行檔案系統解決方案的過程。  TR-4859 旨在提供有關如何安裝 Spectrum Scale、驗證基礎設施和管理配置的詳細資訊。</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">此NetApp驗證架構描述了具有NetApp BeeGFS 構建塊的NVIDIA DGX SuperPOD的設計。此解決方案是一個全端資料中心平台，已在NVIDIA的專用驗收集群上經過驗證。</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NVIDIA DGX SuperPOD與NetApp - 設計指南</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">此NetApp驗證架構描述了具有NetApp BeeGFS 構建塊的NVIDIA DGX SuperPOD的設計。此解決方案是一個全端資料中心平台，在NVIDIA的專用驗收集群上進行了驗證。</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200,200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">NetApp 的Amine Bennani、Christian Whiteside、David Arnette 和 Sathish Thyagarajan</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">執行摘要</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">在當今快速發展的技術格局中，人工智慧正在徹底改變消費者體驗並推動各行各業的創新。然而，這也給 IT 部門帶來了巨大的挑戰，他們面臨著部署能夠處理 AI 工作負載的強烈需求的高效能運算 (HPC) 解決方案的壓力。隨著各組織競相利用人工智慧的力量，對易於部署、擴展和管理的解決方案的需求也日益迫切。</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPOD是一個 AI 資料中心基礎架構平台，作為 IT 的交鑰匙解決方案提供，以支援當今企業面臨的最複雜的 AI 工作負載。任何精確的深度學習 (DL) 模型的核心都是大量數據，需要能夠有效地提供和重新提供這些數據的高吞吐量儲存解決方案。  NetApp BeeGFS 解決方案由具有 BeeGFS 平行檔案系統的NetApp EF600 儲存陣列組成，使NVIDIA DGX SuperPOD能夠充分發揮其功能。 NetApp BeeGFS 解決方案已通過NVIDIA驗證，可與 SuperPOD 架構整合和擴充。其結果是簡化了 AI 資料中心的部署和管理，同時提供了幾乎無限的效能和容量可擴展性。</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">NetApp BeeGFS 解決方案由高效能NetApp EF600 NVMe 儲存系統和可擴展的 BeeGFS 平行檔案系統提供支援，為要求苛刻的 AI 工作負載提供了強大而高效的儲存基礎。其共享磁碟架構確保高可用性，即使面臨系統挑戰也能保持一致的效能和可存取性。該解決方案提供了可擴展且靈活的架構，可客製化以滿足不同的儲存需求。客戶可以透過整合額外的儲存構建塊來輕鬆擴展其儲存效能和容量，以處理最苛刻的工作負載。</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">NVIDIA DGX SuperPOD利用 DGX H100 和 H200 系統以及經過驗證的外部連接共享儲存：</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">每個 DGX SuperPOD 可擴充單元 (SU) 由 32 個 DGX 系統組成，能夠以 FP8 精度達到 640 petaFLOPS 的 AI 效能。  NetApp建議為單一 DGX SuperPOD 設定使用至少 2 個建置區塊來調整NetApp BeeGFS 儲存解決方案的大小。</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_解決方案的高層視圖_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">該圖顯示了採用NVIDIA DGX SuperPOD的NetApp BeeGFS 解決方案的高級概覽。</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">NetApp BeeGFS 建置區塊由兩個NetApp EF600 陣列和兩台 x86 伺服器組成：</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">透過以NVIDIA DGX SuperPOD為基礎的NetApp EF600 全快閃陣列，客戶可以獲得可靠的儲存基礎，並享有 6 個 9 的正常運作時間。</block>
  <block id="23830778b135794055062035d895d122" category="list-text">NetApp EF600 和NVIDIA DGX 系統之間的檔案系統層是 BeeGFS 平行檔案系統。 BeeGFS 由德國弗勞恩霍夫高效能運算中心創建，旨在解決傳統平行檔案系統的痛點。其結果是一個具有現代用戶空間架構的檔案系統，現在由 ThinkParQ 開發和交付，並被許多超級運算環境使用。</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">NetApp對 BeeGFS 的支援使 NetApp 優秀的支援組織與客戶對效能和正常運作時間的要求保持一致。客戶可以獲得優質的支援資源、提前獲得 BeeGFS 版本，以及使用部分 BeeGFS 企業功能，例如配額實施和高可用性 (HA)。</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">NVIDIA SuperPOD SU 和NetApp BeeGFS 構建塊的結合提供了一種敏捷的 AI 解決方案，其中計算或儲存可以輕鬆無縫地擴展。</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">NetApp BeeGFS 構建塊</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">圖中顯示了單一NetApp BeeGFS 構建塊。</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">用例摘要</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">此解決方案適用於以下用例：</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">人工智慧（AI）包括機器學習（ML）、深度學習（DL）、自然語言處理（NLP）、自然語言理解（NLU）和生成人工智慧（GenAI）。</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">中大規模人工智慧訓練</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">電腦視覺、語音、音訊和語言模型</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">HPC，包括透過訊息傳遞介面 (MPI) 和其他分散式運算技術加速的應用程式</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">應用程式工作負載具有以下特點：</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">讀取或寫入大於 1GB 的文件</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">多個客戶端（10 個、100 個和 1000 個）讀取或寫入相同文件</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">多 TB 或多 PB 資料集</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">需要針對大檔案和小檔案混合進行最佳化的單一儲存命名空間的環境</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">本節介紹採用NetApp解決方案的NVIDIA DGX SuperPOD的技術需求。</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">NVIDIA DGX H100 SuperPOD 參考架構</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DESIGN： NetApp NVA 上的 BeeGFS 設計</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">下表 1 列出了單一 SU 實施解決方案所需的硬體元件。解決方案規模從 32 個NVIDIA DGX H100 系統和兩個或三個NetApp BeeGFS 構建塊開始。單一NetApp BeeGFS 建置區塊由兩個NetApp EF600 陣列和兩台 x86 伺服器組成。隨著部署規模的增加，客戶可以添加額外的建置區塊。有關詳細信息，請參閱<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block>和<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block>。</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 或 H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">NVIDIA Quantum QM9700 交換機</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">8 片葉子，4 根脊柱</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">NetApp BeeGFS 構建塊</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">下表 2 列出了實施此解決方案所需的軟體元件。解決方案的任何特定實施中使用的軟體元件可能會根據客戶要求而有所不同。</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">NVIDIA DGX 軟體堆疊</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">ThinkParQ BeeGFS平行檔案系統</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">解決方案驗證</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD： NetApp EF600 和 BeeGFS 參考架構</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">NVIDIA DGX SuperPOD與NetApp透過使用NetApp BeeGFS 構建塊在NVIDIA的專用驗收集群上進行了驗證。驗收標準是基於NVIDIA執行的一系列應用程式、效能和壓力測試。有關詳細信息，請參閱<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block>。</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">NetApp和NVIDIA有著長期的合作，致力於為市場提供一系列 AI 解決方案。 NVIDIA DGX SuperPOD與NetApp EF600 全快閃陣列結合，是經過驗證的解決方案，客戶可以放心部署。這種完全整合的交鑰匙架構消除了部署風險，使任何人都可以走上贏得人工智慧領導地位的道路。</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">NVIDIA DGX SuperPOD參考架構</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">NVIDIA DGX SuperPOD資料中心設計參考指南</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD： NetApp EF600 和 BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">人工智慧驅動的自動化和邊緣運算是幫助商業組織實現數位轉型並最大限度提高營運效率和安全性的領先方法。透過邊緣運算，資料處理速度更快，因為它不必往返於資料中心。因此，與資料中心或雲端來回發送資料相關的成本就會降低。</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">人工智慧驅動的自動化和邊緣運算是幫助商業組織實現數位轉型並最大限度提高營運效率和安全性的領先方法。透過邊緣運算，資料處理速度更快，因為它不必往返於資料中心。因此，與資料中心或雲端來回發送資料相關的成本就會降低。當企業必須使用部署在邊緣的人工智慧推理模型近乎即時地做出決策時，更低的延遲和更高的速度會很有幫助。</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetApp儲存系統提供與本機 SSD 儲存相同或更好的效能，並為資料科學家、資料工程師、AI/ML 開發人員以及業務或 IT 決策者提供以下優勢：</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">在人工智慧系統、分析系統和其他關鍵業務系統之間輕鬆共享資料。這種資料共享減少了基礎設施開銷，提高了效能，並簡化了整個企業的資料管理。</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">獨立可擴展的計算和存儲，以最大限度地降低成本並提高資源利用率。</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">使用整合的 Snapshot 副本和複製來簡化開發和部署工作流程，以實現即時且節省空間的使用者工作區、整合版本控制和自動部署。</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">實現災難復原和業務連續性的企業級資料保護。本文檔中介紹的NetApp和聯想解決方案是一種靈活的橫向擴展架構，非常適合邊緣企業級 AI 推理部署。</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">致謝</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">俊傑Falkanger，聯想 HPC 和人工智慧解決方案高級經理</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">NetApp技術行銷工程師 Dave Arnette</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell， NetApp E 系列 AI 解決方案技術主管</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman， NetApp品質保證工程師</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">要了解有關本文檔中描述的信息的更多信息，請參閱以下文檔和/或網站：</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF A系列陣列產品頁面</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP資料管理軟體 - ONTAP 9 資訊庫</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727： NetApp EF系列簡介</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E系列SANtricity軟體資料表</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">NetApp容器持久性儲存 — NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow 基準測試</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">聯想 ThinkSystem SE350 邊緣伺服器</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">聯想 ThinkSystem DM5100F 統一快閃儲存陣列</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">本節介紹測試的配置、網路基礎架構、SE350 伺服器和儲存配置詳細資訊。</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">測試配置</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">下圖顯示了測試配置。我們使用了NetApp AFF C190儲存系統和兩台 Lenovo ThinkSystem SE350 伺服器（每台配備一個NVIDIA T4 加速器）。這些組件透過 10GbE 網路交換器連接。網路儲存保存驗證/測試資料集和預訓練模型。伺服器提供運算能力，並透過 NFS 協定存取儲存。</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">本節介紹測試的配置、網路基礎架構、SE350 伺服器和儲存配置詳細資訊。下表列出了解決方案架構的基本元件。</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">聯想 ThinkSystem 伺服器</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 台 SE350 伺服器，每台配備一張NVIDIA T4 GPU 卡</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">每台伺服器包含一個 Intel Xeon D-2123IT CPU，該 CPU 具有四個實體核心，運行頻率為 2.20GHz，並配備 128GB RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">入門級NetApp AFF儲存系統（HA 對）</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 軟體</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24個960GB SSD</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS 協定</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">每個控制器一個介面組，具有四個用於掛載點的邏輯 IP 位址</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">下表列出了儲存配置： AFF C190 ，24 個磁碟機插槽。</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">控制器</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">總計的</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup卷</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">聚合尺寸</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">體積大小</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">作業系統掛載點</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo_AI_fg 資料夾包含用於模型驗證的資料集。</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">下圖顯示了測試配置。我們使用了NetApp EF280 儲存系統和兩台 Lenovo ThinkSystem SE350 伺服器（每台配備一個NVIDIA T4 加速器）。這些組件透過 10GbE 網路交換器連接。網路儲存保存驗證/測試資料集和預訓練模型。伺服器提供運算能力，並透過 NFS 協定存取儲存。</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">下表列出了 EF280 的儲存配置。</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">卷組</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">體積</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDP大小</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">連接方法</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">第 1 卷</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 到 iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">第 2 卷</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 到 iSCSI LUN 1</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">本文檔介紹了一種運算和儲存架構，用於在滿足新興應用場景的邊緣環境中在NetApp儲存控制器和 Lenovo ThinkSystem 伺服器上部署基於 GPU 的人工智慧 (AI) 推理。</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886：邊緣 AI 推理 - NetApp與聯想 ThinkSystem - 解決方案設計</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan， NetApp Miroslav Hodak，聯想</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">總結</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">高級駕駛輔助系統 (ADAS)、工業 4.0、智慧城市和物聯網 (IoT) 等一些新興應用情境需要在接近零延遲的情況下處理連續資料流。本文檔介紹了一種運算和儲存架構，用於在滿足這些要求的邊緣環境中的NetApp儲存控制器和 Lenovo ThinkSystem 伺服器上部署基於 GPU 的人工智慧 (AI) 推理。本文檔還提供了業界標準 MLPerf 推理基準的效能數據，評估了配備NVIDIA T4 GPU 的邊緣伺服器上的各種推理任務。我們研究了離線、單流和多流推理場景的效能，並表明具有經濟高效的共享網路儲存系統的架構性能高，並為多個邊緣伺服器的資料和模型管理提供了中心點。</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">越來越多的公司在網路邊緣產生大量數據。為了從智慧感測器和物聯網數據中獲得最大價值，組織正在尋找能夠實現邊緣運算的即時事件流解決方案。因此，運算要求高的工作越來越多地在資料中心之外的邊緣執行。人工智慧推理是這一趨勢的驅動因素之一。邊緣伺服器為這些工作負載提供了足夠的運算能力，尤其是在使用加速器時，但有限的儲存空間通常是一個問題，尤其是在多伺服器環境中。在本文檔中，我們展示瞭如何在邊緣環境中部署共享儲存系統，以及它如何在不影響效能的情況下使 AI 推理工作負載受益。</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">本文檔描述了邊緣 AI 推理的參考架構。它將多台聯想 ThinkSystem 邊緣伺服器與NetApp儲存系統結合，以創建易於部署和管理的解決方案。它旨在成為各種情況下實際部署的基準指南，例如具有多個攝影機和工業感測器的工廠車間、零售交易中的銷售點 (POS) 系統或識別自動駕駛汽車視覺異常的全自動駕駛 (FSD) 系統。</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">本文檔涵蓋由 Lenovo ThinkSystem SE350 Edge 伺服器和入門級NetApp AFF和 EF 系列儲存系統組成的運算和儲存配置的測試和驗證。參考架構為 AI 部署提供了高效且經濟的解決方案，同時也透過NetApp ONTAP和NetApp SANtricity資料管理軟體提供全面的資料服務、整合資料保護、無縫可擴充性和雲端連接資料儲存。</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">本文檔適用於以下受眾：</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">希望將邊緣 AI 產品化的商業領袖和企業架構師。</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">資料科學家、資料工程師、人工智慧/機器學習 (ML) 研究人員和人工智慧系統開發人員。</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">為 AI/ML 模型和應用程式的開發設計解決方案的企業架構師。</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">資料科學家和人工智慧工程師正在尋找部署深度學習 (DL) 和 ML 模型的有效方法。</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">負責邊緣推理模型的部署和管理的邊緣設備管理員和邊緣伺服器管理員。</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">解決方案架構</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">這款聯想 ThinkSystem 伺服器和NetApp ONTAP或NetApp SANtricity儲存解決方案旨在利用 GPU 和傳統 CPU 的處理能力來處理大型資料集上的 AI 推理。此驗證展示了高效能和最佳資料管理，其架構使用單一或多個 Lenovo SR350 邊緣伺服器與單一NetApp AFF儲存系統互連，如以下兩圖所示。</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">下圖中的邏輯架構概覽展示了此架構中運算和儲存元素的角色。具體來說，它顯示了以下內容：</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">邊緣運算設備對從攝影機、感測器等接收的資料進行推理。</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">具有多種用途的共享儲存元素：</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">為推理模型和執行推理所需的其他數據提供一個中心位置。計算伺服器直接存取儲存空間並透過網路使用推理模型，而無需在本地複製它們。</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">更新的模型推送到這裡。</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">將邊緣伺服器接收的輸入資料存檔以供日後分析。例如，如果邊緣設備連接到攝影機，則儲存元件會保存攝影機擷取的視訊。</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">紅色的</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">藍色的</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">聯想計算系統</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF儲存系統</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">邊緣設備對來自相機、感測器等的輸入進行推理。</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">共享儲存保存推理模型和來自邊緣設備的數據以供後續分析。</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">NetApp和聯想的解決方案有以下主要優勢：</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">邊緣 GPU 加速運算。</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">部署由共享儲存支援和管理的多個邊緣伺服器。</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">強大的資料保護，滿足低恢復點目標 (RPO) 和復原時間目標 (RTO)，且不會遺失資料。</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">使用NetApp Snapshot 副本和克隆優化資料管理，以簡化開發工作流程。</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">如何使用此架構</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">本文檔驗證了所提出的架構的設計和效能。但是，我們還沒有測試某些軟體層級的部分，例如容器、工作負載或模型管理以及與雲端或資料中心內部的資料同步，因為它們特定於部署場景。這裡存在多種選擇。</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">NetApp AI 控制平面</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">在容器管理層面，Kubernetes 容器管理是一個不錯的選擇，無論是完全上游版本（Canonical）還是適合企業部署的修改版本（Red Hat）都得到了很好的支援。這<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block>它採用NetApp Trident和新添加的<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block>為資料科學家和資料工程師提供內建的可追溯性、資料管理功能、介面和工具，以便與NetApp儲存整合。 Kubeflow 是 Kubernetes 的 ML 工具包，它提供了額外的 AI 功能，並在 TensorFlow Serving 或NVIDIA Triton Inference Server 等多個平台上支援模型版本控制和 KFServing。另一個選擇是NVIDIA EGX 平台，它提供工作負載管理以及對支援 GPU 的 AI 推理容器目錄的存取。然而，這些選項可能需要付出大量努力和專業知識才能投入生產，並且可能需要第三方獨立軟體供應商 (ISV) 或顧問的協助。</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">解決方案領域</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 推理和邊緣運算的主要優勢在於設備能夠高品質且無延遲地計算、處理和分析數據。本文檔中描述了太多的邊緣運算用例範例，但以下是一些突出的用例：</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">汽車：自動駕駛汽車</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">經典的邊緣運算範例是自動駕駛汽車（AV）中的高級駕駛輔助系統（ADAS）。無人駕駛汽車中的人工智慧必須快速處理來自攝影機和感測器的大量數據才能成為成功的安全駕駛員。花費太長時間來解讀物體和人之間的差異可能意味著生死，因此能夠盡可能靠近車輛處理資料至關重要。在這種情況下，一個或多個邊緣運算伺服器處理來自攝影機、雷達、光達和其他感測器的輸入，而共享儲存保存推理模型並儲存來自感測器的輸入資料。</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">醫療保健：病患監護</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">人工智慧和邊緣運算的最大影響之一是它能夠增強對家庭護理和重症監護病房 (ICU) 中慢性病患者的持續監測。監測胰島素水平、呼吸、神經活動、心律和胃腸功能的邊緣設備的數據需要即時分析，並且必須立即採取行動，因為採取行動來挽救某人的生命的時間有限。</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">零售：無收銀員支付</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">邊緣運算可以為人工智慧和機器學習提供支持，幫助零售商減少結帳時間並增加客流量。無收銀系統支援各種組件，例如：</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">身份驗證和存取。將實體購物者連接到已驗證的帳戶並允許進入零售空間。</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">庫存監控。使用感測器、RFID 標籤和電腦視覺系統來幫助購物者確認選擇或取消選擇商品。</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">在這裡，每個邊緣伺服器處理每個結帳櫃檯，共享儲存系統作為中央同步點。</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">金融服務：自助服務終端的人員安全與詐欺預防</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">銀行機構正在使用人工智慧和邊緣運算來創新和創造個人化的銀行體驗。使用即時數據分析和人工智慧推理的互動式自助服務終端現在不僅能夠讓 ATM 機幫助客戶提款，還能透過攝影機擷取的影像主動監控自助服務終端，以識別對人類安全的風險或詐欺行為。在這個場景中，邊緣運算伺服器和共享儲存系統連接到互動式資訊亭和攝影機，幫助銀行使用人工智慧推理模型收集和處理資料。</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">製造業：工業4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">第四次工業革命（工業 4.0）已經開始，同時也出現了智慧工廠和 3D 列印等新興趨勢。為了迎接資料主導的未來，大規模機器對機器 (M2M) 通訊和物聯網被整合在一起，以提高自動化程度，而無需人工幹預。製造業已經高度自動化，添加人工智慧功能是長期趨勢的自然延續。人工智慧可以實現自動化操作，這些操作可以藉助電腦視覺和其他人工智慧功能實現。您可以自動化品質控製或依賴人類視覺或決策的任務，以便對工廠車間裝配線上的材料進行更快的分析，幫助製造工廠滿足所需的 ISO 安全和品質管理標準。在這裡，每個運算邊緣伺服器都連接到監控製造過程的感測器陣列，並根據需要將更新的推理模型推送到共用儲存。</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">電信：鏽蝕檢測、塔台檢查和網路最佳化</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">電信業使用電腦視覺和人工智慧技術處理影像，自動檢測鏽蝕並識別含有腐蝕並因此需要進一步檢查的手機訊號塔。近年來，使用無人機影像和人工智慧模型來識別塔的不同區域以分析鏽蝕、表面裂縫和腐蝕的情況越來越多。人們對人工智慧技術的需求持續成長，這些技術可以有效地檢查電信基礎設施和手機訊號塔，定期評估其性能是否下降，並在需要時及時修復。</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">此外，電信領域的另一個新興用例是使用人工智慧和機器學習演算法來預測資料流量模式、檢測支援 5G 的設備以及自動化和增強多輸入多輸出 (MIMO) 能源管理。無線電塔使用 MIMO 硬體來增加網路容量；然而，這會帶來額外的能源成本。部署在蜂窩基地台的「MIMO 睡眠模式」的 ML 模型可以預測無線電的有效使用情況，並有助於降低行動網路營運商 (MNO) 的能源消耗成本。人工智慧推理和邊緣運算解決方案可協助 MNO 減少往返資料中心的資料量、降低 TCO、優化網路營運並提高最終用戶的整體效能。</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">本文檔遵循 MLPerf Inference v0.7 程式碼、MLPerf Inference v1.1 程式碼和規則。我們執行了專為邊緣推理而設計的基準測試，如本節表格中所定義。</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">測試計劃</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">程式碼</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">規則</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">本文檔遵循 MLPerf Inference v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> ，MLPerf 推理 v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> ， 和<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>。我們運行了專為邊緣推理而設計的 MLPerf 基準，如下表所定義。</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">區域</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">模型</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">數據集</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL尺寸</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">品質</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">多流延遲約束</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">想像</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">影像分類</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">影像網（224x224）</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32 的 99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50毫秒</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">物體偵測（大）</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">可可 (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66毫秒</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">物體檢測（小）</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD-MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">可可 (300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">醫學影像分割</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">BraTS 2019（224x224x160）</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32 的 99% 和 99.9%</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">演講</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">語音轉文本</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech dev-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">語言</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">語言處理</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">SQuAD v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">下表列出了 Edge 基準測試場景。</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">場景</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">影像分類</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">單流、離線、多流</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">單流、離線</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">語音轉文本</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">我們使用本次驗證中開發的網路儲存架構執行了這些基準測試，並將結果與先前提交給 MLPerf 的邊緣伺服器上的本機運行結果進行了比較。比較是為了確定共享儲存對推理效能有多大的影響。</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">本節介紹用於驗證該解決方案的測試程序。</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">測試程式</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">作業系統和 AI 推理設置</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">對於AFF C190，我們使用了具有NVIDIA驅動程式的 Ubuntu 18.04 和支援NVIDIA GPU 的 docker，並使用了 MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>作為聯想向 MLPerf Inference v0.7 提交的一部分提供。</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">對於 EF280，我們使用了具有NVIDIA驅動程式的 Ubuntu 20.04 和支援NVIDIA GPU 和 MLPerf 的 docker<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>作為聯想向 MLPerf Inference v1.1 提交的一部分提供。</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">若要設定 AI 推理，請依照下列步驟操作：</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">下載需要註冊的資料集，ImageNet 2012 驗證集、Criteo Terabyte 資料集、BraTS 2019 訓練集，然後解壓縮檔案。</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">建立至少 1TB 的工作目錄並定義環境變數<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block>參考目錄。</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">您應該在網路儲存用例的共用儲存體上共用此目錄，或在使用本機資料進行測試時在本機磁碟上共用此目錄。</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">運行 make<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block>命令，該命令為所需的推理任務建置並啟動 docker 容器。</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">以下命令均在正在執行的 docker 容器內執行：</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">下載用於 MLPerf 推理任務的預訓練 AI 模型：<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">下載可免費下載的其他資料集：<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">預處理資料：<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">跑步：<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> 。</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">建立針對計算伺服器中的 GPU 最佳化的推理引擎：<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">若要執行推理工作負載，請執行以下命令（一個命令）：</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI推理運行</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">執行了三種類型的運行：</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">使用本地儲存的單一伺服器 AI 推理</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">使用網路儲存的單一伺服器 AI 推理</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">使用網路儲存的多伺服器 AI 推理</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">我們進行了大量的測試來評估所提出的架構的效能。有六種不同的工作負載（影像分類、物件偵測 [小]、物件偵測 [大]、醫學影像、語音轉文字和自然語言處理 [NLP]），您可以在三種不同的場景中運行 - 離線、單流和多流。</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">測試結果</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">我們進行了大量的測試來評估所提出的架構的效能。</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">有六種不同的工作負載（影像分類、物件偵測[小]、物件偵測[大]、醫學影像、語音轉文字和自然語言處理[NLP]），您可以在三種不同的場景中運行：離線、單流和多流。</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">最後一種場景僅用於影像分類和物件檢測。</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">這給出了 15 種可能的工作負載，它們都在三種不同的設定下進行了測試：</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">單一伺服器/本地存儲</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">單一伺服器/網路存儲</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">多伺服器/網路存儲</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">結果在以下章節中描述。</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFF離線場景下的AI推理</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">在這種情況下，所有資料都可供伺服器使用，並且測量處理所有樣本所需的時間。我們將每秒樣本的頻寬作為測試結果來報告。當使用多台計算伺服器時，我們會報告所有伺服器的總頻寬。下圖顯示了所有三個用例的結果。對於雙伺服器的情況，我們報告兩台伺服器的組合頻寬。</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">結果表明，網路儲存不會對效能產生負面影響——變化很小，對於某些任務來說，沒有發現任何變化。當添加第二台伺服器時，總頻寬要么正好翻倍，要么在最壞的情況下，變化小於 1%。</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">AFF單流場景下的 AI 推理</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">該基準測量延遲。對於多計算伺服器的情況，我們報告平均延遲。下圖給出了這組任務的結果。對於雙伺服器的情況，我們報告兩台伺服器的平均延遲。</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">結果再次表明，網路儲存足以處理這些任務。在一台伺服器的情況下，本地儲存和網路儲存之間的差異很小或沒有。類似地，當兩台伺服器使用相同的儲存空間時，兩台伺服器上的延遲保持不變或變化很小。</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">AFF多流場景下的 AI 推理</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">在這種情況下，結果是系統在滿足 QoS 限制的同時可以處理的流的數量。因此，結果始終是整數。對於多台伺服器，我們報告所有伺服器上的流量總數。並非所有工作負載都支援此場景，但我們執行了支援此場景的工作負載。下圖總結了我們的測試結果。對於雙伺服器的情況，我們報告來自兩個伺服器的流的總數。</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">結果顯示該設定的效能完美——本地和網路儲存給出相同的結果，並且添加第二台伺服器使建議的設定可以處理的串流數量增加一倍。</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EF 測試結果</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">我們進行了大量的測試來評估所提出的架構的效能。有六種不同的工作負載（影像分類、物件偵測[小]、物件偵測[大]、醫學影像、語音轉文字和自然語言處理[NLP]），它們在兩種不同的場景中運作：離線和單流。結果在以下章節中描述。</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EF 離線場景下的 AI 推理</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">在這種情況下，所有資料都可供伺服器使用，並且測量處理所有樣本所需的時間。我們將每秒樣本的頻寬作為測試結果來報告。對於單一節點運行，我們報告兩台伺服器的平均值，而對於雙伺服器運行，我們報告所有伺服器的總頻寬總和。用例的結果如下圖所示。</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">EF 單流場景下的 AI 推理</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">該基準測量延遲。對於所有情況，我們報告運行中涉及的所有伺服器的平均延遲。給出了這一系列任務的結果。</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">結果再次顯示網路儲存足以處理這些任務。在一台伺服器的情況下，本地儲存和網路儲存之間的差異很小或沒有。類似地，當兩台伺服器使用相同的儲存空間時，兩台伺服器上的延遲保持不變或變化很小。</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">您可以調整用於驗證的設定以適合其他用例。</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">架構規模選項</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">計算伺服器</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">我們使用了 Intel Xeon D-2123IT CPU，這是 SE350 支援的最低等級的 CPU，具有四個實體核心和 60W TDP。雖然該伺服器不支援更換 CPU，但可以訂購功能更強大的 CPU。支援的最高 CPU 是 Intel Xeon D-2183IT，16 核，100W，運行頻率為 2.20GHz。這大大提高了CPU的運算能力。雖然 CPU 本身並不是運行推理工作負載的瓶頸，但它有助於資料處理和其他與推理相關的任務。目前， NVIDIA T4 是唯一可用於邊緣用例的 GPU；因此，目前無法升級或降級 GPU。</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">共享儲存</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">為了進行測試和驗證，本文檔使用了NetApp AFF C190系統，該系統的最大儲存容量為 50.5TB，順序讀取的吞吐量為 4.4GBps，小型隨機讀取的吞吐量為 230K IOPS，事實證明它非常適合邊緣推理工作負載。</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">但是，如果您需要更大的儲存容量或更快的網路速度，則應該使用NetApp AFF A220或NetApp AFF A250儲存系統。此外，最大容量1.5PB、頻寬10GBps的NetApp EF280系統也被用於此解決方案的驗證。如果您希望擁有更大的儲存容量和更高的頻寬，<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block>可以使用。</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">本節介紹此AI解決方案的技術基礎。</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">NetApp AFF系統</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">最先進的NetApp AFF儲存系統支援邊緣 AI 推理部署，以業界領先的效能、卓越的靈活性、雲端整合和一流的資料管理滿足企業儲存需求。  NetApp AFF系統專為快閃記憶體設計，有助於加速、管理和保護業務關鍵資料。</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">入門級NetApp AFF儲存系統基於FAS2750硬體和 SSD 快閃記憶體媒體</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA 配置中的兩個控制器</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetApp入門級AFF C190儲存系統支援以下功能：</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">最大驅動器數量為 24 個 960GB SSD</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">兩種可能的配置：</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">乙太網路 (10GbE)：4 個 10GBASE-T (RJ-45) 端口</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">統一（16Gb FC 或 10GbE）：4 個統一目標適配器 2 (UTA2) 端口</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">最大50.5TB有效容量</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">對於 NAS 工作負載，單一入門級AFF C190系統支援 4.4GBps 的順序讀取吞吐量和 230K IOPS 的小型隨機讀取吞吐量，延遲時間為 1ms 或更短。</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp還提供其他入門級儲存系統，為更大規模的部署提供更高的效能和可擴充性。對於 NAS 工作負載，單一入門級AFF A220系統支援：</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">順序讀取吞吐量為 6.2GBps</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375K IOPS，用於延遲為 1ms 或更短的小隨機讀取</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">最大驅動器數量為 144 個 960GB、3.8TB 或 7.6TB SSD</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220可擴充至超過 1PB 的有效容量</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">最大有效容量為 35PB，最大橫向擴展 2-24 個節點（12 個 HA 對）</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">性能比AFF A220提高 ≥ 45%</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440k IOPS 隨機讀取@1ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">基於最新的NetApp ONTAP版本： ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">利用兩個 25Gb 乙太網路實現 HA 和群集互連</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E系列EF系統</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF 系列是入門級和中檔全快閃 SAN 儲存陣列系列，可加速對資料的訪問，並幫助您透過NetApp SANtricity軟體更快地從中獲取價值。這些系統提供 SAS 和 NVMe 快閃記憶體，並為您提供從經濟實惠到極致的 IOPS、低於 100 微秒的響應時間和高達 44GBps 的頻寬，使其成為混合工作負載和 AI 推理和高效能運算 (HPC) 等要求苛刻的應用程式的理想選擇。</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">下圖顯示的是NetApp EF280 儲存系統。</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32Gb/16Gb FC、25Gb/10Gb iSCSI 和 12Gb SAS 支持</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">最大有效容量為 96 個驅動器，總計 1.5PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">吞吐量為 10GBps（順序讀取）</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300K IOPs（隨機讀取）</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280 是NetApp產品組合中成本最低的全快閃陣列 (AFA)</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 個 NVMe SSD 驅動器，總容量為 367TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">擴充選項總計 240 個 NL-SAS HDD、96 個 SAS SSD 或組合</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100Gb NVMe/IB、NVMe/RoCE、iSER/IB 和 SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32Gb NVME/FC，FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25Gb iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20GBps（連續讀取）</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPs（隨機讀取）</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF 系列NetApp EF 系列全快閃陣列 EF600、F300、EF570 和 EF280 資料表</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">有關詳細信息，請參閱<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>。</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1 是NetApp最新一代的儲存管理軟體，它支援企業實現基礎架構現代化並過渡到雲端就緒資料中心。 ONTAP利用業界領先的數據管理功能，只需一套工具即可管理和保護數據，無論數據位於何處。您也可以將資料自由移動到任何需要的地方：邊緣、核心或雲端。  ONTAP 9.8.1 包含眾多功能，可簡化資料管理、加速和保護關鍵數據，並支援跨混合雲架構的下一代基礎架構功能。</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">資料管理對於企業 IT 營運至關重要，以便為應用程式和資料集使用適當的資源。  ONTAP包括以下功能，可簡化操作並降低整體營運成本：</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*內聯資料壓縮和擴展重複資料刪除。 *資料壓縮減少了儲存區塊內部浪費的空間，重複資料刪除顯著增加了有效容量。這適用於本地儲存的資料和分層到雲端的資料。</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*最小、最大和自適應服務品質 (AQoS)。 *細粒度的服務品質 (QoS) 控制有助於維持高度共享環境中關鍵應用程式的效能水準。</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool。 *此功能可將冷資料自動分層至公有和私有雲端儲存選項，包括 Amazon Web Services (AWS)、Azure 和NetApp StorageGRID儲存解決方案。有關FabricPool的更多信息，請參閱<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>。</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 提供卓越等級的效能和資料保護，並透過以下方式擴展這些功能：</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*性能和更低的延遲。 *  ONTAP以盡可能低的延遲提供盡可能高的吞吐量。</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*資料保護*  ONTAP提供內建資料保護功能，並在所有平台上提供通用管理。</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NetApp磁碟區加密 (NVE)。 *  ONTAP提供原生磁碟區級加密，同時支援板載和外部金鑰管理。</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*多租戶和多因素身份驗證。 *  ONTAP支援以最高等級的安全性共用基礎架構資源。</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 具有以下功能，可協助滿足嚴苛且不斷變化的業務需求：</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*無縫擴展和無中斷運行。 * ONTAP支援無中斷地向現有控制器和橫向擴展叢集添加容量。客戶可以升級到最新技術，例如 NVMe 和 32Gb FC，而無需昂貴的資料遷移或中斷。</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*雲端連線。 *  ONTAP是與雲端連接最緊密的儲存管理軟體，在所有公有雲中均提供軟體定義儲存（ONTAP Select）和Google Cloud NetApp Volumes Volumes ）的選項。</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*與新興應用程式整合。 *  ONTAP使用支援現有企業應用的相同基礎架構，為下一代平台和應用（如自動駕駛汽車、智慧城市和工業 4.0）提供企業級資料服務。</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E系列SANtricity軟體資料表</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity旨在為 E 系列混合快閃記憶體和 EF 系列全快閃陣列提供業界領先的效能、可靠性和簡單性。實現 E 系列混合快閃記憶體和 EF 系列全快閃陣列的最大效能和使用率，適用於資料分析、視訊監控以及備份和復原等高負載應用程式。借助SANtricity，可以在儲存保持在線的情況下完成配置調整、維護、容量擴展和其他任務。 SANtricity還提供卓越的資料保護、主動監控和經過認證的安全性——所有這些都可以透過易於使用的機上系統管理員介面存取。要了解更多信息，請參閱<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>。</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">效能最佳化</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">效能最佳化的SANtricity軟體以高 IOPS、高吞吐量和低延遲向您的所有資料分析、視訊監控和備份應用程式提供資料。加速高 IOPS、低延遲應用程式以及高頻寬、高吞吐量應用程式的效能。</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">最大化正常運作時間</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">在儲存保持在線時完成所有管理任務。調整配置、執行維護或擴充容量，而無需中斷 I/O。透過自動化功能、線上配置、最先進的動態磁碟池 (DPP) 技術等實現一流的可靠性。</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">安心休息</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity軟體透過易於使用的機載系統管理員介面提供卓越的資料保護、主動監控和認證的安全性。簡化儲存管理工作。獲得對所有 E 系列儲存系統進行進階調整所需的靈活性。隨時隨地管理您的NetApp E 系列系統。我們的網路為基礎的機載介面簡化了您的管理工作流程。</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>NetApp推出的一款適用於 Docker 和 Kubernetes 的開源動態儲存編排器，可簡化持久性儲存的建立、管理和使用。  Trident是 Kubernetes 原生應用程序，直接在 Kubernetes 叢集內運作。  Trident讓客戶能夠將 DL 容器映像無縫部署到NetApp儲存體上，並為 AI 容器部署提供企業級體驗。  Kubernetes 使用者（例如 ML 開發人員和資料科學家）可以建立、管理和自動化編排和克隆，以利用由NetApp技術支援的NetApp進階資料管理功能。</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>是NetApp 的一項快速、安全的資料同步服務。無論您需要在本機 NFS 或 SMB 檔案共用、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、Amazon Simple Storage Service (Amazon S3)、Amazon Elastic File System (Amazon EFS)、Azure Blob、Google )傳輸都能快速安全地將文件移動到您需要的位置。資料傳輸完成後，可在來源端和目標端完全使用。  BlueXP Copy and Sync 根據您預先定義的時間表持續同步數據，僅移動增量，從而最大限度地減少數據複製所花費的時間和金錢。  BlueXP Copy and Sync 是一種軟體即服務 (SaaS) 工具，其設定和使用極為簡單。 BlueXP Copy 和 Sync 觸發的資料傳輸由資料代理執行。您可以在 AWS、Azure、Google Cloud Platform 或本機部署BlueXP Copy 和 Sync 資料代理程式。</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">聯想 ThinkSystem 伺服器採用創新的硬體、軟體和服務，可解決客戶當前面臨的挑戰，並提供革命性的、適合用途的模組化設計方法來應對未來的挑戰。這些伺服器利用一流的行業標準技術以及差異化的聯想創新，為 x86 伺服器提供最大的靈活性。</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">部署聯想 ThinkSystem 伺服器的主要優勢包括：</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">高度可擴展、模組化設計，可隨著您的業務成長</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">業界領先的彈性，可節省數小時昂貴的計劃外停機時間</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">快速快閃記憶體技術可實現更低的延遲、更快的回應時間和更智慧的即時資料管理</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">在人工智慧領域，聯想正在採取切實可行的方法來幫助企業了解並採用機器學習和人工智慧為其工作負載帶來的好處。聯想客戶可以在聯想人工智慧創新中心探索和評估聯想人工智慧產品，以充分了解其特定用例的價值。為了縮短價值實現時間，這種以客戶為中心的方法為客戶提供了可立即使用且針對 AI 進行最佳化的解決方案開發平台的概念驗證。</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">邊緣運算允許在網路邊緣分析來自物聯網設備的數據，然後再將其發送到資料中心或雲端。如下圖所示，聯想 ThinkSystem SE350 專為滿足邊緣部署的獨特要求而設計，注重靈活性、連接性、安全性和遠端可管理性，具有緊湊、堅固且耐環境侵蝕的外形。</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">SE350 配備英特爾至強 D 處理器，可靈活支援邊緣 AI 工作負載的加速，專為解決資料中心外各種環境中的伺服器部署挑戰而設計。</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf 推理 v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf 是業界領先的評估 AI 效能的基準套件。它涵蓋了應用人工智慧的許多領域，包括影像分類、物件檢測、醫學成像和自然語言處理 (NLP)。在本次驗證中，我們使用了 Inference v0.7 工作負載，這是本次驗證完成時 MLPerf Inference 的最新版本。這<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block>該套件包括四個針對資料中心和邊緣系統的新基準：</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*伯特*使用 SQuAD 資料集對 Transformer 的雙向編碼器表示 (BERT) 進行微調，以用於問答。</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM。 *深度學習推薦模型 (DLRM) 是一種經過訓練以優化點擊率 (CTR) 的個人化和推薦模型。</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">3D U-Net。  3D U-Net 架構在腦腫瘤分割 (BraTS) 資料集上進行訓練。</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T* 循環神經網路感測器 (RNN-T) 是一種在 LibriSpeech 子集上訓練的自動語音辨識 (ASR) 模型。  MLPerf 推理結果和程式碼是公開的，並根據 Apache 許可發布。  MLPerf Inference 有一個 Edge 部門，支援以下場景：</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*單流。 *該場景模擬了響應能力是關鍵因素的系統，例如在智慧型手機上執行的離線 AI 查詢。單獨的查詢被傳送到系統並記錄回應時間。所有回應的第 90 個百分位延遲被報告為結果。</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*多流。 *此基準適用於處理來自多個感測器的輸入的系統。在測試期間，查詢以固定的時間間隔發送。施加了 QoS 約束（允許的最大延遲）。此測試報告系統在滿足 QoS 約束的情況下可以處理的流數量。</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*離線。 *這是涵蓋批次應用程式的最簡單的場景，其指標是每秒樣本的吞吐量。所有數據均可供系統使用，基準測量處理所有樣本所需的時間。</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">聯想已發佈本文檔中使用的伺服器 SE350 與 T4 的 MLPerf 推理分數。查看結果<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block>在條目 #0.7-145 的「邊緣，封閉分區」部分。</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">可以調整用於驗證的設定以適應其他用例。</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">架構調整</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">可以調整用於此驗證的設定以適應其他用例。</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">CPU調整</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">按照聯想的推薦，我們使用 Skylake Intel Xeon Platinum 8360Y 處理器進行此驗證。我們預期同等的 Cascade Lake CPU（英特爾至強金牌 6330 處理器）將提供類似的效能，因為此工作負載不受 CPU 限制。</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">增加儲存容量</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">根據您的儲存容量需求，您可以按需增加共用儲存（NFS 磁碟區），前提是您有額外的磁碟架和控制器型號。您可以以管理員使用者身分從 CLI 或儲存控制器的NetApp Web 介面執行此操作。</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">NetApp和聯想的解決方案是一種靈活的橫向擴展架構，非常適合進入中型企業 AI。  NetApp儲存提供與本地 SSD 儲存相同或更好的效能，並為資料科學家、資料工程師和 IT 決策者提供以下優勢。</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">這裡驗證的NetApp和聯想解決方案是一種靈活的橫向擴展架構，非常適合進入中型企業 AI。</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">NetApp儲存提供與本地 SSD 儲存相同或更好的效能，並為資料科學家、資料工程師和 IT 決策者提供以下優勢：</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">獨立可擴展的計算和存儲，以最大限度地降低成本並提高資源利用率。</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">使用整合快照和複製來簡化開發和部署工作流程，以實現即時且節省空間的使用者工作區、整合版本控制和自動部署。</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">用於災難復原和業務連續性的企業級資料保護。</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam， NetApp技術行銷工程師</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton，聯想人工智慧實驗室系統管理員</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">NetApp全快閃陣列產品頁面</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">NetApp AFF A400頁面</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">NetApp ONTAP資料管理軟體產品頁面</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI（nvidia-smi）</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">本節介紹測試的配置、網路基礎架構、SR670 V2 伺服器和儲存配置詳細資訊。</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">本節介紹測試的配置、網路基礎架構、SR670 V2 伺服器和NetApp儲存配置詳細資訊。</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">我們使用下表列出的解決方案元件進行此驗證。</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">兩台 SR670 V2 伺服器，每台配備八張NVIDIA A100 80GB GPU 卡</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">每台伺服器包含 2 個 Intel Xeon Platinum 8360Y CPU（28 個實體核心）和 1TB RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux（Ubuntu - 20.04，附 CUDA 11.8）</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">NetApp AFF儲存系統（HA 對）</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">NetApp ONTAP 9.10.1軟體</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">每個控制器 1 個介面組 (ifgrp)，具有四個用於掛載點的邏輯 IP 位址</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">在本次驗證中，我們使用了 ResNet v2.0 和 MLPerf v2.0 指定的 ImageNet 基底集。資料集儲存在具有 NFS 協定的NetApp AFF儲存系統中。  SR670 透過 100GbE 交換器連接到NetApp AFF A400儲存系統。</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet 是一個經常使用的影像資料集。它包含近 130 萬張圖片，總大小為 144GB。平均影像大小為 108KB。</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">下圖描述了測試配置的網路拓撲。</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">此圖描繪了運算層（聯想 ThinkSystem SR670 V2）、網路層（聯想乙太網路交換器）和儲存層（ NetApp AFF A400儲存控制器）。包括所有網路連線。</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">下表列出了儲存配置。</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">骨材大小</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">卷大小</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">作業系統掛載點</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100克</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9.9TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">/a400-100g 資料夾包含用於 ResNet 驗證的資料集。</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">本節描述了詳細的測試過程結果。</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">測試程序和詳細結果</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">在ONTAP中使用 ResNet 進行影像辨識訓練</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">我們使用一台和兩台 SR670 V2 伺服器執行 ResNet50 基準測試。本次測試使用MXNet 22.04-py3 NGC容器運行訓練。</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">我們在本次驗證中使用了以下測試程序：</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">我們在運行腳本之前清除了主機緩存，以確保資料尚未被緩存：</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">我們在伺服器儲存（本機 SSD 儲存）以及NetApp AFF儲存系統上使用 ImageNet 資料集執行基準測試腳本。</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">我們使用以下方法驗證了網路和本地儲存效能<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>命令。</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">對於單節點運行，我們使用以下命令：</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">對於分散式運行，我們使用了參數伺服器的並行化模型。我們每個節點使用兩個參數伺服器，並將 epoch 數設定為與單節點運行相同。我們這樣做是因為由於進程之間的同步不完善，分散式訓練通常需要更多的時期。不同的時期數可能會扭曲單節點和分佈式情況之間的比較。</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">資料讀取速度：本地儲存與網路儲存</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">讀取速度是透過<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>對 ImageNet 資料集的其中一個檔案執行指令。具體來說，我們對本地和網路資料運行以下命令：</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">兩個值相似，表示網路儲存可以以與本地儲存相似的速率傳輸資料。</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">共享用例：多個獨立、同時的作業</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">該測試模擬了該解決方案的預期用例：多作業、多用戶 AI 訓練。每個節點在使用共享網路儲存的同時運行自己的訓練。結果如下圖所示，從圖中可以看出，該解決方案案例提供了出色的效能，所有作業的運行速度與單一作業基本相同。總吞吐量與節點數量成線性關係。</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">該圖顯示了每秒的聚合影像數。</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">此圖顯示了運行時間（以分鐘為單位）。</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">這些圖表顯示了使用 100 GbE 用戶端網路上每個伺服器的八個 GPU 的運算節點的運行時間（以分鐘為單位）和每秒的聚合圖像數，結合了並發訓練模型和單一訓練模型。訓練模型的平均運作時間為35分9秒。個人成績分別為34分32秒、36分21秒、34分37秒、35分25秒、34分31秒。訓練模型每秒的平均影像數為 22,573 張，每秒的單一影像數為 21,764 張；23,438 張；22,556 張；22,564 張；22,547 張。</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">根據我們的驗證，一個使用NetApp資料運行時間的獨立訓練模型的運行時間為 34 分 54 秒，每秒 22,231 張圖像。一個具有本地資料（DAS）的獨立訓練模型的運行時間為 34 分 21 秒，每秒 22,102 張影像。在這些運行期間，平均 GPU 利用率為 96%，如在 nvidia-smi 上觀察到的。請注意，此平均值包括測試階段，在此期間未使用 GPU，而 CPU 利用率為 40%（由 mpstat 測量）。這表明在每種情況下數據傳輸率都是足夠的。</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">該解決方案專注於入門級和中端叢集架構，使用針對人工智慧工作負載優化的NetApp儲存和聯想伺服器。它適用於大多數運算作業是單節點（單或多 GPU）或分佈在幾個運算節點上的中小型團隊。這不是一個主要的限制，因為大多數日常的人工智慧訓練工作都是單節點的。</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810： NetApp AFF A400與聯想 ThinkSystem SR670 V2 搭配用於 AI 與 ML 模型訓練</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan、David Arnette、 NetApp Mircea Troaca、聯想</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">該解決方案採用了NetApp儲存和針對人工智慧 (AI) 工作負載優化的聯想伺服器的中階叢集架構。它適用於大多數運算作業是單節點（單 GPU 或多 GPU）或分佈在幾個運算節點上的中小型企業。該解決方案與許多企業的大多數日常 AI 培訓工作一致。</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">本文檔涵蓋由八 GPU 聯想 SR670V2 伺服器、中階NetApp AFF A400儲存系統和 100GbE 互連交換器組成的運算和儲存配置的測試和驗證。為了衡量效能，我們使用了 ResNet50 和 ImageNet 資料集、批次大小為 408、半精度、CUDA 和 cuDNN。該架構為剛開始 AI 計劃且需要NetApp ONTAP雲端連接資料儲存的企業級功能的中小型組織提供了高效且經濟的解決方案。</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">資料科學家、資料工程師、資料管理員和人工智慧系統開發人員</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">為 AI 模型開發設計解決方案的企業架構師</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">尋求有效方法實現深度學習 (DL) 和機器學習 (ML) 開發目標的資料科學家和資料工程師</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">希望盡快實現 AI 計畫上市的企業領導者和 OT/IT 決策者</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">此解決方案採用聯想 ThinkSystem 伺服器和具有AFF儲存的NetApp ONTAP，旨在利用 GPU 和傳統 CPU 的處理能力來處理大型資料集的 AI 訓練。此驗證展示了採用橫向擴展架構的高效能和最佳資料管理，該架構使用一台、兩台或四台 Lenovo SR670 V2 伺服器以及一台NetApp AFF A400儲存系統。下圖提供了架構概覽。</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">該圖描繪了一個乙太網路交換機，周圍是管理伺服器、四個 SR670 V2（每個有八個 GPU）和一個NetApp ONTAP儲存系統。</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">並行執行多個訓練作業時具有高效且經濟的性能</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">根據不同數量的聯想伺服器和不同型號的NetApp儲存控制器擴充效能</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">強大的資料保護，滿足低復原點目標 (RPO) 和復原時間目標 (RTO)，且不會遺失資料</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">透過快照和克隆優化資料管理，簡化開發工作流程</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">在本次驗證中，我們依照 MLPerf v2.0 的規定執行了影像辨識訓練。具體來說，我們使用 ImageNet 資料集訓練了 ResNet v2.0 模型。主要指標是達到所需精度的時間。我們也報告了每秒影像數的訓練頻寬，以便更好地判斷擴展效率。</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">在本次驗證中，我們依照 MLPerf v2.0 的規定進行了影像辨識訓練。具體來說，我們使用 ImageNet 資料集訓練 ResNet v2.0 模型，直到達到 76.1% 的準確率。主要指標是達到所需精度的時間。我們也報告了每秒影像數的訓練頻寬，以便更好地判斷擴展效率。</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">主要測試案例評估同時運行的多個獨立訓練過程（每個節點一個）。這模擬了主要用例，即多個資料科學家使用的共享系統。第二個測試案例評估了橫向擴展效率。</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">本節總結了此解決方案的測試結果。</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">下表總結了針對該解決方案執行的所有測試的結果。</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">測試描述</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">結果摘要</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">圖像辨識訓練：多個並發作業</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">高效的性能。即使叢集已充分利用，所有作業仍能全速運作。  NetApp儲存系統提供了與本地 SSD 儲存相當的訓練效能，同時支援伺服器之間輕鬆共享資料。</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">影像辨識訓練：橫向擴展</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">最多四個節點的效率很高。此時，橫向擴展的效率較低，但仍可行。使用更高速的運算網路可以提高可擴展性。  NetApp儲存系統提供了與本地 SSD 儲存相當的訓練效能，同時支援伺服器之間輕鬆共享資料。</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">本節更詳細地介紹此解決方案的主要組件。</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">NetApp AFF儲存系統使企業能夠透過業界領先的效能、卓越的靈活性、雲端整合和一流的資料管理來滿足企業儲存需求。  AFF系統專為快閃記憶體設計，有助於加速、管理和保護關鍵業務資料。</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">該圖展示了NetApp AFF A400儲存控制器的正面。</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">該圖描繪了NetApp AFF A400儲存控制器的背面。</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400是一款中階 NVMe 快閃儲存系統，具備以下功能：</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">最大有效容量：~20PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">最大橫向擴展：2-24 個節點（12 個 HA 對）</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">25GbE 和 16Gb FC 主機支持</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">透過融合乙太網路 (RoCE) 的 100GbE RDMA 連接到 NVMe 擴充儲存架</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">如果未連接 NVMe 機架，則可使用 100GbE RoCE 連接埠進行主機網路連接</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">全12Gbps SAS連接擴充儲存架</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">有兩種配置可供選擇：</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">乙太網路：4個25Gb乙太網路（SFP28）端口</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">光纖通道：4x 16Gb FC（SFP+）端口</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% 8KB 隨機讀取 @.4 毫秒 400k IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">NetApp AFF A250適用於入門級 AI/ML 部署的功能包括：</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">最大有效容量：35PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">最大橫向擴展：2-24 個節點（12 個 HA 對）</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">基於最新的NetApp ONTAP版本ONTAP 9.8 或更高版本</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">兩個 25Gb 乙太網路端口，用於 HA 和群集互連</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp還提供其他儲存系統，例如AFF A800和AFF A700 ，它們為更大規模的 AI/ML 部署提供更高的效能和可擴充性。</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">ONTAP 9 是NetApp最新一代儲存管理軟體，它支援企業實現基礎架構現代化並過渡到雲端就緒資料中心。 ONTAP利用業界領先的數據管理功能，只需一套工具即可管理和保護數據，無論數據位於何處。資料還可以自由移動到任何需要的地方：邊緣、核心或雲端。  ONTAP 9 包含許多功能，可簡化資料管理、加速和保護關鍵資料以及跨混合雲架構的未來基礎架構。</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*最小、最大和自適應服務品質 (QoS)。 *細粒度的 QoS 控制有助於在高度共享的環境中維持關鍵應用程式的效能水準。</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool.*此功能可自動將冷資料分層到公有和私有雲端儲存選項，包括 Amazon Web Services (AWS)、Azure 和NetApp StorageGRID物件儲存。</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*性能和更低的延遲。 *  ONTAP以盡可能低的延遲提供盡可能高的吞吐量。</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp磁碟區加密。 *  ONTAP提供原生磁碟區級加密，並支援板載和外部金鑰管理。</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 有助於滿足嚴苛且不斷變化的業務需求：</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*無縫擴展和無中斷運行。 * ONTAP支援無中斷地向現有控制器以及橫向擴展叢集添加容量。客戶可以升級到最新技術，例如 NVMe 和 32Gb FC，而無需昂貴的資料遷移或中斷。</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*與新興應用程式整合。 *  ONTAP使用支援現有企業應用程式的相同基礎架構，為下一代平台和應用程式（如 OpenStack、Hadoop 和 MongoDB）提供企業級資料服務。</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">NetApp FlexGroup卷</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">訓練資料集通常是數十億個文件的集合。文件可以包括文字、音訊、視訊和其他形式的非結構化數據，這些數據必須儲存和處理才能並行讀取。儲存系統必須儲存許多小文件，並且必須並行讀取這些文件以實現順序和隨機 I/O。</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">FlexGroup磁碟區（下圖）是由多個組成成員磁碟區組成的單一命名空間，對儲存管理員而言，該磁碟區的管理方式和NetApp FlexVol volume類似。 FlexGroup卷中的檔案被指派給各個成員卷，並且不會跨卷或節點進行條帶化。它們支援以下功能：</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">高達 20 PB 的容量和可預測的低延遲，適用於高元資料工作負載</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">同一命名空間內最多可容納 4000 億個文件</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">跨 CPU、節點、聚合體和組成FlexVol磁碟區的 NAS 工作負載的平行操作</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">該圖描繪了一對 HA 儲存控制器，其中包含FlexGroup內具有主檔案的多個磁碟區。</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">聯想 ThinkSystem 產品組合</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">部署聯想 ThinkSystem 伺服器的主要優勢包括：</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">高度可擴展的模組化設計，可隨著您的業務成長而成長</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">在人工智慧領域，聯想正在採取切實可行的方法來幫助企業了解並採用機器學習和人工智慧為其工作負載帶來的好處。聯想客戶可以在聯想人工智慧創新中心探索和評估聯想人工智慧產品，以充分了解其特定用例的價值。為了縮短價值實現時間，這種以客戶為中心的方法為客戶提供了可立即使用且針對 AI 進行最佳化的解決方案開發平台的概念驗證。</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">聯想SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Lenovo ThinkSystem SR670 V2 機架式伺服器為加速 AI 和高效能運算 (HPC) 提供最佳效能。  SR670 V2 支援多達八個 GPU，適合 ML、DL 和推理的計算密集型工作負載要求。</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">此圖描繪了三種 SR670 配置。第一個顯示四個 SXM GPU，有八個 2.5 吋 HS 硬碟和 2 個 PCIe I/O 插槽。第二個顯示四個雙寬或八個單寬 GPU 插槽和兩個 PCIe I/O 插槽，帶有八個 2.5 吋或四個 3.5 吋 HS 硬碟。第三個顯示八個雙寬 GPU 插槽，其中有六個 EDSFF HS 驅動器和兩個 PCIe I/O 插槽。</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">ThinkSystem SR670 V2 配備支援高階 GPU（包括NVIDIA A100 80GB PCIe 8x GPU）的最新可擴充 Intel Xeon CPU，可為 AI 和 HPC 工作負載提供最佳化、加速的效能。</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">由於越來越多的工作負載需要使用加速器的效能，因此對 GPU 密度的需求也隨之增加。零售、金融服務、能源和醫療保健等行業正在使用 GPU 來獲取更深入的見解，並透過 ML、DL 和推理技術推動創新。</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2 是一款最佳化的企業級解決方案，用於在生產中部署加速的 HPC 和 AI 工作負載，最大限度地提高系統效能，同時保持下一代平台超級運算叢集的資料中心密度。</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">其他功能包括：</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">支援 GPU 直接 RDMA I/O，其中高速網路適配器直接連接到 GPU，以最大化 I/O 效能。</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">支援 GPU 直接存儲，其中 NVMe 驅動器直接連接到 GPU，以最大限度地提高儲存效能。</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf 是業界領先的評估 AI 效能的基準套件。在本次驗證中，我們將其影像分類基準與最受歡迎的 AI 框架之一 MXNet 一起使用。使用MXNet_benchmarks訓練腳本來驅動AI訓練。該腳本包含幾種流行的常規模型的實現，並且旨在盡可能快。它可以在單一機器上運行，也可以在多台主機上以分散式模式運行。</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">本文介紹了NetApp AIPod for Enterprise RAG 的經過驗證的參考設計，該設計採用了 Intel Xeon 6 處理器和NetApp資料管理解決方案的技術和組合功能。該解決方案演示了下游 ChatQnA 應用程式利用大型語言模型，為並髮用戶提供準確、上下文相關的回應。這些回應是透過隔離的 RAG 推理管道從組織的內部知識庫中檢索的。</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini - 利用NetApp和 Intel 進行企業 RAG 推理</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">英特爾標誌</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c6562cf6ae61e882bf5b2ce4cfcba9d" category="paragraph">Sathish Thyagarajan、Michael Oglesby、 NetApp</block>
  <block id="609170132b6430c9060811e3315d482b" category="paragraph">越來越多的組織正在利用檢索增強生成 (RAG) 應用程式和大型語言模型 (LLM) 來解釋使用者提示並產生回應，以提高生產力和商業價值。這些提示和回應可以包括從組織內部知識庫、資料湖、程式碼儲存庫和文件儲存庫檢索到的文字、程式碼、圖像，甚至治療蛋白質結構。本文介紹了NetApp AIPod Mini 解決方案的參考設計，包括NetApp AFF儲存和搭載 Intel Xeon 6 處理器的伺服器。它包括與英特爾高級矩陣擴展 (Intel AMX) 結合的NetApp ONTAP資料管理軟體，以及基於企業 AI 開放平台 (OPEA) 構建的英特爾企業檢索增強生成 (RAG) 軟體。適用於企業 RAG 的NetApp AIPod Mini 使組織能夠將公用 LLM 增強為私有生成式 AI (GenAI) 推理解決方案。此解決方案展示了企業規模的高效且經濟的 RAG 推理，旨在提高可靠性並讓您更好地控制您的專有資訊。</block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">英特爾儲存合作夥伴驗證</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">搭載英特爾至強 6 處理器的伺服器專為處理要求苛刻的 AI 推理工作負載而設計，並使用英特爾 AMX 實現最佳效能。為了實現最佳的儲存效能和可擴展性，該解決方案已使用NetApp ONTAP成功驗證，使企業能夠滿足 RAG 應用程式的需求。該驗證是在配備 Intel Xeon 6 處理器的伺服器上進行的。英特爾和NetApp建立了強大的合作夥伴關係，致力於提供最佳化、可擴展且符合客戶業務需求的 AI 解決方案。</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">使用NetApp運行 RAG 系統的優勢</block>
  <block id="320696921fb4cab1e55c519f97302d91" category="paragraph">RAG 應用程式涉及從公司各種類型的文件儲存庫中檢索知識，例如 PDF、文字、CSV、Excel 或知識圖。這些資料通常儲存在諸如 S3 物件儲存或 NFS 本地解決方案中作為資料來源。  NetApp一直是邊緣、資料中心和雲端生態系統中資料管理、資料移動性、資料治理和資料安全技術的領導者。  NetApp ONTAP資料管理提供企業級存儲，以支援各種類型的 AI 工作負載，包括批次和即時推理，並提供以下一些優勢：</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">速度和可擴展性。您可以高速處理大型資料集以進行版本控制，並能夠獨立擴展效能和容量。</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">數據存取。多協定支援允許客戶端應用程式使用 S3、NFS 和 SMB 檔案共用協定讀取資料。  ONTAP S3 NAS 儲存桶可以促進多模式 LLM 推理場景中的資料存取。</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">可靠性和保密性。  ONTAP提供資料保護、內建NetApp自主勒索軟體保護 (ARP) 和動態儲存配置，並提供基於軟體和硬體的加密以增強機密性和安全性。  ONTAP 的所有 SSL 連線均符合 FIPS 140-2 標準。</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">本文檔適用於希望利用為提供企業 RAG 和 GenAI 解決方案而建構的基礎設施的 AI 決策者、資料工程師、業務領導者和部門主管。對 AI 推理、LLM、Kubernetes 以及網路及其元件的先前了解將有助於實施階段。</block>
  <block id="63b41ad25402b4d0e25695e062bb14ad" category="section-title">英特爾人工智慧技術</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">Xeon 6處理器</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">使用 Xeon 6 作為主機 CPU，加速系統可受益於高單執行緒效能；更高的記憶體頻寬；更高的可靠性、可用性和可服務性 (RAS)；以及更多的 I/O 通道。英特爾 AMX 加速了 INT8 和 BF16 的推理，並支援 FP16 訓練模型，INT8 每核每週期最多可進行 2,048 次浮點運算，BF16/FP16 每核每週期最多可進行 1,024 次浮點運算。要使用 Xeon 6 處理器部署 RAG 解決方案，通常建議至少使用 250GB 的 RAM 和 500GB 的磁碟空間。然而，這在很大程度上取決於 LLM 模型的大小。欲了解更多信息，請參閱英特爾<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block>產品簡介。</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300,300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">圖 1 - 搭載 Intel Xeon 6 處理器的運算伺服器<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">NetApp AFF存儲</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">入門級和中級NetApp AFF A 系列系統提供更強大的效能、密度和更高的效率。  NetApp AFF A20、 AFF A30 和AFF A50 系統提供真正的統一存儲，支援區塊、檔案和對象，基於單一作業系統，可以以最低的成本在混合雲中無縫管理、保護和調動 RAG 應用程式的資料。</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">圖 2 - NetApp AFF A 系列系統。<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*硬體*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*數量*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*評論*</block>
  <block id="f0ef78c28754fd06e4d1d893f113852d" category="cell">基於 Intel Xeon 6 的伺服器</block>
  <block id="3e18c872662c63bcc37a4934b1161411" category="cell">RAG 推理節點 - 配備雙插槽 Intel Xeon 6900 系列或 Intel Xeon 6700 系列處理器以及 250GB 至 3TB RAM，配備 DDR5 (6400MHz) 或 MRDIMM (8800MHz)。  2U伺服器。</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">帶有英特爾處理器的控制平面伺服器</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">Kubernetes 控制平面/1U 伺服器。</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">100Gb 乙太網路交換器的選擇</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">資料中心交換器。</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20（或AFF A30； AFF A50）</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">最大儲存容量：9.3PB。注意：網路：10/25/100 GbE 連接埠。</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">為了驗證此參考設計，我們使用了 Supermicro 的 Intel Xeon 6 處理器伺服器（222HA-TN-OTO-37）和 Arista 的 100GbE 交換器（7280R3A）。</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">企業AI開放平台</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">企業 AI 開放平台 (OPEA) 是由英特爾與生態系統合作夥伴共同主導的開源計畫。它提供了一個可組合構建塊的模組化平台，旨在加速尖端生成 AI 系統的開發，並專注於 RAG。  OPEA 包括一個綜合框架，該框架具有 LLM、資料儲存、提示引擎、RAG 架構藍圖以及基於效能、特性、可信度和企業準備度評估生成式 AI 系統的四步驟評估方法。</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">OPEA 的核心包括兩個關鍵部分：</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps：由微服務元件組成的基於服務的工具包</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">GenAIExamples：可立即部署的解決方案，例如 ChatQnA，可展示實際用例</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">OPEA專案文檔</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">有關詳細信息，請參閱<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="515b4067e1d91f462d68de8996b254f6" category="section-title">由 OPEA 提供支援的英特爾企業人工智慧推理</block>
  <block id="36a128563cdcf54e3a3e0bfe9a0952a5" category="paragraph">適用於英特爾企業人工智慧 RAG 的 OPEA 簡化了將企業資料轉化為可操作見解的過程。它由英特爾至強處理器提供支持，整合了來自行業合作夥伴的組件，為部署企業解決方案提供了簡化的方法。它可以與成熟的編排框架無縫擴展，提供企業所需的靈活性和選擇。</block>
  <block id="9cc188487c3944246ae7f6c5402d3c53" category="paragraph">在 OPEA 的基礎上，英特爾企業人工智慧 RAG 透過增強可擴展性、安全性和使用者體驗的關鍵功能擴展了這一基礎。這些功能包括與現代基於服務的架構無縫整合的服務網格功能、用於管道可靠性的生產就緒驗證以及用於 RAG 即服務的功能豐富的 UI，從而可以輕鬆管理和監控工作流程。此外，英特爾和合作夥伴的支援提供了廣泛的解決方案生態系統，結合整合的身份和存取管理 (IAM) 與 UI 和應用程序，實現安全且合規的操作。可程式護欄對管道行為提供細粒度的控制，實現客製化的安全性和合規性設定。</block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">了解ONTAP S3 配置</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">NetApp ONTAP是 NetApp 關鍵資料儲存解決方案的基礎技術。 ONTAP包含各種資料管理和資料保護功能，例如針對網路攻擊的自動勒索軟體保護、內建資料傳輸功能和儲存效率功能。這些優勢適用於一系列架構，從本地到 NAS、SAN、物件和 LLM 部署的軟體定義儲存中的混合多雲。您可以在ONTAP叢集中使用ONTAP S3 物件儲存伺服器來部署 RAG 應用程序，從而利用透過授權使用者和客戶端應用程式提供的ONTAP的儲存效率和安全性。有關詳細信息，請參閱<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">Git 上的NetApp Trident</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">NetApp Trident軟體是一款開源且完全支援的儲存編排器，適用於容器和 Kubernetes 發行版，包括 Red Hat OpenShift。 Trident可與整個NetApp儲存產品組合搭配使用，包括NetApp ONTAP ，並且還支援 NFS 和 iSCSI 連線。有關詳細信息，請參閱<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*軟體*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*版本*</block>
  <block id="b968b232dc718c194c40c140b496647a" category="cell">企業 RAG 的英特爾 AI 的 OPEA</block>
  <block id="522c33efdda0b8dc6ce90c991beb9666" category="cell">1.1.2</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">基於OPEA微服務的企業RAG平台</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">容器儲存介面（CSI驅動程式）</block>
  <block id="a821a7b77c7f65a585f8b5e2b6679cd3" category="cell">NetApp Trident 25.02</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">支援動態配置、 NetApp Snapshot 副本和磁碟區。</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d63705a0c12ee1eea0e9fa2f30be636d" category="cell">雙節點叢集上的作業系統</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">容器編排</block>
  <block id="307ea69c7c6931f75ee51c5349fefb05" category="cell">Kubernetes 1.31.4</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">運行 RAG 框架的環境</block>
  <block id="6f72c11338419e7cbef5d90da27338b1" category="cell">ONTAP 9.16.1P4</block>
  <block id="345ec8aa297f872cecdbf6b3c0e32bfd" category="cell">AFF A20 上的儲存作業系統。它具有 Vscan 和 ARP 功能。</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">解決方案部署</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">軟體堆疊</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">此解決方案部署在由基於 Intel Xeon 的應用節點組成的 Kubernetes 叢集上。至少需要三個節點才能實現 Kubernetes 控制平面的基本高可用性。我們使用以下叢集佈局驗證了該解決方案。</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">表 3 - Kubernetes 叢集佈局</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">節點</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">角色</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">配備 Intel Xeon 6 處理器和 1TB RAM 的伺服器</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">應用節點、控制平面節點</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">通用伺服器</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">控制平面節點</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600,600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">下圖描述了該解決方案的「軟體堆疊視圖」。<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">部署步驟</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">部署ONTAP儲存設備</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">ONTAP硬體系統文檔</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">部署並設定您的NetApp ONTAP儲存設備。請參閱<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block>了解詳情。</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">配置ONTAP SVM 以進行 NFS 和 S3 訪問</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">在 Kubernetes 節點可存取的網路上設定ONTAP儲存虛擬機器 (SVM) 以進行 NFS 和 S3 存取。</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">ONTAP文檔。</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">若要使用ONTAP系統管理員建立 SVM，請導覽至“儲存”&gt;“儲存虛擬機器”，然後按一下“+ 新增”按鈕。為您的 SVM 啟用 S3 存取權時，請選擇使用外部 CA（憑證授權單位）簽署的證書，而不是系統產生的憑證。您可以使用自簽名憑證或由公眾信任的 CA 簽署的憑證。有關更多詳細信息，請參閱<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">以下螢幕截圖展示了使用ONTAP系統管理員建立 SVM 的過程。根據您的環境根據需要修改詳細資訊。</block>
  <block id="ba045795e96e030beb3430fdc0bcf388" category="paragraph">圖 4 — 使用ONTAP系統管理員建立 SVM。<block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">配置 S3 權限</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">為您在上一個步驟中建立的 SVM 配置 S3 使用者/群組設定。確保您擁有對該 SVM 的所有 S3 API 操作具有完全存取權限的使用者。有關詳細信息，請參閱ONTAP S3 文件。</block>
  <block id="8182eb49f0464e8a5b6d2e7b642a6da5" category="paragraph">注意：Intel AI for Enterprise RAG 應用程式的資料擷取服務需要此使用者。如果您使用ONTAP系統管理員建立了 SVM，系統管理員將自動建立一個名為<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>以及一個名為<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block>當您建立 SVM 時，但尚未指派任何權限<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>。</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">若要編輯此使用者的權限，請導航至“儲存”&gt;“儲存虛擬機器”，按一下您在上一個步驟中建立的 SVM 的名稱，按一下“設定”，然後按一下“S3”旁的鉛筆圖示。給予<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>擁有所有 S3 API 操作的完全存取權限，建立一個關聯<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>與<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block>策略如下面的螢幕截圖所示。</block>
  <block id="229c665cb2b8cb2576229fea9470bfe6" category="paragraph">圖 5 - S3 權限。</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">建立 S3 儲存桶</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">在您先前建立的 SVM 內建立一個 S3 儲存桶。若要使用ONTAP系統管理員建立 SVM，請導航至“儲存”&gt;“儲存桶”，然後按一下“+ 新增”按鈕。有關更多詳細信息，請參閱ONTAP S3 文件。</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">以下螢幕截圖展示了使用ONTAP系統管理員建立 S3 儲存桶的過程。</block>
  <block id="9568e70889a07b151a91a53d10969aed" category="paragraph">圖 6 - 建立 S3 儲存桶。<block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">配置 S3 儲存桶權限</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">為您在上一個步驟中建立的 S3 儲存桶配置權限。確保您在上一個步驟中配置的使用者俱有以下權限：<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">ONTAP S3 文檔</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">若要使用ONTAP系統管理員編輯 S3 儲存桶權限，請導覽至“儲存體”&gt;“儲存桶”，按一下儲存桶的名稱，按一下“權限”，然後按一下“編輯”。請參閱<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block>了解更多詳細資訊。</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">以下螢幕截圖展示了ONTAP系統管理員中必要的儲存桶權限。</block>
  <block id="54bf7776c2d0b7f0ee45097aaad50403" category="paragraph">圖 7 - S3 儲存桶權限。<block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">建立 bucket 跨域資源共享規則</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">使用ONTAP CLI，為您在上一個步驟中建立的儲存桶建立儲存桶跨域資源共用 (CORS) 規則：</block>
  <block id="51704d982c17dad72393ced89212b5ca" category="paragraph">此規則允許英特爾 AI for Enterprise RAG Web 應用程式的 OPEA 從 Web 瀏覽器內與儲存桶進行互動。</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">部署伺服器</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">部署您的伺服器並在每台伺服器上安裝 Ubuntu 22.04 LTS。安裝 Ubuntu 後，在每台伺服器上安裝 NFS 實用程式。若要安裝 NFS 實用程序，請執行以下命令：</block>
  <block id="5ed0c66dfa2ac395ad8e9830aa5964aa" category="section-title">安裝 Kubernetes</block>
  <block id="7a21958624d0a70f3a6b70bcf03ba09a" category="inline-link">Kubespray 文件</block>
  <block id="eb6273ed753aae187941e09aa142f02a" category="paragraph">使用 Kubespray 在您的伺服器上安裝 Kubernetes。請參閱<block ref="1d9598782a4be0d8f1003429c1865811" category="inline-link-rx"></block>了解詳情。</block>
  <block id="b0583213f3e2e379b7dd549fd41f909f" category="section-title">安裝Trident CSI 驅動程式</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Trident安裝文檔</block>
  <block id="1ba254856621ddad1eb72d0beee0001c" category="paragraph">在您的 Kubernetes 叢集中安裝NetApp Trident CSI 驅動程式。請參閱<block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block>了解詳情。</block>
  <block id="cca56b6e3954004aac402213ce3054e6" category="section-title">建立Trident後端</block>
  <block id="f95ebb45354495c835f81296b11e95c1" category="inline-link">Trident後端文檔</block>
  <block id="31f53fbd09b24f455b372567da98766f" category="paragraph">為您先前建立的 SVM 建立Trident後端。建立後端時，使用<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>司機。請參閱<block ref="4b8fa33525637fa26acc3e336d80affb" category="inline-link-rx"></block>了解詳情。</block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">建立儲存類別</block>
  <block id="bdecb047bffb568e0e8e84eeca503f89" category="paragraph">建立與您在上一個步驟中建立的Trident後端相對應的 Kubernetes 儲存類別。有關詳細信息，請參閱Trident存儲類文檔。</block>
  <block id="6a61b11e836f0eeccddb33643f7aa4cd" category="inline-link">英特爾 AI 企業版 RAG 部署</block>
  <block id="ba489bb61012c1097c380a06f7b20cbe" category="paragraph">在您的 Kubernetes 叢集中安裝適用於 Intel AI for Enterprise RAG 的 OPEA。請參閱<block ref="d6f70ce0ce5c9ddf0b1e28a93f0968a7" category="inline-link-rx"></block>文件以了解詳細資訊。請務必記下本文後面所述的所需的設定檔修改。您必須在執行安裝手冊之前進行這些修改，以便 Intel AI for Enterprise RAG 應用程式能夠與您的ONTAP儲存系統正確搭配使用。</block>
  <block id="cd806c912d9a85a913016682326e17bc" category="section-title">啟用ONTAP S3</block>
  <block id="4a65f719a33b2a0cdefdd371bc5b4aa9" category="paragraph">為 Intel AI for Enterprise RAG 安裝 OPEA 時，編輯主設定檔以允許使用ONTAP S3 作為來源資料儲存庫。</block>
  <block id="3bbecd0884a5e013f45ca28fdee8daf4" category="paragraph">要啟用ONTAP S3，請在<block ref="ed9bdb883dd5d0bf37bd5d208a17fadc" prefix=" " category="inline-code"></block>部分。</block>
  <block id="799685b83814ceb35225cd15c9221159" category="paragraph">注意：預設情況下，Intel AI for Enterprise RAG 應用程式會從 SVM 中所有現有儲存桶中擷取資料。如果您的 SVM 中有多個儲存桶，則可以修改<block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block>字段，以便僅從某些儲存桶中提取資料。</block>
  <block id="533e38d744354d370be3e86bd8fe8b28" category="section-title">配置計劃同步設定</block>
  <block id="ad99b73b01de134452a17a0dfa32cec2" category="paragraph">安裝英特爾企業人工智慧 RAG 應用程式的 OPEA 時，啟用<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>以便應用程式自動從您的 S3 儲存桶中提取新的或更新的檔案。</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">什麼時候<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>啟用後，應用程式會自動檢查來源 S3 儲存桶中是否有新檔案或更新的檔案。在此同步過程中發現的任何新檔案或更新檔案都會自動提取並新增至 RAG 知識庫。應用程式根據預設的時間間隔檢查您的來源儲存桶。預設時間間隔為 60 秒，這表示應用程式每 60 秒檢查一次變更。您可能希望更改此間隔以滿足您的特定需求。</block>
  <block id="6d6914305f62085b3a9f416c96b4d127" category="paragraph">啟用<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>並設定同步間隔，在<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="b9edd7aa680f588a01b814c4969d387b" category="section-title">變更卷宗訪問模式</block>
  <block id="2fe889d552298c286373b708cafda8e7" category="paragraph">在<block ref="cd37fd54d9ac25bbfe45a164824d6194" prefix=" " category="inline-code"></block>，對於每個卷<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block>列表，更改<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>到<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block>。</block>
  <block id="edad21c5950d7e773534103192f18dd8" category="section-title">（可選）停用 SSL 憑證驗證</block>
  <block id="6aaadab147a2227d76985e7ef0fc2680" category="paragraph">如果您在為 SVM 啟用 S3 存取權時使用了自簽章證書，則必須停用 SSL 憑證驗證。如果您使用由公眾信任的 CA 簽署的證書，則可以跳過此步驟。</block>
  <block id="2bb2c1d3d614a1de0e2e1e97fe3ac3c1" category="paragraph">若要停用 SSL 憑證驗證，請在<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="dd88285a7105f2f3e6756070ae0535e2" category="section-title">訪問適用於企業 RAG UI 的英特爾 AI 的 OPEA</block>
  <block id="123b51539e81bc36af05f29733939680" category="inline-link">英特爾企業人工智慧 RAG 部署文檔</block>
  <block id="c1b501f6d4c8c6a8616b9ca35cd2fc45" category="paragraph">訪問英特爾企業人工智慧 RAG UI 的 OPEA。請參閱<block ref="746fad554462625e79393992880c7bc6" category="inline-link-rx"></block>了解詳情。</block>
  <block id="922ca547bcfcab30994177a3c1d383ae" category="paragraph">圖 8 - 適用於企業 RAG UI 的英特爾 AI 的 OPEA。<block ref="4cedb9bc094b7a9f8925870620118f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">為 RAG 提取數據</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">現在您可以提取文件以包含在基於 RAG 的查詢擴充中。有多種提取檔案的選項。根據您的需求選擇適當的選項。</block>
  <block id="36dc767aab6b2ad698f45815826a1a29" category="paragraph">注意：提取檔案後，英特爾 AI for Enterprise RAG 應用程式的 OPEA 會自動檢查檔案的更新並相應地提取更新。</block>
  <block id="39ba5d380c5ff87759539eee68e65d99" category="paragraph">*選項 1：直接上傳到您的 S3 儲存桶 要一次提取多個文件，我們建議使用您選擇的 S3 用戶端將文件上傳到您的 S3 儲存桶（您之前建立的儲存桶）。受歡迎的 S3 用戶端包括 AWS CLI、Amazon SDK for Python（Boto3）、s3cmd、S3 瀏覽器、Cyberduck 和 Commander One。如果檔案屬於受支援的類型，則您上傳至 S3 儲存桶的任何檔案將由英特爾 AI for Enterprise RAG 應用程式的 OPEA 自動擷取。</block>
  <block id="e8c9e1c06420b69e589d260def731d88" category="paragraph">注意：在撰寫本文時，支援以下文件類型：PDF、HTML、TXT、DOC、DOCX、PPT、PPTX、MD、XML、JSON、JSONL、YAML、XLS、XLSX、CSV、TIFF、JPG、JPEG、PNG 和 SVG。</block>
  <block id="bc974fb6199b9073fbf1026bd2d236d2" category="paragraph">您可以使用 OPEA for Intel AI for Enterprise RAG UI 來確認您的檔案是否已正確擷取。有關詳細信息，請參閱英特爾 AI for Enterprise RAG UI 文件。請注意，應用程式可能需要一些時間來提取大量文件。</block>
  <block id="25ce0ebd12d3573d98440a5151efd06e" category="paragraph">*選項 2：使用 UI 上傳 如果您只需要提取少量文件，則可以使用 OPEA for Intel AI for Enterprise RAG UI 來提取它們。有關詳細信息，請參閱英特爾 AI for Enterprise RAG UI 文件。</block>
  <block id="aad57997fffb9169edca9049f6c408fc" category="paragraph">圖 9-資料提取 UI。<block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">執行聊天查詢</block>
  <block id="37afbf2924fcb8ec313cd060eae9317c" category="paragraph">現在您可以使用隨附的聊天 UI 與英特爾企業人工智慧 RAG 應用程式的 OPEA「聊天」。在回應您的查詢時，應用程式會使用您提取的檔案執行 RAG。這意味著應用程式會自動在您攝取的文件中搜尋相關信息，並在回應您的查詢時合併這些資訊。</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">作為驗證工作的一部分，我們與英特爾合作進行了性能測試。此次測試得出了下表中列出的尺寸指導。</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">特徵</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">價值</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">模型尺寸</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">200億個參數</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">Llama-8B、Llama-13B、Mistral 7B、Qwen 14B、DeepSeek Distill 8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">輸入尺寸</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">約2000個代幣</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">約4頁</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">輸出尺寸</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">並髮用戶</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">「並髮用戶」是指同時提交查詢的提示請求。</block>
  <block id="e8d9bc5e8e6b28217a5661b56a0ce38d" category="paragraph">_注意：上面提供的尺寸指導是基於使用 96 核心 Intel Xeon 6 處理器收集的效能驗證和測試結果。對於具有類似 I/O 令牌和模型大小要求的客戶，我們建議使用具有 96 或 128 個核心的 Xeon 6 處理器的伺服器。</block>
  <block id="d83a33143fe76973b5528ae0d2b5750c" category="paragraph">企業 RAG 系統和 LLM 是協同工作的技術，可協助組織提供準確且情境感知的回應。這些回應涉及基於大量私人和內部企業資料的資訊檢索。透過使用 RAG、API、向量嵌入和高效能儲存系統來查詢包含公司資料的文件儲存庫，可以更快、更安全地處理資料。  NetApp AIPod Mini 將 NetApp 的智慧資料基礎架構與ONTAP資料管理功能以及 Intel Xeon 6 處理器、Intel AI for Enterprise RAG 和 OPEA 軟體堆疊結合，協助部署高效能 RAG 應用程式並讓組織走上 AI 領導之路。</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">致謝</block>
  <block id="9d17f4dbd111838ecf2ecb0306f6c255" category="paragraph">本文檔由NetApp解決方案工程團隊成員 Sathish Thyagarajan 和 Michael Ogelsby 撰寫。作者也要感謝英特爾企業 AI 產品團隊（Ajay Mungara、Mikolaj Zyczynski、Igor Konopko、Ramakrishna Karamsetty、Michal Prostko、Shreejan Mistry 和 Ned Fiori）以及NetApp的其他團隊成員（Lawrence Bunka、Bobby Oommen 和 Jeff Liborio）在驗證此解決方案期間給予的持續支持和幫助。</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">物料清單</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">以下是用於此解決方案功能驗證的BOM，可供參考。可以使用符合以下配置的任何伺服器或網路元件（甚至是最好具有 100GbE 頻寬的現有網路）。</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">對於應用程式伺服器：</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*零件編號*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*產品描述*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">超級伺服器 SYS-222HA-TN /2U</block>
  <block id="f6c89f7ba30cbd887804a4308bd66add" category="cell">P4X-GNR6972P-SRPL2-UCC</block>
  <block id="68a721cd66b4e182958e8b3ba088ae78" category="cell">英特爾至強 6972P 2P 128C 2G 504M 500W SGX512</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">記憶體</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">MEM-DR564MC-ER64(x16)64GB DDR5-6400 2RX4 (16Gb) ECC RDIMM</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960GB 1DWPD TLC D，80 毫米</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">WS-1K63A-1R(x2)1U 692W/1600W 冗餘單輸出電源。散熱量為 2361 BTU/Hr，最高溫度為 59 C（約）</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">對於控制伺服器：</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">優化了 1U X13SCH-SYS、CSE-813MF2TS-R0RCNBP、PWS-602A-1R</block>
  <block id="3a3c852894f27ec7f0e61dfb46110539" category="cell">P4D-G7400-SRL66(x1) ADL 奔騰 G7400</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)16GB DDR5-4800 1Rx8 (16Gb) ECC UDIMM</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">對於網路交換器：</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">Arista 7280R3A 28x100 GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">NetApp AFF儲存：</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">AFF A20 HA 系統，-C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">跳線 Crd，駕駛室內，C13-C14，-C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">電源，1600W，鈦金，-C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-N-C</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">電纜，100GbE，QSFP28-QSFP28，銅，2米，-C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-N-C</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">電纜，25GbE，SFP28-SFP28，銅，0.5米，-C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-N-C</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">導軌，4 柱，薄，圓形/方孔，小，可調節，24-32，-C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-A-C</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">驅動器包 2X1.92TB，NVMe4，SED，-C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">IO 模組，2PT，100GbE，-C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">IO 模組，4PT，10/25GbE，-C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW、 ONTAP基礎套件、每 TB、快閃記憶體、A20、-C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="1006bcc3d9e9f1297760c57c62541267" category="paragraph"><block ref="1006bcc3d9e9f1297760c57c62541267" category="inline-link-rx"></block></block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">OPEA項目</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">OPEA Enterprise RAG 部署手冊</block>
  <block id="3d766654d6f2d85f314e655c63e91d81" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851：適用於自動駕駛工作負載的NetApp StorageGRID資料湖 - 解決方案設計</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">NetApp的 David Arnette</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 示範如何使用NetApp StorageGRID物件儲存作為機器學習 (ML) 和深度學習 (DL) 軟體開發的資料儲存庫和管理系統。本文介紹了自動駕駛汽車軟體開發中的資料流和要求以及簡化資料生命週期的StorageGRID功能。此解決方案適用於 ML 和 DL 開發過程中典型的任何多階段資料管道工作流程。</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">法律聲明</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">法律聲明提供對版權聲明、商標、專利等的存取。</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">版權</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">商標</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP、NETAPP 標誌和NetApp商標頁面上列出的標誌是NetApp, Inc. 的商標。其他公司和產品名稱可能是其各自所有者的商標。</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">專利</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">NetApp擁有的專利的最新清單可在以下位置找到：</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">隱私權政策</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">為了進行此驗證，我們使用一組原始影像對影像檢測用例進行了推理。然後，我們對同一組圖像執行相同的推理任務，並在推理之前添加了 Protopia 混淆。我們使用 Protopia 混淆組件的不同 ALPHA 值重複了這個任務。</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">推理精度比較</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">為了進行此驗證，我們使用一組原始影像對影像檢測用例進行了推理。然後，我們對同一組圖像執行相同的推理任務，並在推理之前添加了 Protopia 混淆。我們使用 Protopia 混淆組件的不同 ALPHA 值重複了這個任務。在 Protopia 混淆的背景下，ALPHA 值表示所應用的混淆量，ALPHA 值越高表示混淆等級越高。然後，我們比較了這些不同運行的推理準確性。</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">以下兩個表格提供了有關我們的用例的詳細資訊並概述了結果。</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia 直接與客戶合作，確定特定用例的適當 ALPHA 值。</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes（PyTorch）-</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDB資料集</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">原始托邦的混淆</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">阿爾法</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">準確性</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">不</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">不適用</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">是的</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">在哪裡可以找到更多資訊和致謝</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI—機密推理</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">NVIDIA Triton 推理伺服器</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton 推理伺服器文檔</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">PyTorch 中的 FaceBoxes</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">NetApp首席產品經理 Mark Cates</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad， NetApp技術行銷工程師</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Protopia AI 技術長兼教授 Hadi Esmaeilzadeh</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">數據有三種狀態 - 靜止、傳輸和計算。任何人工智慧推理服務的一個重要部分應該是在整個過程中保護資料免受威脅。在推理過程中保護資料至關重要，因為該流程可能會暴露有關外部客戶和提供推理服務的企業的私人資訊。</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">數據有三種狀態：靜止、傳輸、計算。任何人工智慧推理服務的一個重要部分應該是在整個過程中保護資料免受威脅。在推理過程中保護資料至關重要，因為該流程可能會暴露有關外部客戶和提供推理服務的企業的私人資訊。 Protopia AI 是當今市場上用於機密 AI 推理的非侵入式純軟體解決方案。借助 Protopia，AI 僅接收資料記錄中對於執行手頭上的 AI/ML 任務至關重要的轉換訊息，僅此而已。這種隨機變換不是一種掩蔽形式，而是基於透過使用精心策劃的雜訊以數學方式改變資料的表示。</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">具有ONTAP功能的NetApp儲存系統可提供與本地 SSD 儲存相同或更好的效能，並且與NetApp DataOps Toolkit 結合使用，可為資料科學家、資料工程師、AI/ML 開發人員以及業務或企業 IT 決策者帶來以下優勢：</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">針對災難復原、業務連續性和監管要求的企業級資料保護和資料治理。</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">簡化資料管理作業的呼叫；從 Jupyter 筆記本中的NetApp DataOps Toolkit 快速取得資料科學家工作區的 Snapshot 副本以進行備份和追溯。</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">NetApp和 Protopia 解決方案提供了靈活的橫向擴展架構，非常適合企業級 AI 推理部署。它可以實現資料保護並為敏感資訊提供隱私，其中機密的 AI 推理要求可以透過內部部署和混合雲端部署中的負責任的 AI 實踐來滿足。</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">本節概述了解決方案設計驗證環境。</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">下表概述了解決方案設計驗證環境。</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">NetApp Trident CSI 驅動程式</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">適用於 Kubernetes 的NetApp DataOps 工具包</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">本文檔描述了在三種不同場景下經過驗證的設計解決方案，包括有和沒有影像混淆的場景，這些場景與保護隱私和部署負責任的人工智慧解決方案有關。</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928：負責任的 AI 和機密推理 - NetApp AI 與 Protopia 影像和資料轉換</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan、Michael Oglesby、 NetApp Byung Hoon Ahn、Jennifer Cwagenberg、Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">隨著影像捕捉和影像處理技術的出現，視覺解讀已成為溝通不可或缺的一部分。數位影像處理中的人工智慧 (AI) 帶來了新的商業機會，例如在醫療領域用於癌症和其他疾病的識別、在地理空間視覺化分析中用於研究環境危害、在模式識別中、在視訊處理中用於打擊犯罪等等。然而，這一機會也伴隨著非凡的責任。</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">組織交給人工智慧的決策越多，他們承擔的與資料隱私和安全以及法律、道德和監管問題相關的風險就越大。負責任的人工智慧使公司和政府組織能夠建立信任和治理的實踐，這對於大型企業大規模應用人工智慧至關重要。本文檔介紹了NetApp在三種不同情境下驗證的 AI 推理解決方案，該解決方案使用NetApp資料管理技術與 Protopia 資料混淆軟體來私有化敏感資料並降低風險和道德問題。</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">消費者和商業實體每天都會使用各種數位設備產生數百萬張影像。隨之而來的數據和運算工作量的激增使得企業轉向雲端運算平台來實現規模和效率。同時，隨著影像資料轉移到公有雲，人們對其所含敏感資訊的隱私問題也產生了擔憂。缺乏安全和隱私保障成為影像處理人工智慧系統部署的主要障礙。</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">刪除權</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">隱私權法</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">此外，還有<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block>根據 GDPR，個人有權要求組織刪除其所有個人資料。還有<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>，該法案製定了公平資訊實踐準則。根據 GDPR，照片等數位影像可以構成個人數據，GDPR 規定了資料的收集、處理和刪除方式。不這樣做就是不遵守 GDPR，這可能會導致違反合規性的巨額罰款，這可能會對組織造成嚴重損害。隱私權原則是實施負責任的人工智慧的支柱之一，它確保機器學習 (ML) 和深度學習 (DL) 模型預測的公平性，並降低違反隱私或法規遵循相關的風險。</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">本文檔描述了在三種不同場景下經過驗證的設計解決方案，包括有和沒有影像混淆，這些場景與保護隱私和部署負責任的 AI 解決方案有關：</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">場景 1.  Jupyter 筆記本中的按需推理。</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">場景 2.在 Kubernetes 上進行批次推理。</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">場景 3.  NVIDIA Triton 推理伺服器。</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">對於該解決方案，我們使用人臉偵測資料集和基準（FDDB），這是一個為研究無約束人臉偵測問題而設計的人臉區域資料集，結合 PyTorch 機器學習框架來實現 FaceBoxes。此資料集包含 2845 張不同解析度影像中 5171 張臉的註釋。此外，本技術報告還介紹了從NetApp客戶和現場工程師收集的一些適用於此解決方案的解決方案領域和相關用例。</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">本技術報告面向以下受眾：</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">希望設計和部署負責任的人工智慧並解決公共場所臉部影像處理的資料保護和隱私問題的商業領袖和企業架構師。</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">旨在保護和維護隱私的資料科學家、資料工程師、人工智慧/機器學習 (ML) 研究人員以及人工智慧/機器學習系統開發人員。</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">為符合 GDPR、CCPA 或國防部 (DoD) 和政府組織的隱私法等監管標準的 AI/ML 模型和應用程式設計資料混淆解決方案的企業架構師。</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">資料科學家和人工智慧工程師正在尋找有效的方法來部署深度學習 (DL) 和 AI/ML/DL 推理模型來保護敏感資訊。</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">該解決方案旨在利用 GPU 和傳統 CPU 的處理能力來處理大型資料集上的即時和批量推理 AI 工作負載。此驗證證明了尋求負責任的 AI 部署的組織所需的 ML 隱私保護推理和最佳資料管理。該解決方案提供了適用於單節點或多節點 Kubernetes 平台的架構，用於邊緣和雲端運算，並透過 Jupyter Lab 和 CLI 介面與核心本地的NetApp ONTAP AI、 NetApp DataOps Toolkit 和 Protopia 混淆軟體互連。下圖顯示了由NetApp支援、採用 DataOps Toolkit 和 Protopia 的資料結構的邏輯架構概覽。</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Protopia 混淆軟體在NetApp DataOps Toolkit 上無縫運行，並在離開儲存伺服器之前轉換資料。</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">本節概述了此解決方案中驗證的三種場景。</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">測試和驗證計劃</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">對於此解決方案設計，驗證了以下三個場景：</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">在 JupyterLab 工作區內，使用NetApp DataOps Toolkit for Kubernetes 進行編排的推理任務（有和沒有 Protopia 混淆）。</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">在 Kubernetes 上執行批次推理作業（有和沒有 Protopia 混淆），其資料磁碟區是使用NetApp DataOps Toolkit for Kubernetes 進行編排的。</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">使用NVIDIA Triton 推理伺服器實例的推理任務，該實例是透過使用NetApp DataOps Toolkit for Kubernetes 進行編排的。在呼叫 Triton 推理 API 之前，我們對圖像應用了 Protopia 混淆，以模擬任何透過網路傳輸的資料都必須混淆的常見要求。此工作流程適用於在受信任區域內收集資料但必須傳遞到該受信任區域之外進行推理的用例。如果沒有 Protopia 混淆，就不可能在敏感資料不離開受信任區域的情況下實現這種類型的工作流程。</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">本節描述完成驗證所需的任務。</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">先決條件</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">要執行本節中概述的任務，您必須能夠存取安裝並配置了以下工具的 Linux 或 macOS 主機：</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl（設定用於存取現有的 Kubernetes 叢集）</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">可以找到安裝和設定說明<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>。</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">安裝說明可以找到<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>。</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">場景 1 – JupyterLab 中的按需推理</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">為 AI/ML 推理工作負載建立 Kubernetes 命名空間。</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">使用NetApp DataOps Toolkit 配置持久卷，用於儲存您將執行推理的資料。</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">使用NetApp DataOps Toolkit 建立新的 JupyterLab 工作區。使用上一步建立的持久性卷<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block>選項。根據需要NVIDIA<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block>選項。</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">在以下範例中，持久卷<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block>被掛載到 JupyterLab 工作區容器中<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block>。使用官方 Project Jupyter 容器鏡像時，<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block>在 JupyterLab Web 介面中顯示為頂級目錄。</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">使用輸出中指定的 URL 存取 JupyterLab 工作區<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block>命令。資料目錄代表掛載到工作區的持久卷。</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">打開<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block>目錄並上傳要執行推理的檔案。當檔案上傳到資料目錄時，它們會自動儲存在掛載到工作區的持久性磁碟區上。要上傳文件，請點擊上傳文件圖標，如下圖所示。</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">返回頂級目錄並建立一個新的筆記本。</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">將推理代碼加入筆記本中。以下範例顯示了影像檢測用例的推理程式碼。</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">將 Protopia 混淆加入到您的推理程式碼中。 Protopia 直接與客戶合作提供特定用例的文檔，這超出了本技術報告的範圍。以下範例展示了新增了 Protopia 混淆的影像偵測用例的推理程式碼。</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">場景 2 – Kubernetes 上的批次推理</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">使用您將執行推理的資料填入新的持久卷。</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOps Toolkit S3 Data Mover 功能</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">有幾種方法可以將資料載入到 PVC 上。如果您的資料目前儲存在與 S3 相容的物件儲存平台（例如NetApp StorageGRID或 Amazon S3）中，那麼您可以使用<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>。另一種簡單的方法是建立一個 JupyterLab 工作區，然後透過 JupyterLab Web 介面上傳文件，如“<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> “</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">為您的批次推理任務建立一個 Kubernetes 作業。以下範例展示了影像偵測用例的批次推理作業。此作業對一組影像中的每個影像執行推理，並將推理準確度指標寫入標準輸出。</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">確認推理作業已成功完成。</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">將 Protopia 混淆加入到您的推理工作中。您可以直接從 Protopia 找到有關新增 Protopia 混淆的用例特定說明，這超出了本技術報告的範圍。以下範例展示了針對人臉偵測用例的批量推理作業，其中新增了 Protopia 混淆，並使用 ALPHA 值 0.8。此作業在對一組影像中的每個影像執行推理之前應用 Protopia 混淆，然後將推理準確度指標寫入標準輸出。</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">推理準確度比較。</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">我們對 ALPHA 值 0.05、0.1、0.2、0.4、0.6、0.8、0.9 和 0.95 重複了此步驟。您可以在<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">場景 3 – NVIDIA Triton 推理伺服器</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">使用NetApp DataOps Toolkit 配置持久性卷，用作NVIDIA Triton 推理伺服器的模型儲存庫。</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">格式</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">將您的模型儲存在新的持久性卷中<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block>NVIDIA Triton 推理伺服器可以識別它。</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">有幾種方法可以將資料載入到 PVC 上。一個簡單的方法是建立一個 JupyterLab 工作區，然後透過 JupyterLab Web 介面上傳文件，如“<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> 。  “</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">使用NetApp DataOps Toolkit 部署新的NVIDIA Triton Inference Server 實例。</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">使用 Triton 客戶端 SDK 執行推理任務。以下 Python 程式碼摘錄使用 Triton Python 用戶端 SDK 執行人臉偵測用例的推理任務。此範例呼叫 Triton API 並傳入圖像進行推理。然後，Triton 推理伺服器接收請求，呼叫模型，並將推理輸出作為 API 結果的一部分傳回。</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">將 Protopia 混淆加入到您的推理程式碼中。您可以直接從 Protopia 找到有關新增 Protopia 混淆的特定用例說明；但是，此過程超出了本技術報告的範圍。以下範例顯示了與前面步驟 5 中所示的相同的 Python 程式碼，但添加了 Protopia 混淆。</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">請注意，在將影像傳遞給 Triton API 之前，會先進行 Protopia 混淆。因此，未混淆的影像永遠不會離開本機。只有經過混淆的圖像才會在網路上傳遞。此工作流程適用於在受信任區域內收集資料但隨後需要傳遞到該受信任區域之外進行推理的用例。如果沒有 Protopia 混淆技術，就不可能實現這種類型的工作流程，因為敏感資料永遠不會離開受信任的區域。</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">為了進行此驗證，我們將 Protopia 混淆應用於 1920 x 1080 像素影像五次，並測量每次完成混淆步驟所需的時間。</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">混淆速度</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">我們使用在單一NVIDIA V100 GPU 上運行的 PyTorch 來應用混淆，並在運行之間清除了 GPU 快取。在五次運行中，混淆步驟分別花費 5.47ms、5.27ms、4.54ms、5.24ms 和 4.84ms 完成。平均速度為5.072毫秒。</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">本節概述了完成此解決方案所需的各種技術組件。</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">普羅托邦</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI 為當今市場上的機密推理提供了一種不引人注目的純軟體解決方案。 Protopia 解決方案透過最大限度地減少敏感資訊的暴露，為推理服務提供了無與倫比的保護。人工智慧僅接收資料記錄中對於執行手頭任務真正必要的信息，僅此而已。大多數推理任務不會使用每個資料記錄中存在的所有資訊。無論您的 AI 使用的是圖像、語音、視訊還是結構化表格數據，Protopia 都只提供推理服務所需的內容。該專利核心技術使用數學策劃的雜訊來隨機轉換資料並混淆給定 ML 服務不需要的資訊。該解決方案不會掩蓋數據；相反，它通過使用精選的隨機噪聲來改變數據表示。</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">Protopia 解決方案將改變表示的問題表述為基於梯度的擾動最大化方法，該方法仍然保留與模型功能相關的輸入特徵空間中的信息。此發現過程在訓練 ML 模型結束時作為微調過程運行。在傳遞過程自動產生一組機率分佈之後，低開銷數據轉換會將這些分佈中的雜訊樣本應用於數據，並在將其傳遞給模型進行推理之前對其進行混淆。</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">NetApp ONTAP AI 參考架構由 DGX A100 系統和NetApp雲端連接儲存系統提供支持，由NetApp和NVIDIA開發和驗證。它為 IT 組織提供了一個具有以下優勢的架構：</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">消除設計複雜性</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">允許獨立擴展計算和存儲</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">使客戶能夠從小規模開始並無縫擴展</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">提供一系列適合各種效能和成本點的儲存選項</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI 將 DGX A100 系統和NetApp AFF A800儲存系統與最先進的網路緊密整合。 ONTAP AI 透過消除設計複雜性和猜測來簡化 AI 部署。客戶可以從小規模開始，然後無中斷地發展，同時智慧地管理從邊緣到核心到雲端再返回的資料。</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">下圖顯示了採用 DGX A100 系統的ONTAP AI 系列解決方案的幾種變體。 AFF A800系統性能已通過最多八個 DGX A100 系統驗證。透過向ONTAP叢集添加儲存控制器對，該架構可以擴展到多個機架，以支援許多 DGX A100 系統和具有線性性能的 PB 級儲存容量。這種方法可以靈活地根據所使用的 DL 模型的大小和所需的效能指標獨立地改變計算與儲存的比率。</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153：配備NVIDIA DGX A100 系統和 Mellanox Spectrum 乙太網路交換器的NetApp ONTAP AI。</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">有關ONTAP AI 的更多信息，請參閱<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11 是NetApp最新一代儲存管理軟體，它支援企業將基礎架構現代化並過渡到雲端就緒資料中心。 ONTAP利用業界領先的數據管理功能，只需一套工具即可管理和保護數據，無論數據位於何處。您也可以將資料自由移動到任何需要的地方：邊緣、核心或雲端。  ONTAP 9.11 包含許多功能，可簡化資料管理、加速和保護關鍵數據，並支援跨混合雲架構的下一代基礎架構功能。</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit 是一個 Python 函式庫，可協助開發人員、資料科學家、DevOps 工程師和資料工程師輕鬆執行各種資料管理任務，例如近乎即時地配置新的資料磁碟區或 JupyterLab 工作區、近乎即時地複製資料磁碟區或 JupyterLab 工作區，以及近乎即時快照資料磁碟區或 JupyterLab 工作區的基準測試區以進行可測試區的基準測試區或 JupyterLab 工作區以測試區。這個 Python 庫可以作為命令列實用程式或函數庫，您可以將其匯入到任何 Python 程式或 Jupyter 筆記本中。</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">NVIDIA Triton 推理伺服器是一款開源推理服務軟體，可協助標準化模型部署和執行，以在生產中提供快速且可擴展的 AI。  Triton Inference Server 透過讓團隊能夠在任何基於 GPU 或 CPU 的基礎架構上從任何框架部署、運行和擴展經過訓練的 AI 模型，簡化了 AI 推理。  Triton Inference Server 支援所有主流框架，例如 TensorFlow、 NVIDIA TensorRT、PyTorch、MXNet、OpenVINO 等。 Triton 與 Kubernetes 集成，可進行編排和擴展，您可以在所有主要的公有雲 AI 和 Kubernetes 平台中使用它。它還與許多 MLOps 軟體解決方案整合。</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>是一個開源的 ML 框架。它是一個針對使用 GPU 和 CPU 的深度學習而最佳化的張量庫。 PyTorch 套件包含多維張量的資料結構，它提供了許多實用程序，用於高效序列化張量以及其他有用的實用程式。它還有一個 CUDA 對應物，可讓您在具有運算能力的NVIDIA GPU 上執行張量運算。在本次驗證中，我們使用 OpenCV-Python (cv2) 函式庫來驗證我們的模型，同時利用 Python 最直覺的電腦視覺概念。</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">性能和更低的延遲。  ONTAP以盡可能低的延遲提供盡可能高的吞吐量。</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">資料保護。  ONTAP提供內建資料保護功能，並在所有平台上提供通用管理。</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">多租戶和多因素身份驗證。  ONTAP支援以最高等級的安全性共用基礎架構資源。</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">無縫擴展和無中斷運行。 ONTAP支援無中斷地向現有控制器和橫向擴展叢集添加容量。客戶可以升級到最新技術，例如 NVMe 和 32Gb FC，而無需昂貴的資料遷移或中斷。</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra控制</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astra控制服務</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">NetApp Astra產品系列由NetApp儲存和資料管理技術提供支持，為本地和公有雲中的 Kubernetes 應用程式提供儲存和應用程式感知資料管理服務。它使您能夠輕鬆備份 Kubernetes 應用程序，將資料遷移到不同的集群，並立即創建可運行的應用程式克隆。如果您需要管理在公有雲中運行的 Kubernetes 應用程序，請參閱<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>。  Astra Control Service 是一項NetApp託管服務，可為 Google Kubernetes Engine (GKE) 和 Azure Kubernetes Service (AKS) 中的 Kubernetes 叢集提供應用程式感知資料管理。</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block>NetApp推出的一款適用於 Docker 和 Kubernetes 的開源動態儲存編排器，可簡化持久性儲存的建立、管理和使用。  Trident是一個 Kubernetes 原生應用程序，直接在 Kubernetes 叢集中運作。  Trident讓客戶能夠將 DL 容器映像無縫部署到NetApp儲存體上，並為 AI 容器部署提供企業級體驗。  Kubernetes 使用者（ML 開發人員、資料科學家等）可以建立、管理和自動化編排和克隆，以利用NetApp技術提供支援的高階資料管理功能。</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>是NetApp 的一項快速、安全的資料同步服務。無論您需要在本機 NFS 或 SMB 檔案共用、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、Amazon Simple Storage Service (Amazon S3)、Amazon Elastic File System (Amazon EFS)、Azure Blob、Google )傳輸都能快速安全地將文件移動到您需要的位置。資料傳輸完成後，可在來源端和目標端完全使用。  BlueXP Copy 和 Syncc 會根據您預先定義的計劃持續同步數據，僅移動增量，從而最大限度地減少數據複製所花費的時間和金錢。  BlueXP Copy and Sync 是一種軟體即服務 (SaaS) 工具，其設定和使用極為簡單。 BlueXP Copy 和 Sync 觸發的資料傳輸由資料代理執行。您可以在 AWS、Azure、Google Cloud Platform 或本機部署BlueXP Copy 和 Sync 資料代理程式。</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">NetApp BlueXP分類</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">在強大的AI演算法驅動下，<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block>為您的整個資料資產提供自動化控制和資料治理。您可以輕鬆找到節省成本的方法、識別合規性和隱私問題並找到最佳化機會。  BlueXP分類儀表板可讓您洞察重複數據以消除冗餘，映射個人、非個人和敏感數據，並針對敏感數據和異常情況發出警報。</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">數位影像處理具有許多優點，使許多組織能夠充分利用與視覺表示相關的數據。 NetApp和 Protopia 解決方案提供了獨特的 AI 推理設計，以在整個 ML/DL 生命週期中保護和私有化 AI/ML 資料。它使客戶能夠保留敏感資料的所有權，透過緩解與隱私相關的擔憂，使用公共或混合雲部署模型實現規模和效率，並在邊緣部署人工智慧推理。</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">環境情報</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">在環境危害領域，各行各業可以多種方式利用地理空間分析。政府和公共工程部門可以就公共衛生和天氣狀況獲得可行的見解，以便在流行病或野火等自然災害期間更好地為公眾提供建議。例如，您可以在公共場所（例如機場或醫院）識別 COVID 陽性患者，而不會損害受影響個人的隱私，並提醒相關部門和附近公眾採取必要的安全措施。</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">邊緣設備穿戴裝置</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">在軍事和戰場上，您可以使用邊緣 AI 推理作為可穿戴設備來追蹤士兵的健康狀況、監控駕駛員行為並向當局發出接近軍用車輛的安全和相關風險警報，同時保護士兵的隱私。軍隊的未來將走向高科技，戰場物聯網 (IoBT) 和軍事物聯網 (IoMT) 將應用於可穿戴作戰裝備，幫助士兵透過使用快速邊緣運算識別敵人並在戰鬥中表現得更好。保護和保存從無人機和穿戴式裝置等邊緣裝置收集的視覺資料對於阻止駭客和敵人至關重要。</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">非戰鬥人員撤離行動</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">非戰鬥人員撤離行動 (NEO) 由國防部執行，旨在協助將生命受到威脅的美國公民和國民、國防部文職人員以及指定人員（東道國 (HN) 和第三國國民 (TCN)）撤離到適當的安全避難所。現有的行政控制措施主要採用手動的撤離人員篩選流程。然而，透過使用高度自動化的 AI/ML 工具結合 AI/ML 視訊混淆技術，可以提高撤離人員識別、撤離人員追蹤和威脅篩選的準確性、安全性和速度。</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">醫療保健和生物醫學研究</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">影像處理用於根據電腦斷層掃描 (CT) 或磁振造影 (MRI) 獲得的 3D 影像診斷手術規劃的病理。 HIPAA 隱私規則規定了組織如何收集、處理和刪除所有個人資訊和照片等數位影像。根據 HIPAA 安全港規定，要使資料符合可共享條件，必須刪除正面照片和任何類似影像。用於從結構 CT/MR 影像中隱藏個人臉部特徵的去識別或顱骨剝離演算法等自動化技術已成為生物醫學研究機構資料共享過程的重要組成部分。</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">AI/ML分析的雲端遷移</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">資料保護</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">企業客戶傳統上在本地訓練和部署 AI/ML 模型。出於規模經濟和效率的原因，這些客戶正在擴展以將 AI/ML 功能轉移到公共、混合或多雲部署。然而，它們受到可以向其他基礎設施公開的數據的限制。  NetApp解決方案可應對各種網路安全威脅，<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block>和安全評估，並與 Protopia 資料轉換結合，最大限度地降低將影像處理 AI/ML 工作負載遷移到雲端所帶來的風險。</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">TR-4886 邊緣人工智慧推理</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">情報與隱私</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">有關其他行業的邊緣運算和 AI 推理的更多用例，請參閱<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block>以及NetApp AI 博客，<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block> 。</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">Domino Data Lab 和NetApp的混合多雲 MLOps - 在哪裡可以找到更多信息</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">如何查找更多信息</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">多米諾數據實驗室</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">Domino Nexus</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetApp BlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">NetApp ONTAP資料管理軟體</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">NetApp AI 解決方案</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Domino Data Lab 技術聯盟 SA 總監 Josh Mineroff</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Nicholas Jablonski，Domino 資料實驗室現場首席技術官</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">Prabu Arjunan， NetApp解決方案架構師</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">NetApp技術聯盟夥伴全球聯盟總監 Brian Young</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">Domino Data Lab 和NetApp的混合多雲 MLOps - 架構</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">該解決方案將 Domino Nexus 的混合多雲工作負載調度功能與NetApp資料服務結合，以建立統一的混合雲 MLOps 平台。請參閱下表以了解詳情。</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">環境</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">MLOps 控制平面</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Domino Enterprise AI 平台與 Domino Nexus</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">MLOps 平台運算環境</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Domino Nexus 資料平面</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS，本地資料中心</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">本地運算平台</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>和<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">本地資料中心</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">雲端運算平台</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">亞馬遜彈性 Kubernetes 服務 (EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>和<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">本地資料平台</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">NetApp儲存設備</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>供電<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">雲端資料平台</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">Domino Data Lab 和NetApp的混合多雲 MLOps - 跨不同環境存取相同數據</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">跨不同環境存取相同數據</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">本節描述了為了跨不同的運算環境存取相同資料而需要執行的任務。在 Domino MLOps 平台中，運算環境被稱為「資料平面」。如果您的資料駐留在一個資料平面的NetApp區上，但您需要在另一個資料平面中存取它，請按照本節中概述的任務進行操作。這種場景通常被稱為“爆發”，或者當目標環境是雲時，被稱為“雲爆發”。在處理受限或超額訂閱的運算資源時通常需要此功能。例如，如果您的本機運算叢集超額訂閱，您可能想要將工作負載安排到雲端，以便立即啟動它們。</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">有兩種建議的選項可用於存取位於不同資料平面的NetApp磁碟區。這些選項在下面的小節中概述。根據您的特定要求選擇其中一個選項。下表描述了這兩個選項的優點和缺點。</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">選項</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">好處</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">缺點</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">選項 1 - 快取</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- 更簡單的工作流程 - 能夠根據需要快取資料子集 - 能夠將資料寫回來源 - 無需管理遠端副本</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- 由於快取被水化，初始資料存取的延遲增加。</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">選項 2 - 鏡像</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- 來源磁碟區的完整副本 - 不會因快取混合而增加延遲（鏡像操作完成後）</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- 必須等待鏡像操作完成後才能存取資料 - 必須管理遠端副本 - 無法寫回來源</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">選項 1 - 建立位於不同資料平面的磁碟區的緩存</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">NetApp FlexCache技術</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">和<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block>，您可以建立位於不同資料平面的NetApp磁碟區的快取。例如，如果您的本機資料平面中有NetApp卷，並且您需要在 AWS 資料平面中存取該卷，則可以在 AWS 中建立該磁碟區的快取。本節概述了建立位於不同資料平面的NetApp磁碟區的快取所需執行的任務。</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">在目標環境中建立FlexCache卷</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">如果目標環境是您的本機資料中心，您將在本機ONTAP系統上建立FlexCache磁碟區。如果目標環境是 AWS，您將在Amazon FSx ONTAP實例上建立FlexCache磁碟區。</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">首先，您必須在目標環境中建立一個FlexCache磁碟區。</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">BlueXP volume caching文檔</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">我們建議使用BlueXP來建立FlexCache磁碟區。若要使用BlueXP建立FlexCache卷，請依照<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block>。</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">如果您不想使用BlueXP，則可以使用ONTAP System Manager 或ONTAP CLI 來建立FlexCache磁碟區。若要使用 System Manager 建立FlexCache卷，請參閱<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block>。若要使用ONTAP CLI 建立FlexCache卷，請參閱<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block>。</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">BlueXP API</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">ONTAP REST API</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">ONTAP Ansible 集合</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">如果您希望自動執行此過程，您可以使用<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block>， 這<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block>或<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block>。</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">系統管理員在Amazon FSx ONTAP中不可用。</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">將FlexCache磁碟區公開給 Domino</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">「將現有NetApp卷公開給 Domino」部分</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">接下來，您必須將FlexCache磁碟區公開給 Domino MLOps 平台。若要將FlexCache磁碟區公開給 Domino，請依照「公開未由Trident提供的現有 NFS 磁碟區」子部分中概述的說明進行操作<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block>此解決方案。</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">現在，您將能夠在目標資料平面啟動作業和工作區時掛載FlexCache卷，如以下螢幕截圖所示。</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">在建立FlexCache磁碟區之前</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">將FlexCache磁碟區暴露給 Domino 之後</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">選項 2 - 複製位於不同資料平面的捲</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">NetApp SnapMirror資料複製技術</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">和<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block>，您可以建立位於不同資料平面的NetApp磁碟區的副本。例如，如果您的本機資料平面中有一個NetApp卷，並且您需要在 AWS 資料平面中存取該卷，則可以在 AWS 中建立該磁碟區的副本。本節概述了建立位於不同資料平面的NetApp磁碟區副本所需執行的任務。</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">創建SnapMirror關係</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">首先，您必須在來源磁碟區和目標環境中的新目標磁碟區之間建立SnapMirror關係。請注意，目標磁碟區將作為創建SnapMirror關係過程的一部分進行建立。</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">BlueXP replication文檔</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">我們建議使用BlueXP來創建SnapMirror關係。若要與BlueXP建立SnapMirror關係，請依照<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block>。</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">如果您不想使用BlueXP，則可以使用ONTAP System Manager 或ONTAP CLI 來建立SnapMirror關係。若要與 System Manager 建立SnapMirror關係，請參閱<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block>。若要使用ONTAP CLI 建立SnapMirror關係，請參閱<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block>。</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">中斷SnapMirror關係</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">接下來，您必須中斷SnapMirror關係才能啟動目標磁碟區進行資料存取。等到初始複製完成後再執行此步驟。</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">您可以透過檢查BlueXP、 ONTAP系統管理員或ONTAP CLI 中的鏡像狀態來確定複製是否已完成。複製完成後，鏡像狀態將為「snapmirrored」。</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">我們建議使用BlueXP來中斷SnapMirror關係。若要中斷與BlueXP 的SnapMirror關係，請依照<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block>。</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">如果您不想使用BlueXP，則可以使用ONTAP System Manager 或ONTAP CLI 來中斷SnapMirror關係。若要中斷與 System Manager 的SnapMirror關係，請參閱<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block>。若要使用ONTAP CLI 來中斷SnapMirror關係，請參閱<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block>。</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">將目標卷公開給 Domino</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">接下來，您必須將目標磁碟區公開給 Domino MLOps 平台。若要將目標磁碟區公開給 Domino，請依照「公開未由Trident提供的現有 NFS 磁碟區」子部分中概述的說明進行操作<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block>此解決方案。</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">現在，您將能夠在目標資料平面啟動作業和工作區時掛載目標卷，如下面的螢幕截圖所示。</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">在創建SnapMirror關係之前</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">將目標卷暴露給 Domino 後</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus 是一個單一玻璃窗格，可讓您在任何運算叢集（任何雲端、區域或本機）運行資料科學和機器學習工作負載。</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">Domino Data Lab 和NetApp的混合多雲 MLOps</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">NetApp的 Mike Oglesby</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">目前，世界各地的組織都在採用人工智慧來轉變其業務和流程。因此，支援人工智慧的運算基礎設施通常供不應求。企業正在採用混合多雲 MLOps 架構，以便利用不同區域、資料中心和雲端中的可用運算環境，平衡成本、可用性和效能。</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Data Lab 的 Domino Nexus 是一個統一的 MLOps 控制平面，可讓您在任何運算叢集（任何雲端、區域或本地）運行資料科學和機器學習工作負載。它統一了整個企業的資料科學孤島，因此您可以在一個地方建立、部署和監控模型。同樣，NetApp 的混合雲資料管理功能使您能夠將資料帶到您的作業和工作區，無論它們在何處運行。將 Domino Nexus 與NetApp配對後，您可以靈活地跨環境安排工作負載，而不必擔心資料可用性。換句話說，您可以將工作負載和資料傳送到適當的運算環境，從而加速您的 AI 部署，同時遵守有關資料隱私和主權的法規。</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">此解決方案示範了統一 MLOps 控制平面的部署，該控制平面結合了本機 Kubernetes 叢集和在 Amazon Web Services (AWS) 中執行的 Elastic Kubernetes Service (EKS) 叢集。</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">採用 Domino Data Lab 和NetApp 的混合多雲 MLOps - 初始設置</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">初始設定</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">本節介紹在包含本機資料中心和 AWS 的混合環境中使用 Domino Nexus 和NetApp資料服務所需執行的初始設定任務。</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">在執行本節中概述的步驟之前，我們假設您已經執行了以下任務：</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">您已經部署並配置了內部部署NetApp ONTAP儲存平台。欲了解更多信息，請參閱<block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> 。</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Amazon FSx ONTAP產品頁面</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">您已在 AWS 中設定了Amazon FSx ONTAP實例。欲了解更多信息，請參閱<block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> 。</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Domino 管理指南</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">您已經在本機資料中心配置了 Kubernetes 叢集。欲了解更多信息，請參閱<block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> 。</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">您已在 AWS 中配置了 Amazon EKS 叢集。欲了解更多信息，請參閱<block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> 。</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">NetApp Trident文檔</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">您已在本機 Kubernetes 叢集中安裝了NetApp Trident 。此外，您已設定此Trident實例以在配置和管理儲存資源時使用您的內部NetApp ONTAP儲存平台。欲了解更多信息，請參閱<block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> 。</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">您已在 Amazon EKS 叢集中安裝了NetApp Trident 。此外，您已設定此Trident實例以在配置和管理儲存資源時使用您的Amazon FSx ONTAP實例。欲了解更多信息，請參閱<block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> 。</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Amazon 虛擬私人網路 (VPN) 文檔</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">您的本機資料中心和 AWS 中的虛擬私有雲 (VPC) 之間必須具有雙向網路連線。有關實現此目的的各種選項的更多詳細信息，請參閱<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block>。</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">在 AWS 中安裝 Domino Enterprise AI 平台</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">若要在 AWS 中安裝 Domino Enterprise MLOps 平台，請依照<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block>。您必須在先前設定的相同 Amazon EKS 叢集中部署 Domino。此外，必須已在此 EKS 叢集中安裝和設定NetApp Trident ，並且您必須在 domino.yml 安裝設定檔中指定 Trident 管理的儲存類別作為共用儲存類別。</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Domino 安裝設定參考指南</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">請參閱<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block>有關如何在 domino.yml 安裝設定檔中指定共用儲存類別的詳細資訊。</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">技術報告 TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>介紹如何使用Amazon FSx ONTAP在 AWS 中部署 Domino，這可以作為解決出現的任何問題的有用參考。</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">啟用 Domino Nexus</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">接下來，您必須啟用 Domino Nexus。請參閱<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block>了解詳情。</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">在本地資料中心部署 Domino 資料平面</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">接下來，您必須在本機資料中心部署 Domino 資料平面。您必須在先前設定的本機 Kubernetes 叢集中部署此資料平面。此外，必須已在此 Kubernetes 叢集中安裝並設定了NetApp Trident 。請參閱<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block>了解詳情。</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">Domino Data Lab 和NetApp的混合多雲 MLOps - 技術概述</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">技術概述</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">本節提供了 Domino Data Lab 和NetApp的混合多雲 MLOps 技術概述。</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab 透過其領先的企業 AI 平台為模型驅動型企業提供支持，該平台受到超過 20% 的財富 100 強企業的信賴。 Domino 加速了資料科學工作的開發和部署，同時增強了協作和治理。借助多米諾骨牌，世界各地的企業可以開發更好的藥品、種植更高產量的作物、製造更好的汽車等等。  Domino 成立於 2013 年，由 Coatue Management、Great Hill Partners、Highland Capital、Sequoia Capital 和其他領先投資者提供支持。</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Domino 讓企業及其資料科學家能夠在統一的端到端平台上快速、負責且經濟高效地建置、部署和管理 AI。團隊可以在任何環境中存取他們所需的所有數據、工具、計算、模型和項目，以便他們可以協作、重複使用過去的工作、追蹤生產中的模型以提高準確性、使用最佳實踐進行標準化，並使 AI 負責任且受到管理。</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*開放且靈活：*存取最廣泛的開源和商業工具及基礎設施生態系統，獲得最佳創新且不受供應商鎖定。</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*記錄系統*：整個企業的人工智慧操作和知識的中心樞紐，支援最佳實踐、跨職能協作、更快的創新和效率。</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*整合*：整合的工作流程和自動化—專為企業流程、控制和治理而建置—滿足您的合規性和監管需求。</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*混合多雲：*在任何地方（本地、混合、任何雲端或多雲）運行靠近資料的 AI 工作負載，以降低成本、實現最佳效能和合規性。</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus 是一個單一玻璃窗格，可讓您在任何運算叢集（任何雲端、區域或本機）運行資料科學和機器學習工作負載。它統一了整個企業的資料科學孤島，因此您可以在一個地方建立、部署和監控模型。</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">NetApp BlueXP將 NetApp 的所有儲存和資料服務統一到一個工具中，讓您可以建置、保護和管理混合多雲資料資產。它為本地和雲端環境中的儲存和資料服務提供統一的體驗，並透過 AIOps 的強大功能實現操作簡化，具有當今雲端主導世界所需的靈活消費參數和整合保護。</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">雲端連線。  ONTAP是與雲端連線最緊密的儲存管理軟體，在所有公有雲中提供軟體定義儲存和雲端原生執行個體的選項。</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">Amazon FSx ONTAP是第一方完全託管的 AWS 服務，它基於 NetApp 流行的ONTAP檔案系統構建，提供高度可靠、可擴展、高效且功能豐富的檔案儲存。FSx ONTAP將NetApp檔案系統的熟悉功能、效能、功能和 API 操作與完全託管的 AWS 服務的靈活性、可擴充性和簡單性相結合。</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">Trident支援在所有流行的NetApp儲存平台上（無論是在公有雲還是在本地）使用和管理儲存資源，包括ONTAP （AFF、 FAS、Select、Cloud、 Amazon FSx ONTAP）、Element 軟體（NetApp HCI、 SolidFire）、 Azure NetApp Files服務和 Google Cloud 上的Google Cloud NetApp Volumes 。  Trident是一個符合容器儲存介面 (CSI) 的動態儲存編排器，可與 Kubernetes 原生整合。</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">Kubernetes 是一個開源的、分散式的容器編排平台，最初由 Google 設計，現在由雲端原生運算基金會 (CNCF) 維護。  Kubernetes 實現了容器化應用程式的部署、管理和擴展功能的自動化，是企業環境中占主導地位的容器編排平台。</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon Elastic Kubernetes Service (Amazon EKS) 是 AWS 雲端中的託管 Kubernetes 服務。 Amazon EKS 自動管理負責調度容器、管理應用程式可用性、儲存叢集資料和其他關鍵任務的 Kubernetes 控制平面節點的可用性和可擴充性。透過 Amazon EKS，您可以利用 AWS 基礎架構的所有效能、規模、可靠性和可用性，以及與 AWS 網路和安全服務的整合。</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">Domino Data Lab 和NetApp的混合多雲 MLOps - 將現有NetApp卷暴露給 Domino</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">將現有NetApp卷公開給 Domino</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">本節介紹將現有NetApp ONTAP NFS 磁碟區公開給 Domino MLOps 平台所需執行的任務。這些相同的步驟適用於本機和 AWS。</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">為什麼要將NetApp ONTAP磁碟區公開給 Domino？</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">將NetApp磁碟區與 Domino 結合使用可帶來以下好處：</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">您可以利用NetApp ONTAP 的橫向擴充功能針對極大資料集執行工作負載。</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">您可以在多個運算節點上執行工作負載，而無需將資料複製到各個節點。</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">您可以利用 NetApp 的混合多雲資料移動和同步功能來跨多個資料中心和/或雲端存取您的資料。</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">您希望能夠快速輕鬆地在不同的資料中心或雲端中建立資料快取。</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">公開未由Trident配置的現有 NFS 卷</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">如果您現有的NetApp ONTAP NFS 磁碟區不是由Trident配置的，請依照本小節所概述的步驟進行。</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">在 Kubernetes 中建立 PV 和 PVC</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">對於本機磁碟區，在本機 Kubernetes 叢集中建立 PV 和 PVC。對於Amazon FSx ONTAP磁碟區，在 Amazon EKS 中建立 PV 和 PVC。</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">NFS PV/PVC 範例</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">首先，您必須在 Kubernetes 叢集中建立持久性磁碟區 (PV) 和持久磁碟區宣告 (PVC)。若要建立 PV 和 PVC，請使用<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block>從 Domino 管理指南中更新值以反映您的環境。確保為<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block>，<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> ， 和<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block>字段。此外，我們建議為您的 PV 和 PVC 提供唯一的名稱，以代表儲存在對應ONTAP NFS 磁碟區上的資料的性質。例如，如果磁碟區包含製造缺陷的影像，您可以將 PV 命名為<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block>以及 PVC，<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> 。</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">在 Domino 中註冊外部資料卷</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">指示</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">接下來，您必須在 Domino 中註冊一個外部資料磁碟區。若要註冊外部資料卷，請參閱<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block>在 Domino 管理指南中。註冊卷時，請確保從“卷類型”下拉式選單中選擇“NFS”。選擇“NFS”後，您應該會在“可用磁碟區”清單中看到您的 PVC。</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">公開由Trident提供的現有捲</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">如果您現有的磁碟區是由Trident配置的，請按照本小節中概述的步驟進行操作。</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">編輯現有 PVC</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">如果您的磁碟區是由Trident配置的，那麼您已經擁有與您的磁碟區相對應的持久磁碟區聲明 (PVC)。為了將此磁碟區公開給 Domino，您必須編輯 PVC 並將以下標籤新增至<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block>場地：</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">接下來，您必須在 Domino 中註冊一個外部資料磁碟區。若要註冊外部資料卷，請參閱<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block>在 Domino 管理指南中。註冊卷時，請務必從「磁碟區類型」下拉式選單中選擇「通用」。選擇“通用”後，您應該會在“可用磁碟區”清單中看到您的 PVC。</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise 與NetApp和 VMware 合作 - 在哪裡可以找到更多信息</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise 與 VMware</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen， NetApp資深經理</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac， NetApp系統管理員</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">NetApp技術行銷工程師 Roney Daniel</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise 與NetApp和 VMware 合作 - 架構</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">該解決方案建立在經過驗證且熟悉的架構之上，具有NetApp、VMware 和NVIDIA認證的系統。請參閱下表以了解詳情。</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">人工智慧和數據分析軟體</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">適用於 VMware 的NVIDIA AI Enterprise</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">虛擬化平台</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">計算平台</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">NVIDIA認證系統</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">資料管理平台</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise 是一款端到端、雲端原生的 AI 和資料分析軟體套件，經過最佳化，每個組織都可以藉助 AI 取得成功。</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise 與NetApp和 VMware 合作</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">對於 IT 架構師和管理員來說，AI 工具可能很複雜且陌生。此外，許多人工智慧平台尚未為企業做好準備。  NVIDIA AI Enterprise 由NetApp和 VMware 提供支持，旨在提供精簡的企業級 AI 架構。</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise 與NetApp和 VMware - 利用NVIDIA NGC 軟體 - 設定</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">設定</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">本節介紹在NVIDIA AI Enterprise 環境中使用NVIDIA NGC 企業軟體所需執行的初始設定任務。</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">在執行本節中概述的步驟之前，NVIDIA假設您已經按照<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block>頁。</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">使用 vGPU 建立 Ubuntu Guest VM</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI 企業部署指南</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">首先，您必須建立一個具有 vGPU 的 Ubuntu 20.04 客戶虛擬機器。要建立具有 vGPU 的 Ubuntu 20.04 來賓虛擬機，請按照<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block>。</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">下載並安裝NVIDIA客戶軟體</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI Enterprise 快速入門指南</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">接下來，您必須在上一步驟建立的客戶虛擬機器中安裝所需的NVIDIA客戶軟體。若要在客戶虛擬機器中下載並安裝所需的NVIDIA客戶軟體，請依照<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>。</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">執行第 5.4 節中概述的驗證任務時，您可能需要使用不同的 CUDA 容器映像版本標籤，因為自編寫指南以來 CUDA 容器映像已更新。在我們的驗證中，我們使用了「nvidia/cuda:11.0.3-base-ubuntu20.04」。</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">下載 AI/分析框架容器</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">接下來，您必須從NVIDIA NGC 下載所需的 AI 或分析框架容器映像，以便它們可以在您的客戶虛擬機器中使用。若要在客戶虛擬機器中下載框架容器，請依照<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block>。</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">安裝和設定NetApp DataOps 工具包</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">接下來，您必須在來賓虛擬機器中安裝適用於傳統環境的NetApp DataOps Toolkit。 NetApp DataOps Toolkit 可用於直接從客戶虛擬機器內的終端機管理ONTAP系統上的橫向擴充資料磁碟區。若要在客戶虛擬機器中安裝NetApp DataOps Toolkit，請執行下列任務。</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">安裝 pip。</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">登出客戶 VM 終端，然後重新登入。</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">配置NetApp DataOps 工具包。為了完成此步驟，您將需要ONTAP系統的 API 存取詳細資訊。您可能需要從儲存管理員取得這些資訊。</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">建立來賓虛擬機器模板</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">最後，您必須根據您的客戶虛擬機器建立虛擬機器範本。您將能夠使用此範本快速建立用於利用NVIDIA NGC 軟體的客戶虛擬機器。</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">若要根據您的來賓 VM 建立 VM 模板，請登入 VMware vSphere，右鍵單擊來賓 VM 名稱，選擇“複製”，選擇“複製到模板...”，然後按照精靈進行操作。</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise 與NetApp和 VMware - 初始設置</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">本節介紹了將NVIDIA AI Enterprise 與NetApp和 VMware 結合使用所需執行的初始設定任務。</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI Enterprise 產品支援矩陣</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">NetApp和 VMware 解決方案文檔</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">在執行本節概述的步驟之前，我們假設您已經部署了 VMware vSphere 和NetApp ONTAP。請參閱<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block>有關支援的 vSphere 版本的詳細資訊。請參閱<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block>有關使用NetApp ONTAP部署 VMware vSphere 的詳細資訊。</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">安裝NVIDIA AI Enterprise Host 軟體</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">若要安裝NVIDIA AI Entrprise 主機軟體，請依照<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>。</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise 與NetApp和 VMware 合作 - 技術概述</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">本節概述了NVIDIA AI Enterprise 與NetApp和 VMware 的技術。</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise 是一款端到端、雲端原生的 AI 和資料分析軟體套件，經過NVIDIA優化、認證和支持，可在具有NVIDIA認證系統的 VMware vSphere 上運行。該軟體有助於在現代混合雲環境中簡單、快速地部署、管理和擴展 AI 工作負載。</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC 為 AI 從業者提供了一系列針對 GPU 最佳化的軟體，以開發他們的 AI 解決方案。它還提供對各種 AI 服務的訪問，包括用於模型訓練的NVIDIA Base Command、用於部署和監控模型的NVIDIA Fleet Command 以及用於安全存取和管理專有 AI 軟體的 NGC Private Registry。此外， NVIDIA AI Enterprise 客戶可以透過 NGC 入口網站請求支援。</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere 是 VMware 的虛擬化平台，它將資料中心轉變為包含 CPU、儲存和網路資源的聚合運算基礎架構。 vSphere 將這些基礎架構作為統一的操作環境進行管理，並為管理員提供管理該環境中資料中心的工具。</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">vSphere 的兩個核心元件是 ESXi 和 vCenter Server。  ESXi 是管理員創建和運行虛擬機器及虛擬設備的虛擬化平台。 vCenter Server 是管理員管理網路中連接的多台主機並池化主機資源的服務。</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps Toolkit 是一款基於 Python 的工具，可簡化由高效能、橫向擴展NetApp儲存支援的開發/培訓工作區和推理伺服器的管理。主要功能包括：</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">近乎即時地克隆高容量的 JupyterLab 工作區，以實現實驗或快速迭代。</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">幾乎即時地保存高容量 JupyterLab 工作區的快照，以用於備份和/或可追溯性/基準測試。</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">近乎即時地提供、複製和快照大容量、高效能資料磁碟區。</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise 與NetApp和 VMware 合作 - 利用NVIDIA NGC 軟體 - 範例用例 - TensorFlow 訓練作業</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">範例用例 - TensorFlow 訓練作業</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">本節介紹在NVIDIA AI Enterprise 環境中執行 TensorFlow 訓練作業所需執行的任務。</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">在執行本節中概述的步驟之前，我們假設您已經按照<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block>頁。</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">從模板建立來賓虛擬機</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">首先，您必須根據上一節中建立的範本建立新的客戶虛擬機器。若要從範本建立新的客戶虛擬機，請登入 VMware vSphere，右鍵單擊範本名稱，選擇“從此範本新虛擬機器...”，然後按照精靈操作。</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">建立並掛載資料卷</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">接下來，您必須建立一個新的資料卷來儲存您的訓練資料集。您可以使用NetApp DataOps Toolkit 快速建立新的資料卷。下面的範例指令顯示建立一個名為「imagenet」、容量為 2 TB 的磁碟區。</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">在您用資料填入資料磁碟區之前，您必須將其安裝在來賓虛擬機器中。您可以使用NetApp DataOps Toolkit 快速安裝資料卷。下面的範例指令顯示了上一個步驟中所建立的磁碟區的安裝。</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">填充數據量</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">在配置並安裝新磁碟區後，可以從來源位置擷取訓練資料集並將其放置在新磁碟區上。這通常涉及從 S3 或 Hadoop 數據湖中提取數據，有時還需要數據工程師的幫助。</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">執行 TensorFlow 訓練作業</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">現在，您已準備好執行 TensorFlow 訓練作業。若要執行 TensorFlow 訓練作業，請執行下列任務。</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">拉取NVIDIA NGC 企業 TensorFlow 容器鏡像。</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">啟動NVIDIA NGC 企業 TensorFlow 容器的執行個體。使用“-v”選項將資料卷附加到容器。</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">在容器內執行您的 TensorFlow 訓練程序。下面的範例指令展示了容器鏡像中所包含的範例 ResNet-50 訓練程式的執行。</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">NetApp開源 MLOps - Apache Airflow 部署</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow 部署</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">本節介紹在 Kubernetes 叢集中部署 Airflow 必須完成的任務。</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">可以在 Kubernetes 以外的平台上部署 Airflow。在 Kubernetes 以外的平台上部署 Airflow 超出了本解決方案的範圍。</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">在執行本節概述的部署練習之前，我們假設您已經執行了以下任務：</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">您已經有一個可以運行的 Kubernetes 叢集。</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Trident文檔</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">您已經在 Kubernetes 叢集中安裝並設定了NetApp Trident 。有關Trident的更多詳細信息，請參閱<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block>。</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">安裝 Helm</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">安裝說明</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow 使用 Helm（Kubernetes 的流行套件管理器）進行部署。在部署 Airflow 之前，必須在部署跳轉主機上安裝 Helm。若要在部署跳轉主機上安裝 Helm，請依照<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>在 Helm 官方文件中。</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">設定預設 Kubernetes StorageClass</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow部署</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">在部署 Airflow 之前，您必須在 Kubernetes 叢集中指定一個預設 StorageClass。 Airflow 部署程序嘗試使用預設 StorageClass 來設定新的持久性磁碟區。如果沒有指定 StorageClass 作為預設 StorageClass，則部署失敗。若要在叢集中指定預設 StorageClass，請依照<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>部分。如果您已經在叢集中指定了預設 StorageClass，則可以跳過此步驟。</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">使用 Helm 部署 Airflow</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">若要使用 Helm 在 Kubernetes 叢集中部署 Airflow，請從部署跳轉主機執行下列任務：</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">部署說明</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">按照以下說明使用 Helm 部署 Airflow<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block>查看 Artifact Hub 上的官方 Airflow 圖表。下面的範例指令展示了使用 Helm 部署 Airflow。修改、新增和/或刪除<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block>根據您的環境和所需配置，根據需要建立文件。</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">確認所有 Airflow pod 均已啟動並正在運作。所有 pod 啟動可能需要幾分鐘。</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">請依照步驟 1 中使用 Helm 部署 Airflow 時列印到控制台的說明取得 Airflow Web 服務 URL。</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">確認您可以存取 Airflow Web 服務。</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">NetApp的開源 MLOps - 將NetApp DataOps 工具包與 Airflow 結合使用</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">將NetApp DataOps 工具包與 Airflow 結合使用</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">這<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block>可以與 Airflow 結合使用。將NetApp DataOps Toolkit 與 Airflow 結合使用，您可以將NetApp資料管理作業（例如建立快照和複製）合併到由 Airflow 協調的自動化工作流程中。</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">氣流範例</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">請參閱<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block>有關將該工具包與 Airflow 結合使用的詳細信息，請參閱NetApp DataOps Toolkit GitHub 儲存庫中的部分。</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">NetApp的開源 MLOps - 架構</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">該解決方案不依賴特定的硬體。此解決方案與NetApp Trident支援的任何NetApp實體儲存設備、軟體定義實例或雲端服務相容。範例包括NetApp AFF儲存系統、 Amazon FSx ONTAP、 Azure NetApp Files、 Google Cloud NetApp Volumes或NetApp Cloud Volumes ONTAP個體。此外，只要所使用的 Kubernetes 版本受到NetApp Trident和正在實施的其他解決方案元件的支持，該解決方案就可以在任何 Kubernetes 叢集上實作。有關Trident支援的 Kubernetes 版本列表，請參閱<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block>。有關用於驗證此解決方案的各個組件的環境的詳細信息，請參閱下表。</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Apache Airflow 驗證環境</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">軟體元件</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Apache Airflow</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Apache Airflow Helm 圖表</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1，透過以下方式部署<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block>8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1.18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21.01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">JupyterHub 驗證環境</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">JupyterHub</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">JupyterHub Helm 圖表</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5，透過部署<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block>3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1.29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24.02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">MLflow 驗證環境</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">機器學習流</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">MLflow Helm 圖表</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1，透過部署<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block>1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Kubeflow 驗證環境</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Kubeflow</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">部署KF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7，透過部署<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block>0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1.26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23.07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">支援</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">聯絡NetApp</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">NetApp不為 Apache Airflow、JupyterHub、MLflow、Kubeflow 或 Kubernetes 提供企業支援。如果您對完全支援的 MLOps 平台感興趣，<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block>了解NetApp與合作夥伴共同提供的全面支援的 MLOps 解決方案。</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">NetApp的開源 MLOps - 技術概述</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">本節重點介紹NetApp的 OpenSource MLOps 技術概述。</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">人工智慧</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">人工智慧是一門電腦科學學科，其中電腦經過訓練可以模仿人類思維的認知功能。人工智慧開發人員訓練電腦以類似於人類甚至優於人類的方式學習和解決問題。深度學習和機器學習是人工智慧的子領域。越來越多的組織採用 AI、ML 和 DL 來支援其關鍵業務需求。以下是一些範例：</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">分析大量數據以發掘以前未知的商業見解</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">使用自然語言處理直接與客戶互動</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">自動化各種業務流程與功能</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">現代人工智慧訓練和推理工作負載需要大規模並行運算能力。因此，GPU 越來越多地被用於執行 AI 操作，因為 GPU 的平行處理能力遠遠優於通用 CPU。</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">容器</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">容器是在共享主機作業系統核心上運行的隔離的使用者空間實例。容器的採用正在迅速增加。容器提供許多與虛擬機器 (VM) 相同的應用程式沙盒優勢。然而，由於虛擬機器所依賴的虛擬機器管理程式和客戶作業系統層已被消除，因此容器變得更加輕量級。下圖描述了虛擬機器與容器的可視化。</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker 網站</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">容器還允許直接將應用程式依賴項、運行時間等與應用程式有效率地打包在一起。最常用的容器打包格式是Docker容器。以 Docker 容器格式容器化的應用程式可以在任何可以執行 Docker 容器的機器上執行。即使應用程式的依賴項不存在於機器上，情況也是如此，因為所有依賴項都打包在容器本身中。欲了解更多信息，請訪問<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>。</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes 網站</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">Kubernetes 是一個開源的、分散式的容器編排平台，最初由 Google 設計，現在由雲端原生運算基金會 (CNCF) 維護。 Kubernetes 支援容器化應用程式的部署、管理和擴充功能的自動化。近年來，Kubernetes 已成為主流的容器編排平台。欲了解更多信息，請訪問<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>。</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>支援在所有流行的NetApp儲存平台上（公有雲或內部）使用和管理儲存資源，包括ONTAP （AFF、 FAS、Select、Cloud、 Amazon FSx ONTAP）、 Azure NetApp Files服務和Google Cloud NetApp Volumes。  Trident是一個符合容器儲存介面 (CSI) 的動態儲存編排器，可與 Kubernetes 原生整合。</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">這<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block>是一個基於 Python 的工具，可簡化由高效能、橫向擴展NetApp儲存支援的開發/培訓工作區和推理伺服器的管理。主要功能包括：</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">快速配置由高效能、橫向擴展NetApp儲存支援的新的高容量工作區。</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">近乎即時地克隆高容量工作區，以實現實驗或快速迭代。</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">幾乎即時地保存高容量工作區的快照，以用於備份和/或可追溯性/基準測試。</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">Apache Airflow 是一個開源工作流程管理平台，支援以程式設計方式編寫、排程和監控複雜的企業工作流程。它通常用於自動化 ETL 和資料管道工作流程，但並不局限於這些類型的工作流程。  Airflow 計畫由 Airbnb 發起，但後來在業界變得非常流行，現在由 Apache 軟體基金會贊助。 Airflow 是用 Python 編寫的，Airflow 工作流程是透過 Python 腳本建立的，而 Airflow 是在「配置即程式碼」的原則下設計的。許多企業 Airflow 用戶現在在 Kubernetes 上運行 Airflow。</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">有向無環圖（DAG）</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">在 Airflow 中，工作流程被稱為有向無環圖 (DAG)。  DAG 由依序、並行或兩者結合執行的任務組成，取決於 DAG 定義。  Airflow 排程器在一組工作器上執行各個任務，遵守 DAG 定義中指定的任務層級依賴關係。  DAG 是透過 Python 腳本定義和建立的。</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">Jupyter 筆記本</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter 網站</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">Jupyter Notebooks 是類似 wiki 的文檔，包含即時程式碼和描述性文字。 Jupyter Notebooks 在 AI 和 ML 社群中被廣泛用作記錄、儲存和共享 AI 和 ML 專案的一種方式。有關 Jupyter Notebooks 的更多信息，請訪問<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>。</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Jupyter Notebook 伺服器</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Jupyter Notebook 伺服器是一個開源 Web 應用程序，允許使用者建立 Jupyter Notebook。</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">JupyterHub 網站</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">JupyterHub 是一個多用戶應用程序，允許個人用戶配置和存取自己的 Jupyter Notebook 伺服器。有關 JupyterHub 的更多信息，請訪問<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block>。</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">MLflow 網站</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow 是一個流行的開源 AI 生命週期管理平台。 MLflow 的主要功能包括 AI/ML 實驗追蹤和 AI/ML 模型庫。有關 MLflow 的更多信息，請訪問<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block>。</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow 網站</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow 是 Kubernetes 的開源 AI 和 ML 工具包，最初由 Google 開發。  Kubeflow 專案使得在 Kubernetes 上部署 AI 和 ML 工作流程變得簡單、可移植且可擴充。 Kubeflow 抽象化了 Kubernetes 的複雜性，使資料科學家能夠專注於他們最了解的領域——資料科學。請參考下圖以了解視覺化效果。對於喜歡一體化 MLOps 平台的組織來說，Kubeflow 是一個不錯的開源選擇。欲了解更多信息，請訪問<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>。</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow 管道</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Kubeflow 官方文檔</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Kubeflow Pipelines 是 Kubeflow 的關鍵元件。 Kubeflow Pipelines 是一個用於定義和部署可移植、可擴展的 AI 和 ML 工作流程的平台和標準。有關詳細信息，請參閱<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block>。</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Kubeflow 筆記本</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">Kubeflow 簡化了 Kubernetes 上 Jupyter Notebook 伺服器的設定和部署。有關 Kubeflow 上下文中的 Jupyter Notebooks 的更多信息，請參閱<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block>。</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">卡提布</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib 是一個用於自動化機器學習 (AutoML) 的 Kubernetes 原生專案。  Katib 支援超參數調整、早期停止和神經架構搜尋 (NAS)。 Katib 是一個與機器學習 (ML) 框架無關的專案。它可以調整使用者選擇的任何語言編寫的應用程式的超參數，並且原生支援許多 ML 框架，例如 TensorFlow、MXNet、PyTorch、XGBoost 等。 Katib 支援許多不同的 AutoML 演算法，例如貝葉斯優化、Parzen 估計器樹、隨機搜尋、協方差矩陣自適應進化策略、超頻、高效能神經架構搜尋、可微分架構搜尋等等。有關 Kubeflow 上下文中的 Jupyter Notebooks 的更多信息，請參閱<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block>。</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">無縫擴展和無中斷運行。 ONTAP支援無中斷地向現有控制器和橫向擴展叢集添加容量。客戶可以升級到最新技術，而無需昂貴的資料遷移或中斷。</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp快照副本</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetApp Snapshot 副本是磁碟區的唯讀、時間點映像。該影像佔用的儲存空間極小，且產生的效能開銷可以忽略不計，因為它僅記錄自上次 Snapshot 副本建立以來對檔案的更改，如下圖所示。</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Snapshot 副本的效率歸功於核心ONTAP儲存虛擬化技術，即任意位置寫入檔案佈局 (WAFL)。與資料庫一樣， WAFL使用元資料指向磁碟上的實際資料區塊。但是，與資料庫不同， WAFL不會覆蓋現有區塊。它將更新的資料寫入新區塊並更改元資料。這是因為ONTAP在創建 Snapshot 副本時引用元數據，而不是複製數據塊，所以 Snapshot 副本非常有效率。這樣做可以消除其他系統在定位要複製的區塊時產生的尋道時間，以及複製本身的成本。</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">您可以使用 Snapshot 副本來還原單一檔案或 LUN，或還原磁碟區的全部內容。  ONTAP將 Snapshot 副本中的指標資訊與磁碟上的資料進行比較，以重建遺失或損壞的對象，而無需停機或造成顯著的效能成本。</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone技術</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexClone技術參考 Snapshot 元資料來建立磁碟區的可寫入時間點副本。副本與其父級共用資料塊，除了元資料所需的儲存空間外，不消耗任何儲存空間，直到將變更寫入副本為止，如下圖所示。傳統的複製可能需要幾分鐘甚至幾小時才能創建，而FlexClone軟體可以讓您幾乎立即複製最大的資料集。這使得它非常適合需要相同資料集的多個副本（例如，開發工作區）或資料集的臨時副本（針對生產資料集測試應用程式）的情況。</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror資料複製技術</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror軟體是一種跨資料結構的經濟高效、易於使用的統一複製解決方案。它透過 LAN 或 WAN 高速複製資料。它為所有類型的應用程式（包括虛擬和傳統環境中的關鍵業務應用程式）提供高資料可用性和快速資料複製。當您將資料複製到一個或多個NetApp儲存系統並不斷更新輔助資料時，您的資料將保持最新狀態並可隨時使用。不需要外部複製伺服器。下圖是利用SnapMirror技術的架構範例。</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror軟體透過網路僅發送更改的區塊來利用NetApp ONTAP儲存效率。 SnapMirror軟體還使用內建網路壓縮來加速資料傳輸並將網路頻寬利用率降低高達 70%。借助SnapMirror技術，您可以利用一個精簡複製資料流來建立一個儲存庫，同時維護活動鏡像和先前的時間點副本，從而將網路流量減少高達 50%。</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>是NetApp 的一項快速、安全的資料同步服務。無論您需要在本機 NFS 或 SMB 檔案共用、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、AWS S3、AWS EFS、Azure Blob、Google Cloud Storage 或 IBM CloudObject Storage 之間傳輸檔案， BlueXP Copy and Sync 都能快速安全地移動到您的位置。</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">資料傳輸完成後，可在來源端和目標端完全使用。 BlueXP Copy and Sync 可以在觸發更新時按需同步數據，或根據預先定義的時間表連續同步數據。無論如何， BlueXP Copy and Sync 僅移動增量，因此在資料複製上花費的時間和金錢被最小化。</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync 是一種軟體即服務 (SaaS) 工具，其設定和使用極為簡單。  BlueXP Copy 和 Sync 觸發的資料傳輸由資料代理執行。  BlueXP Copy 和 Sync 資料代理程式可以部署在 AWS、Azure、Google Cloud Platform 或本地端。</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>是一款基於客戶端的軟體，用於任意到NetApp和NetApp到NetApp 的資料遷移和檔案系統洞察。  XCP 旨在透過利用所有可用的系統資源來處理大容量資料集和高效能遷移，從而實現擴展並實現最大效能。  XCP 可協助您全面了解檔案系統，並提供產生報告的選項。</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup卷</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">訓練資料集可能包含數十億個檔案。文件可以包括文字、音訊、視訊和其他形式的非結構化數據，這些數據必須儲存和處理才能並行讀取。儲存系統必須儲存大量小文件，並且必須並行讀取這些文件以實現順序和隨機 I/O。</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroup磁碟區是一個由多個組成成員磁碟區組成的單一命名空間，如下圖所示。從儲存管理員的角度來看， FlexGroup磁碟區的管理和行為類似於NetApp FlexVol volume。 FlexGroup卷中的檔案被指派給各個成員卷，並且不會跨卷或節點進行條帶化。它們支援以下功能：</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup磁碟區為高元資料工作負載提供了數 PB 的容量和可預測的低延遲。</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">它們支援同一命名空間中最多 4000 億個檔案。</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">它們支援跨 CPU、節點、聚合體和組成FlexVol磁碟區的 NAS 工作負載的平行操作。</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">此解決方案旨在展示可納入 MLOps 工作流程的幾種不同的開源工具和框架。根據需求和用例，這些不同的工具和框架可以一起使用或單獨使用。</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">NetApp的開源 MLOps</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby， NetApp Sufian Ahmad， NetApp Rick Huang， NetApp Mohan Acharya， NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">各種規模和各行業的公司和組織都在轉向人工智慧 (AI) 來解決現實世界的問題、提供創新的產品和服務，並在競爭日益激烈的市場中佔據優勢。許多組織正在轉向開源 MLOps 工具，以跟上產業快速創新的步伐。這些開源工具提供了先進的功能和尖端的特性，但通常不考慮資料可用性和資料安全性。不幸的是，這意味著高技能的資料科學家被迫花費大量時間等待獲取資料或等待基本的資料相關操作完成。透過將流行的開源 MLOps 工具與NetApp的智慧資料基礎架構結合，組織可以加速其資料管道，從而加速其 AI 計劃。他們可以從資料中釋放價值，同時確保資料受到保護且安全。該解決方案展示了NetApp資料管理功能與幾種流行的開源工具和框架的配對，以應對這些挑戰。</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">以下列表重點介紹了此解決方案支援的一些關鍵功能：</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">使用者可以快速配置由高效能、橫向擴展的NetApp儲存支援的新的高容量資料磁碟區和開發工作區。</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">使用者可以幾乎即時地克隆大容量資料磁碟區和開發工作區，以便進行實驗或快速迭代。</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">使用者可以幾乎即時保存大容量資料磁碟區和開發工作區的快照，以進行備份和/或可追溯性/基準測試。</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">Jupyter 筆記本</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">典型的 MLOps 工作流程包含開發工作區，通常採用以下形式<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block>；實驗追蹤；自動化訓練管道；資料管道；以及推理/部署。該解決方案重點介紹了幾種不同的工具和框架，它們可以獨立使用或結合使用來解決工作流程的不同方面。我們也展示了NetApp資料管理功能與每種工具的配對。此解決方案旨在提供建置模組，組織可據此建置針對其用例和要求的客製化 MLOps 工作流程。</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">此解決方案涵蓋以下工具/框架：</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">以下列表描述了獨立或共同部署這些工具的常見模式。</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">聯合部署 JupyterHub、MLflow 和 Apache Airflow - JupyterHub<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> 、用於實驗追蹤的 MLflow 以及用於自動化訓練和資料管道的 Apache Airflow。</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">聯合部署 Kubeflow 和 Apache Airflow - Kubeflow<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> 、實驗追蹤、自動化訓練管道和推理；以及用於資料管道的 Apache Airflow。</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">將 Kubeflow 部署為一體化 MLOps 平台解決方案<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block>、實驗追蹤、自動化訓練和資料管道以及推理。</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">NetApp開源 MLOps - JupyterHub 部署</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">JupyterHub 部署</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">本節介紹在 Kubernetes 叢集中部署 JupyterHub 必須完成的任務。</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">可以在 Kubernetes 以外的平台上部署 JupyterHub。在 Kubernetes 以外的平台上部署 JupyterHub 超出了本解決方案的範圍。</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">您已經在 Kubernetes 叢集中安裝並設定了NetApp Trident 。有關Trident的更多詳細信息，請參閱<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block>。</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">JupyterHub 使用 Helm（Kubernetes 的熱門套件管理器）進行部署。在部署 JupyterHub 之前，您必須在 Kubernetes 控制節點上安裝 Helm。要安裝 Helm，請按照<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>在 Helm 官方文件中。</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">在部署 JupyterHub 之前，您必須在 Kubernetes 叢集中指定一個預設 StorageClass。若要在叢集中指定預設 StorageClass，請依照<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>部分。如果您已經在叢集中指定了預設 StorageClass，則可以跳過此步驟。</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">部署 JupyterHub</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">完成上述步驟後，現在可以部署 JupyterHub 了。  JupyterHub 部署需要以下步驟：</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">設定 JupyterHub 部署</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">在部署之前，最好先針對各自的環境最佳化 JupyterHub 部署。您可以建立一個 *config.yaml* 檔案並在使用 Helm 圖表部署期間使用它。</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">可以在以下位置找到範例 *config.yaml* 文件<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">在此 config.yaml 檔案中，您可以為NetApp Trident StorageClass 設定 *(singleuser.storage.dynamic.storageClass)* 參數。這是用於為各個使用者工作區配置磁碟區的儲存類別。</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">新增共享磁碟區</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">如果您想要為所有 JupyterHub 使用者使用共享卷，您可以相應地調整您的 *config.yaml*。例如，如果您有一個名為 jupyterhub-shared-volume 的共用 PersistentVolumeClaim，則可以將其作為 /home/shared 掛載在所有使用者 pod 中，如下所示：</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">這是可選步驟，您可以根據需要調整這些參數。</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">使用 Helm Chart 部署 JupyterHub</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">讓 Helm 了解 JupyterHub Helm 圖表儲存庫。</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">這應該會顯示如下輸出：</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">現在透過從包含您的 config.yaml 的目錄執行以下命令來安裝由您的 config.yaml 設定的圖表：</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">在此範例中：</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt; 設定為 my-jupyterhub，這將是您的 JupyterHub 版本的名稱。 &lt;k8s-namespace&gt; 設定為 my-namespace，這是您要安裝 JupyterHub 的命名空間。如果命名空間不存在，則使用 --create-namespace 標誌建立命名空間。  --values 標誌指定包含所需設定選項的 config.yaml 檔案。</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">檢查部署</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">在步驟 2 運行時，您可以透過以下命令看到正在建立的 pod：</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">等待 hub 和 proxy pod 進入 Running 狀態。</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">造訪 JupyterHub</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">尋找我們可以用來存取 JupyterHub 的 IP。執行以下命令，直到代理公共服務的 EXTERNAL-IP 可用，如範例輸出所示。</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">我們在 config.yaml 檔案中使用了 NodePort 服務，您可以根據您的設定（例如 LoadBalancer）調整您的環境。</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">若要使用 JupyterHub，請在瀏覽器中輸入代理公共服務的外部 IP。</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">NetApp的開源 MLOps - 將NetApp DataOps 工具包與 JupyterHub 結合使用</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">將NetApp DataOps 工具包與 JupyterHub 結合使用</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">這<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block>可與 JupyterHub 結合使用。透過將NetApp DataOps Toolkit 與 JupyterHub 結合使用，最終使用者可以直接在 Jupyter Notebook 中建立用於工作區備份和/或資料集到模型可追溯性的磁碟區快照。</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">在將 DataOps Toolkit 與 JupyterHub 一起使用之前，您必須向 JupyterHub 指派給各個使用者 Jupyter Notebook Server pod 的 Kubernetes 服務帳戶授予適當的權限。  JupyterHub 使用由<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block>JupyterHub Helm 圖表設定檔中的變數。</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">為 DataOps Toolkit 建立叢集角色</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">首先，建立一個名為「netapp-dataops」的叢集角色，該角色具有建立磁碟區快照所需的 Kubernetes API 權限。</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">將叢集角色指派給筆記本伺服器服務帳戶</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">建立一個角色綁定，將「netapp-dataops-snapshots」叢集角色指派給適當命名空間中的適當服務帳戶。例如，如果您在「jupyterhub」命名空間中安裝了 JupyterHub，並且透過以下方式指定了「預設」服務帳戶<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block>變量，您需要將“netapp-dataops-snapshots”集群角色指派給“jupyterhub”命名空間中的“預設”服務帳戶，如下例所示。</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">在 Jupyter Notebook 中建立卷宗快照</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">現在，JupyterHub 使用者可以使用NetApp DataOps Toolkit 直接從 Jupyter Notebook 建立磁碟區快照，如下例所示。</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">使用NetApp SnapMirror擷取數據</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">使用NetApp SnapMirror將資料匯入 JupyterHub</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">NetApp SnapMirror是一種複製技術，可讓您在NetApp儲存系統之間複製資料。  SnapMirror可用於將遠端環境中的資料提取到 JupyterHub。</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">範例工作流程和演示</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">此 Tech ONTAP部落格文章</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">參考<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block>有關使用NetApp SnapMirror將資料匯入 JupyterHub 的詳細範例工作流程和示範。</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">NetApp開源 MLOps - Kubeflow 部署</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">本節介紹在 Kubernetes 叢集中部署 Kubeflow 必須完成的任務。</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">您已經有一個可運行的 Kubernetes 集群，並且您正在運行您打算部署的 Kubeflow 版本支援的 Kubernetes 版本。有關支援的 Kubernetes 版本列表，請參閱 Kubeflow 版本的依賴項<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block>。</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">在部署 Kubeflow 之前，我們建議在 Kubernetes 叢集中指定一個預設 StorageClass。 Kubeflow 部署程序可能會嘗試使用預設 StorageClass 來設定新的持久性磁碟區。如果沒有指定 StorageClass 作為預設 StorageClass，則部署可能會失敗。若要在叢集中指定預設 StorageClass，請從部署跳轉主機執行下列任務。如果您已經在叢集中指定了預設 StorageClass，則可以跳過此步驟。</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">將現有 StorageClass 之一指定為預設 StorageClass。以下範例命令顯示了名為<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block>作為預設的 StorageClass。</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">這<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>Trident Backend 類型的最小 PVC 尺寸相當大。預設情況下，Kubeflow 嘗試配置大小僅為幾 GB 的 PVC。因此，您不應該指定使用<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>後端類型作為 Kubeflow 部署的預設 StorageClass。</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Kubeflow部署選項</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">部署 Kubeflow 有很多不同的選擇。請參閱<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block>取得部署選項列表，然後選擇最適合您需求的選項。</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">為了驗證目的，我們使用以下方式部署了 Kubeflow 1.7<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1。</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">NetApp的開源 MLOps - 將NetApp DataOps 工具包與 Kubeflow 結合使用</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">將NetApp DataOps 工具包與 Kubeflow 結合使用</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">適用於 Kubernetes 的NetApp資料科學工具包</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">這<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block>可以與Kubeflow結合使用。將NetApp資料科學工具包與 Kubeflow 結合使用可帶來以下好處：</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">資料科學家可以直接在 Jupyter Notebook 中執行高階NetApp資料管理操作，例如建立快照和複製。</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">可以使用 Kubeflow Pipelines 框架將進階NetApp資料管理作業（例如建立快照和複製）納入自動化工作流程。</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow 範例</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">請參閱<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block>有關將該工具包與 Kubeflow 一起使用的詳細信息，請參閱NetApp資料科學工具包 GitHub 儲存庫中的部分。</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">NetApp的開源 MLOps - 為資料科學家或開發人員提供 Jupyter Notebook 工作區</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">為資料科學家或開發人員提供 Jupyter Notebook 工作區</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">Kubeflow 能夠快速設定新的 Jupyter Notebook 伺服器作為資料科學家工作區。有關 Kubeflow 上下文中的 Jupyter Notebooks 的更多信息，請參閱<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>。</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">NetApp開源 MLOps - 範例工作流程 - 使用 Kubeflow 和NetApp DataOps 工具包訓練影像辨識模型</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">範例工作流程 - 使用 Kubeflow 和NetApp DataOps 工具包訓練影像辨識模型</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">本節介紹使用 Kubeflow 和NetApp DataOps Toolkit 訓練和部署用於影像辨識的神經網路的步驟。這旨在作為範例來展示結合NetApp儲存的訓練作業。</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">建立一個包含所需配置的 Dockerfile，用於 Kubeflow 管道內的訓練和測試步驟。以下是 Dockerfile 的範例 -</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">根據您的要求，安裝運行程式所需的所有必需程式庫和套件。在訓練機器學習模型之前，假設您已經有一個可執行的 Kubeflow 部署。</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">使用 PyTorch 和 Kubeflow Pipelines 在 MNIST 資料上訓練小型 NN</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">我們使用在 MNIST 資料上訓練的小型神經網路作為範例。 MNIST 資料集由 0-9 的手寫數位影像組成。影像尺寸為 28x28 像素。此資料集分為 60,000 張訓練影像和 10,000 張驗證影像。本實驗所採用的神經網路是一個2層前饋網路。訓練是使用 Kubeflow Pipelines 執行的。請參閱文檔<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block>了解更多。我們的 Kubeflow 管道包含了先決條件部分的 docker 映像。</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Kubeflow 管道運行可視化</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">使用 Tensorboard 可視化結果</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">Tensorboard</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">一旦模型訓練完成，我們就可以使用 Tensorboard 將結果視覺化。<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block>作為 Kubeflow 儀表板上的功能提供。您可以為您的工作建立自訂張量板。以下的範例展示了訓練準確度與時期數以及訓練損失與時期數的關係圖。</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">訓練損失和準確率的 Tensorboard 圖表</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">使用 Katib 進行超參數實驗</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>是 Kubeflow 中的一個工具，可用來試驗模型超參數。要建立實驗，首先要定義所需的指標/目標。這通常是測試準確度。一旦定義了指標，選擇您想要使用的超參數（優化器/學習率/層數）。 Katib 使用使用者定義的值進行超參數掃描，以找到滿足所需指標的最佳參數組合。您可以在 UI 的每個部分中定義這些參數。或者，您可以定義一個具有必要規範的 *YAML* 檔案。以下是 Katib 實驗的說明 -</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">帶有超參數的 Katib 實驗儀表板</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">試運行成功</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">使用NetApp快照保存資料以實現可追溯性</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">在模型訓練期間，我們可能希望保存訓練資料集的快照以便於追溯。為此，我們可以向管道新增快照步驟，如下所示。要建立快照，我們可以使用<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block>。</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">在 Kubeflow 中建立快照管道的程式碼</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">適用於 Kubeflow 的NetApp DataOps Toolkit 範例</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">請參閱<block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block>了解更多。</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">NetApp開源 MLOps - MLflow 部署</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">MLflow部署</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">本節介紹在 Kubernetes 叢集中部署 MLflow 必須完成的任務。</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">可以在 Kubernetes 以外的平台上部署 MLflow。在 Kubernetes 以外的平台上部署 MLflow 超出了本解決方案的範圍。</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">MLflow 使用 Helm（Kubernetes 的流行套件管理器）進行部署。在部署 MLflow 之前，必須在 Kubernetes 控制節點上安裝 Helm。要安裝 Helm，請按照<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>在 Helm 官方文件中。</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">在部署 MLflow 之前，您必須在 Kubernetes 叢集中指定一個預設 StorageClass。若要在叢集中指定預設 StorageClass，請依照<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>部分。如果您已經在叢集中指定了預設 StorageClass，則可以跳過此步驟。</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">部署 MLflow</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">滿足先決條件後，您就可以使用 Helm Chart 開始 MLflow 部署。</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">設定 MLflow Helm Chart 部署。</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">在使用 Helm 圖表部署 MLflow 之前，我們可以使用 *config.yaml* 檔案將部署配置為使用NetApp Trident儲存類別並更改其他參數以滿足我們的需求。您可以在以下位置找到 *config.yaml* 檔案的範例：<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">您可以在 config.yaml 檔案中的 *global.defaultStorageClass* 參數下設定Trident storageClass（例如 storageClass：「ontap-flexvol」）。</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">安裝 Helm Chart</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">可以使用以下命令將 Helm 圖表與 MLflow 的自訂 *config.yaml* 檔案一起安裝：</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">該命令透過提供的*config.yaml*檔案在自訂配置中的 Kubernetes 叢集上部署 MLflow。  MLflow 部署在給定的命名空間中，並透過 kubernetes 為該版本提供一個隨機發布名稱。</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Helm 圖表部署完成後，您可以使用以下命令檢查服務是否可存取：</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">將 *jupyterhub* 替換為您在部署期間使用的命名空間。</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">您應該會看到以下服務：</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">我們編輯了 config.yaml 檔案以使用 NodePort 服務存取連接埠 30002 上的 MLflow。</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">存取 MLflow</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">一旦與 MLflow 相關的所有服務都啟動並運行，您就可以使用給定的 NodePort 或 LoadBalancer IP 位址存取它（例如<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block>)</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">NetApp開源 MLOps - 使用NetApp和 MLflow 實現資料集到模型的可追溯性</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">使用NetApp和 MLflow 實現資料集到模型的可追溯性</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">這<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block>可以與 MLflow 的實驗追蹤功能結合使用，以實現資料集到模型或工作區到模型的可追溯性。</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">要實現資料集到模型或工作區到模型的可追溯性，只需在訓練運行過程中使用 DataOps Toolkit 建立資料集或工作區磁碟區的快照，如下列範例程式碼片段所示。此程式碼將資料卷名稱和快照名稱儲存為與您記錄到 MLflow 實驗追蹤伺服器的特定訓練運行相關的標籤。</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">NetApp開源 MLOps - 執行同步分散式 AI 工作負載</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">執行同步分散式 AI 工作負載</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">若要在 Kubernetes 叢集中執行同步多節點 AI 和 ML 作業，請在部署跳轉主機上執行下列任務。此過程使您能夠利用儲存在NetApp磁碟區上的數據，並使用比單一工作節點所能提供的更多的 GPU。請參考下圖以了解同步分散式 AI 作業的描述。</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">與非同步分散式作業相比，同步分散式作業可以幫助提高效能和訓練準確性。關於同步作業與非同步作業的優缺點的討論超出了本文檔的範圍。</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">執行單節點 AI 工作負載</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">以下範例指令顯示如何建立一個工作器，該工作器參與本節範例中在單一節點上執行的相同 TensorFlow 基準測試作業的同步分散式執行<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block>。在這個特定的例子中，只部署了一個工作器，因為作業是在兩個工作器節點上執行的。</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Kubernetes 官方文檔</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">此範例工作器部署請求八個 GPU，因此可以在具有八個或更多 GPU 的單一 GPU 工作器節點上執行。如果您的 GPU 工作節點具有超過 8 個 GPU，為了最大限度地提高效能，您可能需要將此數字增加到等於您的工作節點所具有的 GPU 數量。有關 Kubernetes 部署的更多信息，請參閱<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>。</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">在此範例中建立了 Kubernetes 部署，因為這個特定的容器化工作程式永遠無法自行完成。因此，使用 Kubernetes 作業建構來部署它是沒有意義的。如果您的工作者被設計或編寫為自行完成，那麼使用作業建構來部署您的工作者可能是有意義的。</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">此範例部署規範中指定的 pod 被賦予<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>的價值<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>。此值表示 pod 使用主機工作節點的網路堆疊，而不是 Kubernetes 通常為每個 pod 建立的虛擬網路堆疊。在這種情況下使用此註釋，因為特定的工作負載依賴 Open MPI、NCCL 和 Horovod 以同步分散式方式執行工作負載。因此，它需要存取主機網路堆疊。有關 Open MPI、NCCL 和 Horovod 的討論超出了本文檔的範圍。不管這是否<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block>註釋是否必要取決於您正在執行的特定工作負載的要求。有關<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>字段，請參閱<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>。</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">確認您在步驟 1 中建立的工作程序部署已成功啟動。以下範例命令確認已為部署建立了一個工作程序 pod（如部署定義所示），並且該 pod 目前正在其中一個 GPU 工作程序節點上執行。</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">為主伺服器建立一個 Kubernetes 作業，該主伺服器啟動、參與並追蹤同步多節點作業的執行。以下範例指令建立一個主伺服器，該主伺服器啟動、參與並追蹤在本節範例中在單一節點上執行的相同 TensorFlow 基準測試作業的同步分散式執行<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block>。</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">此範例主作業請求八個 GPU，因此可以在具有八個或更多 GPU 的單一 GPU 工作節點上執行。如果您的 GPU 工作節點具有超過 8 個 GPU，為了最大限度地提高效能，您可能需要將此數字增加到等於您的工作節點所具有的 GPU 數量。</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">此範例作業定義中指定的主 Pod 被賦予<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>的價值<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>就像工作艙被賦予了<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>的價值<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>在步驟 1 中。有關為什麼需要此值的詳細信息，請參閱步驟 1。</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">確認您在步驟 3 中建立的主作業正在正確執行。下列範例指令確認已為該作業建立了一個主 pod（如作業定義所示），而該 pod 目前正在其中一個 GPU 工作節點上執行。您還應該看到，您在步驟 1 中最初看到的工作 pod 仍在運行，並且主 pod 和工作 pod 在不同的節點上運行。</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">確認您在步驟 3 中建立的主作業已成功完成。以下範例指令確認作業已成功完成。</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">當您不再需要工作部署時，請刪除它。以下範例指令顯示刪除在步驟 1 中建立的工作程序部署物件。</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">當您刪除工作部署物件時，Kubernetes 會自動刪除任何關聯的工作容器。</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*可選：*清理主作業工件。以下範例指令顯示刪除在步驟 3 中建立的主作業物件。</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">當您刪除主作業物件時，Kubernetes 會自動刪除任何關聯的主 pod。</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">NetApp開源 MLOps - 執行單節點 AI 工作負載</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">若要在 Kubernetes 叢集中執行單節點 AI 和 ML 作業，請從部署跳轉主機執行下列任務。使用Trident，您可以快速輕鬆地建立可能包含 PB 級資料的資料卷，以供 Kubernetes 工作負載存取。為了讓此類資料卷可從 Kubernetes pod 內部訪問，只需在 pod 定義中指定 PVC。</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">本節假設您已經將嘗試在 Kubernetes 叢集中執行的特定 AI 和 ML 工作負載容器化（以 Docker 容器格式）。</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet 網站</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">以下範例指令展示如何為使用 ImageNet 資料集的 TensorFlow 基準工作負載建立 Kubernetes 作業。有關 ImageNet 資料集的更多信息，請參閱<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>。</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">此範例作業請求八個 GPU，因此可以在具有八個或更多 GPU 的單一 GPU 工作節點上執行。此範例作業可以在叢集中提交，該叢集中不存在具有八個或更多 GPU 的工作節點，或目前正被另一個工作負載佔用。如果是，那麼作業將保持待處理狀態，直到有這樣的工作節點可用。</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">此外，為了最大限度地提高儲存頻寬，包含所需訓練資料的磁碟區在該作業建立的 pod 中被安裝了兩次。另一個卷也安裝在 pod 中。第二卷將用於儲存結果和指標。這些磁碟區在作業定義中透過使用 PVC 的名稱來引用。有關 Kubernetes 作業的更多信息，請參閱<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>。</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">一個<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>音量<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block>的價值<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block>安裝到<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>在此範例作業所建立的 pod 中。預設大小<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>Docker 容器運行時自動建立的虛擬磁碟區有時無法滿足 TensorFlow 的需求。安裝<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>如下例所示，音量提供了足夠大的<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>虛擬卷。有關更多信息<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>卷，參見<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>。</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">此範例作業定義中指定的單一容器被賦予<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block>的價值<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>。該值意味著容器實際上在主機上具有 root 存取權限。在這種情況下使用此註釋，因為正在執行的特定工作負載需要 root 存取權。具體來說，工作負載執行的清除快取操作需要 root 存取權限。不管這是否<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block>註釋是否必要取決於您正在執行的特定工作負載的要求。</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">確認您在步驟 1 中建立的作業正在正確執行。下列範例命令確認已為該作業建立了一個 pod（如作業定義中所指定），並且該 pod 目前正在其中一個 GPU 工作節點上執行。</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">確認您在步驟 1 中建立的作業已成功完成。以下範例指令確認作業已成功完成。</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*可選：*清理工作成果。以下範例指令顯示刪除在步驟 1 中建立的作業物件。</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">當您刪除作業物件時，Kubernetes 會自動刪除任何關聯的 pod。</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">NetApp開源 MLOps - NetApp AIPod部署的Trident後端範例</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">NetApp AIPod部署的Trident後端範例</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">在使用Trident在 Kubernetes 叢集中動態設定儲存資源之前，您必須建立一個或多個Trident後端。以下範例代表如果您要在下列位置部署此解決方案的元件，您可能需要建立的不同類型的後端：<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> 。有關後端的更多信息，以及其他平台/環境的後端示例，請參閱<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block>。</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">NetApp建議為您的AIPod建立支援FlexGroup的Trident Backend。</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">以下的範例指令展示如何為AIPod儲存虛擬機器 (SVM) 建立支援FlexGroup的Trident Backend。此後端使用<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>儲存驅動程式。  ONTAP支援兩種主要資料磁碟區類型： FlexVol和FlexGroup。 FlexVol卷的大小受到限制（截至撰寫本文時，最大大小取決於具體的部署）。另一方面， FlexGroup磁碟區可以線性擴展到最多 20PB 和 4000 億個文件，從而提供單一命名空間，大大簡化資料管理。因此， FlexGroup磁碟區最適合依賴大量資料的 AI 和 ML 工作負載。</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">如果您處理的資料量較小，並且想要使用FlexVol捲而不是FlexGroup卷，則可以建立使用<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>儲存驅動程序，而不是<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>儲存驅動程式。</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">NetApp也建議建立支援FlexVol的Trident Backend。您可能希望使用FlexVol磁碟區來託管持久性應用程式、儲存結果、輸出、偵錯資訊等。如果要使用FlexVol磁碟區，則必須建立一個或多個啟用FlexVol的Trident後端。下面的範例指令顯示如何建立啟用單一FlexVol的Trident後端。</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">NetApp的開源 MLOps - Trident作業範例</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Trident操作範例</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">本節包含您可能想要使用Trident執行的各種操作的範例。</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">導入現有磁碟區</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">如果您的NetApp儲存系統/平台上存在現有磁碟區，並且您想要將其安裝在 Kubernetes 叢集內的容器上，但這些磁碟區未與叢集中的 PVC 綁定，則必須匯入這些磁碟區。您可以使用Trident磁碟區匯入功能來匯入這些磁碟區。</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">以下範例指令顯示導入名為<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block>。有關 PVC 的更多信息，請參閱<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。有關卷宗導入功能的更多信息，請參閱<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block>。</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">一個<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block>的價值<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block>在範例 PVC 規格檔中指定。有關<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>字段，請參閱<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">提供新卷</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">您可以使用Trident在NetApp儲存系統或平台上設定新磁碟區。</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">使用 kubectl 設定新卷</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">以下範例指令顯示使用 kubectl 設定新的FlexVol volume。</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">一個<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block>的價值<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block>在下面的範例 PVC 定義檔中指定。有關<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>字段，請參閱<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">使用NetApp DataOps 工具包配置新磁碟區</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">文件</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">您也可以使用NetApp DataOps Toolkit for Kubernetes 在NetApp儲存系統或平台上設定新磁碟區。 NetApp DataOps Toolkit for Kubernetes 利用Trident來設定磁碟區，但簡化了使用者的流程。請參閱<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block>了解詳情。</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">NetApp開源 MLOps - NetApp AIPod部署的 Kubernetes 儲存類別範例</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">NetApp AIPod部署的 Kubernetes 儲存類別範例</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">在使用Trident在 Kubernetes 叢集中動態設定儲存資源之前，您必須建立一個或多個 Kubernetes StorageClasses。以下範例代表如果您在下列位置部署此解決方案的元件，您可能需要建立的不同類型的 StorageClasses：<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> 。有關 StorageClasses 的更多信息，以及其他平台/環境的 StorageClasses 範例，請參閱<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block>。</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">基於 RDMA 的 NFS</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">NetApp建議為您在本節中建立的支援FlexGroup的Trident Backend 建立 StorageClass<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block>中，步驟 1。下面的範例指令顯示如何建立多個 StorageClasses，這些 StorageClasses 與本節中建立的範例 Backend 相對應<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block>，步驟 1 - 利用<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block>還有一個則不然。</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes 文檔</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">為了確保持久卷在刪除相應的 PersistentVolumeClaim (PVC) 時不會被刪除，以下範例使用<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block>的價值<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block>。有關<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block>字段，請參閱官方<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>。</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">注意：下列範例 StorageClasses 使用的最大傳輸大小為 262144。若要使用此最大傳輸大小，您必須在ONTAP系統上相應地配置最大傳輸大小。請參閱<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block>了解詳情。</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">注意：要使用 NFS over RDMA，您必須在ONTAP系統上設定 NFS over RDMA。請參閱<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block>了解詳情。</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">注意：在以下範例中，StorageClass 定義檔中的 storagePool 欄位指定了具體的 Backend。</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">用於AIPod部署的Trident後端範例</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">NetApp也建議建立一個與您在本節中建立的支援FlexVol的Trident Backend 相對應的 StorageClass<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block>中，步驟 2。下面的範例指令展示如何為FlexVol磁碟區建立單一 StorageClass。</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">注意：在下面的範例中，StorageClass 定義檔中的 storagePool 欄位未指定特定的 Backend。當你使用 Kubernetes 來管理使用此 StorageClass 的磁碟區時， Trident會嘗試使用任何可用的後端，該後端使用<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>司機。</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">近乎即時地克隆高容量的 JupyterLab 工作區，以便進行實驗或快速迭代。</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">幾乎即時保存高容量 JupyterLab 工作區的快照，以用於備份和/或可追溯性/基準測試。</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">近乎即時地提供、複製和快照大容量、高效能資料磁碟區。</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">結論 - NetApp 的向量資料庫解決方案</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">本節總結了NetApp的向量資料庫解決方案。</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">總而言之，本文檔全面概述了在NetApp儲存解決方案上部署和管理向量資料庫（例如 Milvus 和 pgvector）。我們討論了利用NetApp ONTAP和StorageGRID物件儲存的基礎設施指南，並透過檔案和物件儲存驗證了 AWS FSx ONTAP中的 Milvus 資料庫。</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">我們探索了 NetApp 的檔案物件二元性，證明了它不僅適用於向量資料庫中的數據，也適用於其他應用程式。我們也重點介紹了 NetApp 的企業管理產品SnapCenter如何為向量資料庫資料提供備份、復原和複製功能，確保資料的完整性和可用性。</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">該文件還深入探討了 NetApp 的混合雲解決方案如何在本地端和雲端環境中提供資料複製和保護，從而提供無縫、安全的資料管理體驗。我們對NetApp ONTAP上 Milvus 和 pgvecto 等向量資料庫的效能驗證提供了見解，並提供了有關其效率和可擴展性的寶貴資訊。</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">最後，我們討論了兩個生成式 AI 用例：具有 LLM 的 RAG 和 NetApp 的內部 ChatAI。這些實際範例強調了本文檔中概述的概念和實踐的實際應用和好處。總的來說，對於任何希望利用 NetApp 強大的儲存解決方案來管理向量資料庫的人來說，本文檔都是一份全面的指南。</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">作者衷心感謝以下貢獻者以及其他提供回饋和評論的人，使本文對NetApp客戶和NetApp領域具有價值。</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan， NetApp ONTAP AI 與分析技術行銷工程師</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">NetApp技術行銷工程師 Mike Oglesby</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">NetApp資深總監 AJ Mahajan</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">NetApp工作負載效能工程經理 Joe Scott</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">NetApp Fsx 產品管理資深總監 Puneet Dhawan</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">NetApp FSx 產品團隊資深產品經理 Yuval Kalderon</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Milvus 文檔 -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Milvus 獨立文檔 -<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">NetApp產品文檔<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">installclustr 文檔</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">instaclustr -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">2024年4月</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">為 NetApp 的向量資料庫解決方案準備數據</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">附錄 B：prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">本節提供用於準備向量資料庫資料的Python腳本範例。</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">向量資料庫部署程式 - NetApp 向量資料庫解決方案</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">本節討論NetApp向量資料庫解決方案的部署過程。</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">部署流程</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">在本部署部分中，我們使用 milvus 向量資料庫和 Kubernetes 進行以下實驗設定。</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">NetApp 儲存為叢集提供存儲，以保存客戶資料和 Milvus 叢集資料。</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">NetApp儲存設定 – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">對於 NFS（網路檔案系統），請依照下列步驟操作：</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">為 NFSv4 建立FlexGroup區。在我們為此驗證所做的設定中，我們使用了 48 個 SSD，其中 1 個 SSD 專用於控制器的根卷，另外 47 個 SSD 分佈用於 NFSv4]].驗證FlexGroup卷的 NFS 導出策略是否對 Kubernetes（K8s）節點網路具有讀取/寫入權限。如果沒有這些權限，請授予 K8s 節點網路的讀取/寫入 (rw) 權限。</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">在所有 K8s 節點上，建立一個資料夾，並透過每個 K8s 節點上的邏輯介面 (LIF) 將FlexGroup磁碟區掛載到該資料夾上。</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">對於 NAS S3（網路附加儲存簡單儲存服務），請依照下列步驟操作：</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">為 NFS 建立FlexGroup區。</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">透過將其類型設為「nas」並提供 NFSv3 磁碟區的路徑來建立 NAS 儲存桶。也可以利用 S3 儲存桶來實現此目的。</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">NetApp儲存設定 – StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">安裝 storageGRID 軟體。</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">建立租戶和儲存桶。</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">建立具有所需權限的使用者。</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">請查看更多詳細信息<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml - Netapp 的向量資料庫解決方案</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">附錄 D：docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">本節包含NetApp向量資料庫解決方案的範例 YAML 程式碼。</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">使用 Snapcenter 進行向量資料庫保護 - NetApp 的向量資料庫解決方案</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">使用SnapCenter進行向量資料庫保護</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">本節介紹如何使用NetApp SnapCenter為向量資料庫提供資料保護。</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">使用NetApp SnapCenter進行向量資料庫保護。</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">例如，在電影製作行業，客戶通常擁有關鍵的嵌入式數據，如視訊和音訊檔案。由於硬碟故障等問題而導致的資料遺失可能會對其營運產生重大影響，甚至可能危及價值數百萬美元的企業。我們曾經遇到寶貴內容遺失的情況，造成嚴重的混亂和經濟損失。因此，確保這些重要數據的安全性和完整性對該行業至關重要。在本節中，我們將深入探討SnapCenter如何保護駐留在ONTAP中的向量資料庫資料和 Milvus 資料。在此範例中，我們使用了從 NFS ONTAP磁碟區 (vol1) 衍生的 NAS 儲存桶 (milvusdbvol1) 來儲存客戶數據，並使用了單獨的 NFS 磁碟區 (vectordbpv) 來儲存 Milvus 叢集配置資料。請查看<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block>Snapcenter 備份工作流程</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">設定將用於執行SnapCenter指令的主機。</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">NetApp自動化商店</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">安裝並配置儲存插件。從新增的主機中，選擇「更多選項」。導航到並選擇下載的儲存插件<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block>。安裝插件並儲存配置。</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">設定儲存系統和磁碟區：在「儲存系統」下新增儲存系統，並選擇SVM（儲存虛擬機器）。在這個例子中，我們選擇了「vs_nvidia」。</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">為向量資料庫建立資源，包含備份策略和自訂快照名稱。</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">使用預設值啟用一致性群組備份，並啟用不具有檔案系統一致性的SnapCenter 。</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">在儲存佔用空間部分，選擇與向量資料庫客戶資料和 Milvus 叢集資料關聯的磁碟區。在我們的範例中，這些是“vol1”和“vectordbpv”。</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">建立向量資料庫保護策略，並利用此策略保護向量資料庫資源。</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">使用 Python 腳本將資料插入 S3 NAS 儲存桶。在我們的案例中，我們修改了 Milvus 提供的備份腳本，即“prepare_data_netapp.py”，並執行“sync”命令從作業系統中刷新資料。</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">驗證 S3 NAS 儲存桶中的資料。在我們的範例中，帶有時間戳記「2024-04-08 21:22」的檔案是由「prepare_data_netapp.py」腳本建立的。</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">使用「milvusdb」資源的一致性群組 (CG) 快照啟動備份</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">為了測試備份功能，我們在備份過程後新增了一個新表，或從 NFS（S3 NAS 儲存桶）中刪除了一些資料。</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">對於此測試，想像一下有人在備份後創建了新的、不必要的或不適當的集合的場景。在這種情況下，我們需要將向量資料庫還原到新增新集合之前的狀態。例如，已插入“hello_milvus_netapp_sc_testnew”和“hello_milvus_netapp_sc_testnew2”等新集合。</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">從上一個快照執行 S3 NAS 儲存桶的完整復原。</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">使用 Python 腳本驗證來自「hello_milvus_netapp_sc_test」和「hello_milvus_netapp_sc_test2」集合的資料。</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">驗證資料庫中不再存在不必要或不適當的集合。</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">總而言之，使用 NetApp 的SnapCenter來保護駐留在ONTAP中的向量資料庫資料和 Milvus 資料可以為客戶帶來顯著的優勢，特別是在資料完整性至關重要的行業，例如電影製作。 SnapCenter 能夠建立一致的備份並執行完整的資料恢復，確保關鍵資料（例如嵌入式視訊和音訊檔案）不會因硬碟故障或其他問題而遺失。這不僅可以防止營運中斷，還可以防止重大財務損失。</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">在本節中，我們示範如何配置SnapCenter來保護駐留在ONTAP中的數據，包括主機的設定、儲存插件的安裝和配置，以及使用自訂快照名稱為向量資料庫建立資源。我們也展示如何使用一致性群組快照執行備份並驗證 S3 NAS 儲存桶中的資料。</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">此外，我們模擬了備份後創建不必要或不適當的集合的情況。在這種情況下，SnapCenter 從先前的快照執行完整復原的能力可確保向量資料庫可以還原到新增集合之前的狀態，從而保持資料庫的完整性。這種將資料恢復到特定時間點的功能對於客戶來說非常寶貴，它為他們提供了保證，確保他們的資料不僅安全，而且得到正確的維護。因此，NetApp 的SnapCenter產品為客戶提供了強大且可靠的資料保護和管理解決方案。</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">使用NetApp SnapMirror進行災難復原 - NetApp 的向量資料庫解決方案</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">使用NetApp SnapMirror進行災難復原</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">本節討論使用SnapMirror為NetApp實現向量資料庫解決方案的 DR（災難復原）。</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">災難復原對於維護向量資料庫的完整性和可用性至關重要，尤其是考慮到其在管理高維度資料和執行複雜相似性搜尋中的作用。精心規劃和實施的災難復原策略可確保在發生硬體故障、自然災害或網路攻擊等不可預見的事件時資料不會遺失或受到損害。這對於依賴向量資料庫的應用程式尤其重要，因為資料的遺失或損壞可能導致嚴重的營運中斷和財務損失。此外，強大的災難復原計劃還可以最大限度地減少停機時間並允許快速恢復服務，從而確保業務連續性。這是透過NetApp資料複製產品 SnapMirror 跨不同地理位置、定期備份和故障轉移機制實現的。因此，災難復原不僅僅是一種保護措施，而且是負責任、有效率的向量資料庫管理的重要組成部分。</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">NetApp 的SnapMirror提供從一個NetApp ONTAP儲存控制器到另一個儲存控制器的資料複製，主要用於災難復原 (DR) 和混合解決方案。在向量資料庫的背景下，該工具有助於實現資料在本地和雲端環境之間的平穩過渡。這種轉變無需任何資料轉換或應用程式重構即可實現，從而提高了跨多個平台資料管理的效率和靈活性。</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">NetApp Hybrid解決方案在向量資料庫場景下可以帶來更多優勢：</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">可擴展性：NetApp 的混合雲解決方案能夠根據您的需求擴展您的資源。您可以利用本機資源來處理常規、可預測的工作負載，並利用雲端資源（例如Amazon FSx ONTAP for NetApp ONTAP和 Google Cloud NetApp Volume（NetApp Volumes））來應對尖峰時段或意外負載。</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">成本效益：NetApp 的混合雲模型可讓您透過使用內部資源來處理常規工作負載並僅在需要時支付雲端資源費用來優化成本。這種按需付費模式透過NetApp instaclustr 服務產品可以實現相當高的成本效益。對於本地和主要雲端服務供應商，instaclustr 提供支援和諮詢。</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">靈活性：NetApp 的混合雲讓您可以靈活地選擇在何處處理資料。例如，您可能選擇在擁有更強大硬體的本地執行複雜的向量操作，而在雲端中執行不太密集的操作。</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">業務連續性：如果發生災難，將資料保存在NetApp混合雲中可以確保業務連續性。如果您的本地資源受到影響，您可以快速切換到雲端。我們可以利用NetApp SnapMirror將資料從本地端移動到雲端，反之亦然。</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">創新：NetApp 的混合雲解決方案還可以透過提供對尖端雲端服務和技術的存取來實現更快的創新。  NetApp在雲端領域的創新，例如Amazon FSx ONTAP for NetApp ONTAP、 Azure NetApp Files和Google Cloud NetApp Volumes都是雲端服務供應商的創新產品和首選 NAS。</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">instaclustr 與 pgvector - Netapp 的向量資料庫解決方案</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">使用 PostgreSQL 的 Instaclustr 向量資料庫：pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">本節討論 instaclustr 產品如何與NetApp向量資料庫解決方案中的 postgreSQL 的 pgvector 功能整合的具體細節。</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">部落格</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">在本節中，我們將深入探討 instaclustr 產品如何在 pgvector 功能上與 postgreSQL 整合的具體細節。我們有一個範例「如何使用 PGVector 和 PostgreSQL 來提高 LLM 準確性和效能：嵌入簡介和 PGVector 的作用」。請檢查<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block>以獲取更多資訊。</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">NetApp向量資料庫解決方案介紹</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">本節介紹NetApp的向量資料庫解決方案。</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">向量資料庫有效地解決了旨在處理大型語言模型 (LLM) 和生成人工智慧 (AI) 中的語義搜尋複雜性的挑戰。與傳統的數據管理系統不同，向量資料庫能夠使用數據本身的內容而不是標籤或標記來處理和搜尋各種類型的數據，包括圖像、視訊、文字、音訊和其他形式的非結構化資料。</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">關聯式資料庫管理系統 (RDBMS) 的限制是有據可查的，尤其是它們在處理人工智慧應用中常見的高維度資料表示和非結構化資料時遇到的困難。 RDBMS 通常需要將資料扁平化為更易於管理的結構，這個過程既耗時又容易出錯，從而導致搜尋延遲和效率低下。向量資料庫的出現解決了這些問題，為複雜高維資料的管理和搜尋提供了更有效率、更準確的解決方案，從而促進了人工智慧應用的發展。</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">本文檔為目前正在使用或計劃使用向量資料庫的客戶提供全面的指南，詳細介紹了在NetApp ONTAP、 NetApp StorageGRID、 Amazon FSx ONTAP for NetApp ONTAP和SnapCenter等平台上使用向量資料庫的最佳實務。本文提供的內容涵蓋了一系列主題：</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">NetApp儲存透過NetApp ONTAP和StorageGRID物件儲存為 Milvus 等向量資料庫提供基礎設施指南。</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">透過檔案和物件儲存驗證 AWS FSx ONTAP中的 Milvus 資料庫。</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">深入研究 NetApp 的檔案物件二元性，展示其對向量資料庫以及其他應用程式中的資料的實用性。</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">NetApp 的資料保護管理產品SnapCenter如何為向量資料庫資料提供備份和復原功能。</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">NetApp 的混合雲如何在本機和雲端環境中提供資料複製和保護。</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">提供有關NetApp ONTAP上 Milvus 和 pgvector 等向量資料庫的效能驗證的見解。</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">兩個具體的用例：具有大型語言模型 (LLM) 的檢索增強生成 (RAG) 和NetApp IT 團隊的 ChatAI，從而提供所概述的概念和實踐的實際範例。</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">向量資料庫 - NetApp 的向量資料庫解決方案</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">向量資料庫</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">本節介紹NetApp AI 解決方案中向量資料庫的定義與使用。</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">向量資料庫是一種特殊類型的資料庫，旨在使用機器學習模型的嵌入來處理、索引和搜尋非結構化資料。它不以傳統的表格格式組織數據，而是將數據排列為高維向量，也稱為向量嵌入。這種獨特的結構使得資料庫能夠更有效率、更準確地處理複雜、多維的資料。</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">向量資料庫的關鍵功能之一是使用生成式人工智慧進行分析。這包括相似性搜索，其中資料庫識別類似於給定輸入的資料點，以及異常檢測，其中它可以發現與常態有顯著偏差的資料點。</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">此外，向量資料庫非常適合處理時間資料或帶有時間戳記的資料。這種類型的數據提供有關發生了什麼以及何時發生的信息，按順序以及與給定 IT 系統中所有其他事件的關係。這種處理和分析時間資料的能力使得向量資料庫對於需要了解隨時間推移的事件的應用程式特別有用。</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">向量資料庫對於機器學習和人工智慧的優勢：</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">高維搜尋：向量資料庫擅長管理和檢索高維數據，這些數據通常在 AI 和 ML 應用程式中產生。</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">可擴展性：它們可以有效擴展以處理大量數據，支援 AI 和 ML 項目的成長和擴展。</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">靈活性：向量資料庫具有高度的靈活性，可以適應多種資料類型和結構。</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">效能：它們提供高效能資料管理和檢索，這對於 AI 和 ML 操作的速度和效率至關重要。</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">可自訂的索引：向量資料庫提供可自訂的索引選項，從而能夠根據特定需求優化資料組織和檢索。</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">向量資料庫和用例。</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">本節提供各種向量資料庫及其用例詳細資訊。</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">Faiss和ScaNN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">它們是向量搜尋領域中的重要工具庫。這些庫提供的功能有助於管理和搜尋向量數據，使其成為數據管理這一專業領域的寶貴資源。</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">Elasticsearch</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">它是一種廣泛使用的搜尋和分析引擎，最近加入了向量搜尋功能。此新功能增強了其功能，使其能夠更有效地處理和搜尋向量資料。</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">松果</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">它是一個具有一組獨特功能的強大向量資料庫。它的索引功能同時支援密集和稀疏向量，從而增強了其靈活性和適應性。它的主要優勢之一在於能夠將傳統搜尋方法與基於人工智慧的密集向量搜尋相結合，從而創造出一種兼具兩全其美的混合搜尋方法。</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Pinecone 主要基於雲端，專為機器學習應用而設計，可與各種平台良好集成，包括 GCP、AWS、Open AI、GPT-3、GPT-3.5、GPT-4、Catgut Plus、Elasticsearch、Haystack 等。值得注意的是，Pinecone 是一個閉源平台，可作為軟體即服務 (SaaS) 產品使用。</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">鑑於其先進的功能，Pinecone 特別適合網路安全產業，其高維度搜尋和混合搜尋功能可以有效地利用來檢測和應對威脅。</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">色度</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">它是一個向量資料庫，具有包含四個主要功能的核心 API，其中一個功能包括記憶體文件向量儲存。它還利用 Face Transformers 庫來向量化文檔，增強其功能和多功能性。 Chroma 的設計可在雲端和本地運行，可根據使用者需求提供靈活性。特別是在音訊相關應用方面表現出色，使其成為基於音訊的搜尋引擎、音樂推薦系統和其他音訊相關用例的絕佳選擇。</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">威維特</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">它是一個多功能向量資料庫，允許用戶使用其內建模組或自訂模組向量化其內容，根據特定需求提供靈活性。它提供完全託管和自託管解決方案，滿足各種部署偏好。</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">Weaviate 的主要功能之一是它能夠同時儲存向量和對象，從而增強其資料處理能力。它廣泛應用於一系列應用，包括 ERP 系統中的語義搜尋和資料分類。在電子商務領域，它為搜尋和推薦引擎提供支援。  Weaviate 也用於影像搜尋、異常偵測、自動資料協調和網路安全威脅分析，展示了其在多個領域的多功能性。</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">Redis</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">Redis 是一種高效能向量資料庫，以其快速的記憶體儲存而聞名，可為讀寫作業提供低延遲。這使其成為需要快速數據存取的推薦系統、搜尋引擎和數據分析應用程式的絕佳選擇。</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">Redis 支援向量的各種資料結構，包括列表、集合和有序集。它還提供向量運算，例如計算向量之間的距離或尋找交集和並集。這些功能對於相似性搜尋、聚類和基於內容的推薦系統特別有用。</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">在可擴展性和可用性方面，Redis 擅長處理高吞吐量工作負載並提供資料複製。它還可以與其他資料類型很好地集成，包括傳統的關係資料庫（RDBMS）。 Redis 包含一個用於即時更新的發布/訂閱（Pub/Sub）功能，這有利於管理即時向量。此外，Redis 輕量且易於使用，使其成為管理向量資料的使用者友善解決方案。</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">Milvus</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">它是一個多功能的向量資料庫，提供類似文件儲存的 API，非常類似於 MongoDB。它因支援多種數據類型而脫穎而出，成為數據科學和機器學習領域的熱門選擇。</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">Milvus 的獨特功能之一是其多向量化功能，它允許使用者在運行時指定用於搜尋的向量類型。此外，它利用 Knowwhere（一個位於 Faiss 等其他庫之上的庫）來管理查詢和向量搜尋演算法之間的通訊。</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">由於與 PyTorch 和 TensorFlow 相容，Milvus 還提供與機器學習工作流程的無縫整合。這使其成為一系列應用的絕佳工具，包括電子商務、圖像和視訊分析、物件識別、圖像相似性搜尋和基於內容的圖像檢索。在自然語言處理領域，Milvus 用於文件聚類、語意搜尋和問答系統。</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">對於這個解決方案，我們選擇了 milvus 進行解決方案驗證。為了提高效能，我們同時使用了 milvus 和 postgres（pgvecto.rs）。</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">為什麼我們選擇 milvus 作為這個解決方案？</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">開源：Milvus 是一個開源向量資料庫，鼓勵社群驅動的開發和改進。</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">AI 整合：它利用嵌入相似性搜尋和 AI 應用程式來增強向量資料庫功能。</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">大容量處理：Milvus 有能力儲存、索引和管理由深度神經網路 (DNN) 和機器學習 (ML) 模型產生的超過十億個嵌入向量。</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">使用者友善：易於使用，設定只需不到一分鐘。  Milvus 也為不同的程式語言提供 SDK。</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">速度：它提供極快的檢索速度，比一些替代方案快 10 倍。</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">可擴展性和可用性：Milvus 具有高度可擴展性，可根據需要進行擴展和縮小。</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">功能豐富：它支援不同的資料類型、屬性過濾、使用者定義函數 (UDF) 支援、可配置的一致性等級和旅行時間，使其成為各種應用的多功能工具。</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Milvus 架構概述</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">本節提供 Milvus 架構中使用的更高層級的元件和服務。  * 存取層－由一組無狀態代理程式組成，作為系統的前端層和使用者的端點。 * 協調器服務－它將任務分配給工作節點並充當系統的大腦。它有三種協調器類型：根協調器、資料協調器和查詢協調器。  * 工作節點：它遵循協調服務的指令並執行使用者觸發的DML / DDL命令。它有三種類型的工作節點，例如查詢節點，資料節點和索引節點。 * 儲存：負責資料持久化。它包括元存儲、日誌代理和物件存儲。  NetApp儲存（例如ONTAP和StorageGRID）為 Milvus 提供物件儲存和基於文件的存儲，用於客戶資料和向量資料庫資料。</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">milvus 與Amazon FSx ONTAP for NetApp ONTAP - NetApp 的向量資料庫解決方案</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">Milvus 與Amazon FSx ONTAP for NetApp ONTAP - 檔案與物件二元性</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">本節討論使用Amazon FSx ONTAP為NetApp提供向量資料庫解決方案的 milvus 叢集設定。</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">Milvus 與Amazon FSx ONTAP for NetApp ONTAP – 檔案與物件二元性</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">在本節中，我們將介紹為什麼需要在雲端部署向量資料庫，以及在 Docker 容器中的Amazon FSx ONTAP for NetApp ONTAP中部署向量資料庫（milvus 獨立版）的步驟。</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">在雲端部署向量資料庫有幾個顯著的好處，特別是對於需要處理高維度資料和執行相似性搜尋的應用程式。首先，基於雲端的部署提供了可擴展性，允許輕鬆調整資源以適應不斷增長的資料量和查詢負載。這確保資料庫能夠有效地處理增加的需求，同時保持高效能。其次，雲端部署提供了高可用性和災難復原，因為資料可以在不同的地理位置複製，最大限度地降低資料遺失的風險，並確保即使在意外事件期間也能持續提供服務。第三，它具有成本效益，因為您只需為您使用的資源付費，並且可以根據需求擴大或縮小規模，從而無需在硬體上進行大量的前期投資。最後，在雲端部署向量資料庫可以增強協作，因為可以從任何地方存取和共享數據，從而促進基於團隊的工作和數據驅動的決策。請使用Amazon FSx ONTAP for NetApp ONTAP檢查此驗證中所使用的 milvus 獨立架構。</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">為NetApp ONTAP實例建立Amazon FSx ONTAP ，並記下 VPC、VPC 安全性群組和子網路的詳細資訊。建立 EC2 執行個體時需要此資訊。您可以在此處找到更多詳細資訊 -<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">建立一個 EC2 實例，確保 VPC、安全性群組和子網路與Amazon FSx ONTAP for NetApp ONTAP執行個體的 VPC、安全性群組和子網路相符。</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">使用指令“apt-get install nfs-common”安裝 nfs-common，並使用“sudo apt-get update”更新套件資訊。</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">建立一個掛載資料夾並在其上掛載適用於NetApp ONTAP 的Amazon FSx ONTAP 。</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">使用“apt-get install”安裝 Docker 和 Docker Compose。</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">根據 docker-compose.yaml 檔案建立 Milvus 集群，該檔案可以從 Milvus 網站下載。</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">在 docker-compose.yml 檔案的「volumes」部分中，將NetApp NFS 掛載點對應到對應的 Milvus 容器路徑，具體在 etcd、minio 和 standalone 中。檢查<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block>有關 yml 更改的詳細信息</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">驗證已安裝的資料夾和檔案。</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">從包含 docker-compose.yml 檔案的目錄執行「docker-compose up -d」。</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">檢查 Milvus 容器的狀態。</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">為了驗證Amazon FSx ONTAP for NetApp ONTAP中向量資料庫及其資料的讀寫功能，我們使用了 Python Milvus SDK 和來自 PyMilvus 的範例程式。使用「apt-get install python3-numpy python3-pip」安裝必要的軟體包，並使用「pip3 install pymilvus」安裝 PyMilvus。</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">驗證向量資料庫中Amazon FSx ONTAP for NetApp ONTAP的資料寫入和讀取操作。</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">使用verify_data_netapp.py腳本檢查讀取操作。</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">如果客戶想要透過 S3 協定存取（讀取）向量資料庫中測試的 NFS 資料以用於 AI 工作負載，則可以使用簡單的 Python 程式進行驗證。一個例子可以是來自另一個應用程式的圖像的相似性搜索，如本節開頭的圖片中提到的那樣。</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">本節有效地展示了客戶如何在 Docker 容器中部署和操作獨立的 Milvus 設置，並利用 Amazon 的NetApp FSx ONTAP進行NetApp ONTAP資料儲存。此設定允許客戶利用向量資料庫的強大功能來處理高維資料和執行複雜查詢，所有這些都可以在可擴展且高效的 Docker 容器環境中完成。透過建立適用於NetApp ONTAP執行個體和符合的 EC2 執行個體的Amazon FSx ONTAP ，客戶可以確保最佳的資源利用率和資料管理。 FSx ONTAP在向量資料庫中資料寫入和讀取操作的成功驗證為客戶提供了可靠、一致的資料操作的保證。此外，透過 S3 協定列出（讀取）來自 AI 工作負載的資料的能力增強了資料可存取性。因此，這項全面的流程為客戶提供了一個強大且高效的解決方案，用於管理他們的大規模資料操作，並利用了 Amazon FSx ONTAP for NetApp ONTAP的功能。</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">milvus 叢集設定 - NetApp 的向量資料庫解決方案</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">在本地使用 Kubernetes 設定 Milvus 集群</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">本節討論針對NetApp的向量資料庫解決方案的 milvus 叢集設定。</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">在本地使用 Kubernetes 設定 Milvus 集群</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">客戶面臨的挑戰是在儲存和運算上獨立擴展、有效的基礎設施管理和資料管理，Kubernetes 和向量資料庫共同構成了管理大數據操作的強大、可擴展的解決方案。 Kubernetes 最佳化資源並管理容器，而向量資料庫則有效率地處理高維度資料和相似性搜尋。這種組合能夠快速處理大型資料集上的複雜查詢，並隨著資料量的增加而無縫擴展，使其成為大數據應用程式和人工智慧工作負載的理想選擇。</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">在本節中，我們詳細介紹了在 Kubernetes 上安裝 Milvus 叢集的過程，並利用NetApp儲存控制器儲存叢集資料和客戶資料。</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">要安裝 Milvus 集群，需要持久卷 (PV) 來儲存來自各個 Milvus 集群組件的資料。這些元件包括 etcd（三個實例）、pulsar-bookie-journal（三個實例）、pulsar-bookie-ledgers（三個實例）和 pulsar-zookeeper-data（三個實例）。</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">此連結</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">在 milvus 叢集中，我們可以使用 pulsar 或 kafka 作為支撐 Milvus 叢集可靠儲存以及訊息流發布/訂閱的底層引擎。對於使用 NFS 的 Kafka， NetApp在ONTAP 9.12.1 及更高版本中做出了改進，這些增強功能以及 RHEL 8.7 或 9.1 及更高版本中包含的 NFSv4.1 和 Linux 更改解決了在 NFS 上運行 Kafka 時可能出現的“愚蠢重命名”問題。如果您對使用 NetApp NFS 解決方案運行 Kafka 主題的更多深入資訊感興趣，請查看 -<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> 。</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">我們從NetApp ONTAP建立了一個 NFS 卷，並建立了 12 個持久性卷，每個卷具有 250GB 的儲存空間。儲存大小可能因集群大小而異；例如，我們有另一個集群，其中每個 PV 有 50GB。請參閱下面的 PV YAML 文件之一以了解更多詳細資訊；我們總共有 12 個這樣的文件。在每個檔案中，storageClassName 設定為“default”，並且儲存和路徑對於每個 PV 都是唯一的。</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">對每個 PV YAML 檔案執行「kubectl apply」命令來建立持久卷，然後使用「kubectl get pv」驗證其建立</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">為了儲存客戶數據，Milvus 支援物件儲存解決方案，例如 MinIO、Azure Blob 和 S3。在本指南中，我們使用 S3。以下步驟適用於ONTAP S3 和StorageGRID物件儲存。我們使用 Helm 來部署 Milvus 叢集。從 Milvus 下載位置下載設定檔 values.yaml。有關我們在本文檔中使用的 values.yaml 文件，請參閱附錄。</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">確保每個部分中的“storageClass”設定為“default”，包括日誌、etcd、zookeeper 和 bookkeeper。</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">在 MinIO 部分，停用 MinIO。</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">從ONTAP或StorageGRID物件儲存建立 NAS 儲存桶，並使用物件儲存憑證將其包含在外部 S3 中。</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">在建立 Milvus 叢集之前，請確保 PersistentVolumeClaim（PVC）沒有任何預先存在的資源。</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">利用 Helm 和 values.yaml 設定檔安裝並啟動 Milvus 叢集。</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">驗證 PersistentVolumeClaims (PVC) 的狀態。</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">檢查 pod 的狀態。</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">請確保 Pod 狀態為「正在運作」且如預期運作</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">測試在 Milvus 和NetApp物件儲存中寫入和讀取資料。</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">使用“prepare_data_netapp_new.py”Python 程式寫入資料。</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">使用“verify_data_netapp.py”Python 檔案讀取資料。</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">基於上述驗證，Kubernetes 與向量資料庫的集成，透過使用NetApp儲存控制器在 Kubernetes 上部署 Milvus 集群，為客戶提供了強大、可擴展且高效的大規模資料操作管理解決方案。此設定為客戶提供了處理高維度資料和快速且有效率地執行複雜查詢的能力，使其成為大數據應用和人工智慧工作負載的理想解決方案。對各種叢集元件使用持久性磁碟區 (PV)，並從NetApp ONTAP建立單一 NFS 卷，可確保最佳資源利用率和資料管理。驗證 PersistentVolumeClaims (PVC) 和 pod 的狀態以及測試資料寫入和讀取的過程為客戶提供了可靠且一致的資料操作的保證。使用ONTAP或StorageGRID物件儲存客戶資料進一步增強了資料的可存取性和安全性。總體而言，這種設定為客戶提供了一種有彈性且高效能的資料管理解決方案，可隨著客戶不斷增長的資料需求而無縫擴展。</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">NetApp 向量資料庫解決方案概述</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">本節概述了NetApp向量資料庫解決方案。</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">該解決方案展示了NetApp為應對向量資料庫客戶面臨的挑戰所提供的獨特優勢和功能。透過利用NetApp ONTAP、 StorageGRID、NetApp 的雲端解決方案和SnapCenter，客戶可以為其業務營運增加顯著的價值。這些工具不僅解決了現有的問題，還提高了效率和生產力，從而促進了整體業務成長。</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">為什麼選擇NetApp？</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">NetApp 的產品（例如ONTAP和StorageGRID）允許分離儲存和運算，從而能夠根據特定需求實現最佳資源利用率。這種靈活性使客戶能夠使用NetApp儲存解決方案獨立擴展其儲存。</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">NetApp ONTAP為 AWS、Azure 和 Google Cloud 等領先的雲端服務供應商提供對 NAS 和物件儲存的原生支援。這種廣泛的兼容性確保了無縫集成，實現了客戶資料移動性、全球可訪問性、災難復原、動態可擴展性和高效能。</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">借助 NetApp 強大的資料管理功能，客戶可以放心，因為他們的資料受到良好的保護，不會受到潛在風險和威脅。  NetApp優先考慮資料安全，讓客戶對其寶貴資訊的安全性和完整性感到放心。</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">向量資料庫效能驗證 - NetApp 向量資料庫解決方案</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">向量資料庫效能驗證</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">本節重點介紹在向量資料庫上執行的效能驗證。</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">性能驗證</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">效能驗證在向量資料庫和儲存系統中都起著至關重要的作用，是確保最佳運作和高效資源利用的關鍵因素。向量資料庫以處理高維度資料和執行相似性搜尋而聞名，需要保持高效能水準才能快速準確地處理複雜查詢。效能驗證有助於識別瓶頸、微調配置並確保系統能夠處理預期負載而不會降低服務品質。同樣，在儲存系統中，效能驗證對於確保資料高效儲存和檢索至關重要，不會出現可能影響整體系統效能的延遲問題或瓶頸。它還有助於對儲存基礎設施的必要升級或變更做出明智的決策。因此，效能驗證是系統管理的重要方面，對維持高服務品質、運作效率和整體系統可靠性有重要貢獻。</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">在本節中，我們旨在深入研究向量資料庫（例如 Milvus 和 pgvecto.rs）的效能驗證，重點關注它們的儲存效能特徵，例如 I/O 設定檔和 NetApp 儲存控制器在 LLM 生命週期內支援 RAG 和推理工作負載的行為。當這些資料庫與ONTAP儲存解決方案結合時，我們將評估並識別任何效能差異因素。我們的分析將基於關鍵效能指標，例如每秒處理的查詢數（QPS）。</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">請檢查下面用於 milvus 和進度的方法。</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus（單機和叢集）</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres（pgvecto.rs）#</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">版本</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">檔案系統</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">iSCSI LUN 上的 XFS</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">工作負載產生器</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">VectorDB-Bench</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– v0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">數據集</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">LAION 資料集 * 1000 萬個嵌入 * 768 個維度 * 資料集大小約 300GB</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * 版本 — 9.14.1 * 4 x 100GbE — 用於 milvus，2x 100GbE 用於 postgres * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">帶有 Milvus 獨立叢集的 VectorDB-Bench</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">我們使用vectorDB-Bench在milvus獨立叢集上進行了以下效能驗證。  milvus 獨立叢集的網路和伺服器連線如下。</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">在本節中，我們分享測試 Milvus 獨立資料庫的觀察和結果。。我們選擇 DiskANN 作為這些測試的索引類型。。提取、優化和建立大約 100GB 資料集的索引大約需要 5 個小時。在此持續時間的大部分時間裡，配備 20 個核心（啟用超線程時相當於 40 個 vCPU）的 Milvus 伺服器都以其最大 CPU 容量 100% 運行。我們發現 DiskANN 對於超過系統記憶體大小的大型資料集尤其重要。。在查詢階段，我們觀察到每秒查詢次數 (QPS) 為 10.93，回想率為 0.9987。查詢的第 99 個百分位延遲測量為 708.2 毫秒。</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">從儲存角度來看，資料庫在攝取、插入後最佳化和索引建立階段發出約 1,000 次操作/秒。在查詢階段，它要求每秒 32,000 次操作。</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">以下部分介紹儲存效能指標。</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">工作負載階段</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">公制</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">資料擷取和插入後優化</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">每秒輸入/輸出次數</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">&lt; 1,000</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">延遲</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">&lt; 400 微秒</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">工作量</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">讀/寫混合，主要是寫入</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">IO大小</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64KB</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">詢問</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">峰值為32,000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">100% 快取讀取</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">主要為8KB</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">VectorDB-bench 結果如下。</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">從獨立 Milvus 實例的效能驗證來看，目前的設定不足以支援 500 萬個向量、維度為 1536 的資料集。我們已確定儲存擁有足夠的資源，不會構成系統的瓶頸。</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">帶有 milvus 叢集的 VectorDB-Bench</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">在本節中，我們討論在 Kubernetes 環境中部署 Milvus 叢集。此 Kubernetes 設定建置於 VMware vSphere 部署之上，該部署託管 Kubernetes 主節點和工作節點。</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">以下部分介紹 VMware vSphere 和 Kubernetes 部署的詳細資訊。</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">在本節中，我們介紹了測試 Milvus 資料庫的觀察結果和結果。  * 使用的索引類型是 DiskANN。 * 下表比較了在處理 500 萬個向量（維度為 1536）時獨立部署和集群部署的差異。我們觀察到，在叢集部署中，資料擷取和插入後最佳化所需的時間較短。與獨立設定相比，叢集部署中查詢的第 99 個百分位延遲減少了六倍。  * 儘管叢集部署中的每秒查詢數 (QPS) 率較高，但並未達到預期水準。</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">下圖提供了各種儲存指標的視圖，包括儲存叢集延遲和總 IOPS（每秒輸入/輸出操作）。</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">以下部分介紹關鍵的儲存效能指標。</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">峰值為147,000</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">基於獨立 Milvus 和 Milvus 叢集的效能驗證，我們展示了儲存 I/O 設定檔的詳細資訊。  * 我們觀察到 I/O 設定檔在獨立部署和叢集部署中保持一致。  * 峰值 IOPS 的觀察到的差異可以歸因於群集部署中的客戶端數量較多。</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">附有 Postgres 的vectorDB-Bench（pgvecto.rs）</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">我們使用 VectorDB-Bench 對 PostgreSQL（pgvecto.rs）進行瞭如下操作：PostgreSQL（具體來說，pgvecto.rs）的網路和伺服器連線詳情如下：</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">在本節中，我們分享測試 PostgreSQL 資料庫（特別是使用 pgvecto.rs）的觀察和結果。  * 我們選擇 HNSW 作為這些測試的索引類型，因為在測試時，DiskANN 不適用於 pgvecto.rs。 * 在資料擷取階段，我們載入了 Cohere 資料集，該資料集包含 1,000 萬個向量，維度為 768。該過程大約耗時 4.5 小時。 * 在查詢階段，我們觀察到每秒查詢次數 (QPS) 為 1,068，回想率為 0.6344。查詢的第 99 個百分位延遲測量為 20 毫秒。在大部分運行時間內，客戶端 CPU 都以 100% 的容量運作。</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">下圖提供了各種儲存指標的視圖，包括儲存叢集延遲總 IOPS（每秒輸入/輸出操作）。</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">milvus 與 postgres 在向量資料庫基準測試上的效能對比</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">根據我們使用 VectorDBBench 對 Milvus 和 PostgreSQL 進行的效能驗證，我們觀察到以下情況：</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">索引類型：HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">資料集：包含 768 個維度的 1000 萬個向量</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">我們發現 pgvecto.rs 的每秒查詢數 (QPS) 達到 1,068，召回率為 0.6344，而 Milvus 的每秒查詢數 (QPS) 達到 106，召回率為 0.9842。</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">如果您優先考慮查詢的高精度，Milvus 的表現優於 pgvecto.rs，因為它在每個查詢中檢索到更高比例的相關項目。但是，如果每秒查詢次數是一個更關鍵的因素，那麼 pgvecto.rs 就超過了 Milvus。但值得注意的是，透過 pgvecto.rs 檢索的資料品質較低，約 37% 的搜尋結果是不相關的項目。</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">根據我們的性能驗證得出的觀察結果：</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">根據我們的性能驗證，我們做出了以下觀察：</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">在 Milvus 中，I/O 設定檔與 OLTP 工作負載非常相似，例如 Oracle SLOB 中的工作負載。基準測試包括三個階段：資料擷取、後最佳化和查詢。初始階段主要以 64KB 寫入操作為特徵，而查詢階段主要涉及 8KB 讀取。我們希望ONTAP能夠熟練地處理 Milvus I/O 負載。</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">PostgreSQL I/O 設定檔不會帶來具有挑戰性的儲存工作負載。鑑於目前正在進行的記憶體實現，我們在查詢階段沒有觀察到任何磁碟 I/O。</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN 成為儲存區分的關鍵技術。它使得向量資料庫搜尋能夠超越系統記憶體邊界進行有效擴展。然而，不太可能透過記憶體中的向量資料庫索引（例如 HNSW）建立儲存效能差異。</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">另外值得注意的是，當索引類型為 HSNW 時，儲存在查詢階段並不起關鍵作用，而查詢階段是支援 RAG 應用的向量資料庫最重要的操作階段。這裡的含義是儲存效能不會顯著影響這些應用程式的整體效能。</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">這是 Netapp 向量資料庫解決方案的摘要頁面。</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">NetApp的向量資料庫解決方案</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">Karthikeyan Nagalingam 與 Rodrigo Nascimento， NetApp</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">本文檔深入探討了使用 NetApp 儲存解決方案部署和管理向量資料庫（例如 Milvus 和開源 PostgreSQL 擴充 pgvecto）的方法。詳細介紹了使用NetApp ONTAP和StorageGRID物件儲存的基礎設施指南，並驗證了 Milvus 資料庫在 AWS FSx ONTAP中的應用。該文件闡明了 NetApp 的文件物件二元性及其對支援向量嵌入的向量資料庫和應用程式的實用性。它強調了 NetApp 企業管理產品SnapCenter的功能，為向量資料庫提供備份和復原功能，確保資料的完整性和可用性。該文件進一步深入探討了 NetApp 的混合雲解決方案，討論了其在本機和雲端環境中的資料複製和保護中的作用。它包括對NetApp ONTAP上向量資料庫效能驗證的見解，並總結了生成 AI 的兩個實際用例：帶有 LLM 的 RAG 和 NetApp 的內部 ChatAI。本文檔是利用 NetApp 儲存解決方案管理向量資料庫的綜合指南。</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">參考架構重點在於以下內容：</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">技術要求</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">解決方案驗證概述</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">Milvus 與Amazon FSx FSx ONTAP for NetApp ONTAP –ONTAP與物件二元NetApp</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">向量資料庫用例</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">附錄 A：values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">附錄C：verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">技術要求-NetApp 的向量資料庫解決方案</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">本節概述了NetApp向量資料庫解決方案的要求。</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">除性能外，下面概述的硬體和軟體配置用於本文檔中執行的大部分驗證。這些配置可作為幫助您設定環境的指南。但請注意，具體組件可能會因個別客戶的要求而有所不同。</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3.49TB SSD-NVM * 兩個靈活組卷：元資料和資料。  * 元資料 NFS 磁碟區有 12 個持久卷，每個磁碟區為 250GB。  * 數據是ONTAP NAS S3 卷</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">6台富士通PRIMERGY RX2540 M4</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64 個 CPU * Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz * 256 GM 實體記憶體 * 1 x 100GbE 網路連接埠</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 x SG100，3xSGF6024 * 3 x 24 x 7.68TB</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">Milvus 集群</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* 圖表 - milvus-4.1.11。  * APP 版本 – 2.3.4 * 依賴的 bundles，例如 bookkeeper、zookeeper、pulsar、etcd、proxy、querynode、worker</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* 5 節點 K8s 叢集 * 1 個主節點和 4 個工作節點 * 版本 – 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">用例 - NetApp 的向量資料庫解決方案</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">本節概述了NetApp向量資料庫解決方案的用例。</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">在本節中，我們討論兩個用例，例如使用大型語言模型的檢索增強生成和NetApp IT 聊天機器人。</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">使用大型語言模型 (LLM) 進行檢索增強生成 (RAG)</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">NVIDIA Enterprise RAG LLM Operator 是企業中實施 RAG 的實用工具。此操作員可用於部署完整的 RAG 管道。 RAG 管道可以客製化為使用 Milvus 或 pgvecto 作為儲存知識庫嵌入的向量資料庫。有關詳細信息，請參閱文件。</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">圖 1) 由NVIDIA NeMo 微服務和NetApp支援的企業 RAG</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">NetApp IT 聊天機器人用例</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">NetApp 的聊天機器人是向量資料庫的另一個即時用例。在這種情況下， NetApp Private OpenAI Sandbox 為管理來自 NetApp 內部使用者的查詢提供了一個有效、安全且高效的平台。透過結合嚴格的安全協議、高效的資料管理系統和複雜的人工智慧處理能力，它保證透過 SSO 身份驗證根據組織中使用者的角色和職責為他們提供高品質、精確的回應。這種架構凸顯了融合先進技術以創建以使用者為中心的智慧系統的潛力。</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">用例可以分為四個主要部分。</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">使用者身份驗證和驗證：</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">使用者查詢首先經過NetApp單一登入 (SSO) 流程確認使用者的身分。</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">身份驗證成功後，系統會檢查VPN連線以確保資料傳輸的安全。</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">資料傳輸和處理：</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">一旦 VPN 驗證通過，資料就會透過 NetAIChat 或 NetAICreate Web 應用程式傳送到 MariaDB。  MariaDB 是一個快速且有效率的資料庫系統，用於管理和儲存使用者資料。</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">然後，MariaDB 將資訊傳送到NetApp Azure 實例，該實例將使用者資料連接到 AI 處理單元。</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">與 OpenAI 和內容過濾的交互作用：</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">Azure 執行個體將使用者的問題傳送至內容過濾系統。系統清理查詢並準備處理。</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">清理後的輸入隨後被傳送到 Azure OpenAI 基礎模型，該模型根據輸入產生回應。</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">回應生成和審核：</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">首先檢查基礎模型的回應，以確保其準確性並符合內容標準。</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">檢查通過後，將回應傳回使用者。此流程可確保使用者收到對其查詢的清晰、準確和適當的答案。</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml - Netapp 的向量資料庫解決方案</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">附錄 A：Values.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">本節提供NetApp向量資料庫解決方案中使用的值的範例 YAML 程式碼。</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">解決方案驗證概述 - NetApp 的向量資料庫解決方案</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">我們針對五個關鍵領域進行了全面的解決方案驗證，具體細節概述如下。每個部分都深入探討了客戶面臨的挑戰、 NetApp提供的解決方案以及隨後為客戶帶來的好處。</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>客戶面臨的挑戰是獨立擴展儲存和運算、有效的基礎設施管理和資料管理。在本節中，我們詳細介紹了在 Kubernetes 上安裝 Milvus 叢集的過程，並利用NetApp儲存控制器儲存叢集資料和客戶資料。</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">milvus 與 Amazon FSx ONTAP for NetApp ONTAP – 檔案與物件二元性 在本節中，我們將介紹為何ONTAP在雲端部署向量資料庫，以及在NetApp Amazon FSxAmazon FSxONTAPNetAppONTAP（milvus 獨立版）的步驟。</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>在本節中，我們將深入探討SnapCenter如何保護駐留在ONTAP中的向量資料庫資料和 Milvus 資料。在此範例中，我們利用源自 NFS ONTAP磁碟區（vol1）的 NAS 儲存桶（milvusdbvol1）來儲存客戶數據，並使用單獨的 NFS 磁碟區（vectordbpv）來儲存 Milvus 叢集配置資料。</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>在本節中，我們討論災難復原（DR）對於向量資料庫的重要性以及NetApp災難復原產品SnapMirror如何為向量資料庫提供DR解決方案。</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>在本節中，我們旨在深入研究向量資料庫（例如 Milvus 和 pgvecto.rs）的效能驗證，重點關注它們的儲存效能特徵，例如 I/O 設定檔和 NetApp 儲存控制器在 LLM 生命週期內支援 RAG 和推理工作負載的行為。當這些資料庫與ONTAP儲存解決方案結合時，我們將評估並識別任何效能差異因素。我們的分析將基於關鍵效能指標，例如每秒處理的查詢數（QPS）。</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py - netapp 的向量資料庫解決方案</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">本節包含一個範例 Python 腳本，可用於驗證NetApp向量資料庫解決方案中的向量資料庫。</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">觀看有關NetApp的 AI 解決方案的視頻</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">了解NetApp如何支援 AI 和機器學習計劃。這些精選的影片播放清單展示了NetApp AI 解決方案和 MLOps 工作流程，重點介紹了進階分析的部署策略、自動化和資料管理。</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">NetApp AI 解決方案</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">觀看NetApp AI 解決方案播放列表</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">全面的視訊播放列表，涵蓋 AI 基礎設施、融合系統和企業 AI 部署。<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">機器學習操作 (MLOps)</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">觀看 MLOps 播放列表</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">有關 MLOps 工作流程、資料管道和最佳操作實踐的影片系列。<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">一系列影片和示範討論了 NetApp 眾多解決方案的功能</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">NetApp解決方案：影片與示範</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">概述影片和演示，重點介紹 NetApp 的許多解決方案的具體功能。</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">NetApp人工智慧解決方案附件的最新變更日誌。</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">NetApp人工智慧解決方案的新功能</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">了解人工智慧解決方案的最新動態。</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">2025年8月18日</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">NetApp解決方案系列</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">NetApp解決方案網站現在是<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block>，其中包括以下網站：</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">NetApp人工智慧解決方案</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">NetApp容器解決方案</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">NetApp資料管理解決方案</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">NetApp資料庫解決方案</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">NetApp公有雲與混合雲解決方案</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">適用於 SAP 的NetApp解決方案</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">NetApp虛擬化解決方案</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">NetApp提供全面的 AI 解決方案，結合企業級資料管理、經過驗證的參考架構和策略合作夥伴關係，以加速您的 AI 計劃並支援關鍵業務成果。從基礎架構部署到 MLOps 自動化，我們的解決方案可在邊緣、資料中心和混合雲環境之間無縫擴展。</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">開始</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">什麼是新的</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">部落格</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">影片和演示</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">人工智慧基礎設施和融合系統</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">搭載NVIDIA DGX 系統的NetApp AIPod</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">搭載 EF 系列的NVIDIA DGX SuperPOD</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NetApp AIPod與聯想攜手為NVIDIA OVX 提供支持</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">E系列的BeeGFS平行檔案系統</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">人工智慧用例和應用</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">用於 RAG 推理的AIPod Mini</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">邊緣人工智慧推理</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">向量資料庫解決方案</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">自動駕駛工作負載</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">昆騰 StorNext E 系列</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOps 與資料管理</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">NetApp的開源 MLOps</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">Domino Data Lab 的混合多雲 MLOps</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">適用於 MLOps 的 FSx ONTAP</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">大數據和混合雲AI解決方案</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">混合雲端資料解決方案</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Apache Spark 解決方案</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">Confluent Kafka 與NetApp ONTAP存儲</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID與 Splunk SmartStore</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">配備NetApp儲存的 Dremio Lakehouse</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">解決方案請求和回饋</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">請求自動化</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">提出新的解決方案</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">提供解決方案回饋</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">利用 NetApp 全面的 MLOps 和資料管理解決方案簡化您的 AI/ML 工作流程。從開源平台到企業級工具，我們的解決方案能夠在混合雲環境中實現高效的模型開發、部署和擴展，同時確保資料一致性和效能。</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">NetApp MLOps 與資料管理解決方案</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">開源 MLOps 平台</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">針對AIPod 的NetApp Trident配置</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Apache Airflow 部署與集成</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">JupyterHub部署與資料操作</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">MLflow 部署和可追溯性</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">進階 MLOps 工作流程</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Kubeflow 部署和筆記本</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">使用 Kubeflow 訓練圖像辨識模型</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">單節點 AI 工作負載執行</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">分散式 AI 工作負載執行</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">使用SnapMirror進行資料擷取</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">企業 MLOps 解決方案</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">Domino Data Lab 的混合 MLOps</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">使用 Domino 進行跨環境資料訪問</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">NVIDIA NGC 軟體集成</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">Cloud MLOps 和 AWS 集成</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">適用於ONTAP MLOps 的Amazon FSx</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">將 FSx ONTAP作為私有 S3 整合到 SageMaker 中</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">用於 SageMaker 模型訓練的 FSx ONTAP</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">使用 FSx 建立簡化的 MLOps 管道</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">向量資料庫和人工智慧應用</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">NetApp的向量資料庫解決方案</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">使用 Kubernetes 設定 Milvus 集群</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">使用SnapCenter進行向量資料庫保護</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">向量資料庫效能驗證</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">向量資料庫用例</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">資料管理工具和存儲</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">用於自動駕駛的StorageGRID資料湖</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">使用SnapMirror進行災難復原</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">利用 NetApp 經過驗證的參考架構和融合系統部署企業級 AI 基礎架構。從NetApp AIPod解決方案到高效能儲存平台，我們的設計可提供要求嚴苛的 AI/ML 工作負載所需的效能、可擴充性和可靠性。</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">NetApp AI 基礎架構與融合系統</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">NetApp AIPod參考架構</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">AIPod架構</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">AIPod部署細節</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">AIPod驗證和尺寸指南</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">適用於 AI 工作負載的高效能存儲</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">搭載 EF 系列儲存的NVIDIA DGX SuperPOD</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">配備 E 系列儲存的 IBM Spectrum Scale</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">NetApp ONTAP與聯想 ThinkSystem</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">使用NetApp解決方案探索現實世界的 AI 實施，從企業 RAG 系統和邊緣推理到負責任的 AI 實踐和資料遷移策略。這些用例展示了NetApp如何幫助組織在不同環境中部署 AI 應用程序，同時保持安全性、效能和可擴展性。</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">NetApp AI 用例和應用程式</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">使用NetApp解決方案探索現實世界的 AI 實施，從企業 RAG 系統和邊緣推理到負責任的 AI 實踐和資料遷移策略。這些用例展示了NetApp如何在保持安全性、效能和可擴展性的同時，在不同環境中支援 AI 應用程式。</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">企業 AI 應用程式和用例</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">適用於企業 RAG 的NetApp AIPod Mini</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">生成式人工智慧和NetApp價值</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">NetApp和聯想合作的邊緣 AI 推理</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">大數據分析向人工智慧遷移</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">負責任的人工智慧</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">Protopia 影像轉換的負責任的 AI</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">AI儲存和基礎設施解決方案</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">採用 E 系列系統設計 Quantum StorNext</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">使用 E 系列系統部署 Quantum StorNext</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">利用 NetApp 針對大數據工作負載的成熟解決方案（包括 Apache Spark、Hadoop、Kafka 以及從邊緣擴展到雲端的現代資料湖架構）轉變您的資料分析基礎架構。</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">NetApp現代資料分析解決方案</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">NetApp現代資料分析解決方案是一套策略和技術能力，展現了NetApp儲存在 AI 領域的能力。</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Apache Kafka 解決方案</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">使用NetApp NFS 儲存的 Apache Kafka 工作負載</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka 與NetApp ONTAP儲存控制器</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Confluent Kafka 的最佳實踐</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">使用 AWS 驗證 Kafka 效能</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Apache Spark 和 Hadoop 解決方案</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">適用於 Apache Spark 的NetApp儲存解決方案</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">使用NetApp儲存部署 Apache Spark 工作負載</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">適用於 Spark 和 Hadoop 的NetApp混合雲資料解決方案</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">用例和架構</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Apache Spark 測試結果</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">雲端資料管理與人工智慧</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">利用NetApp文件物件二元性和 AWS SageMaker 進行雲端資料管理</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">大數據分析到人工智慧</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">Amazon FSx for NetApp ONTAP （適用於 MLOps）</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Apache Spark 混合雲解決方案</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">現代資料湖與分析平台</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">NetApp和 Dremio 的下一代混合冰山湖屋解決方案</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E系列E5700和Splunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">其他資源</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">針對不同分析策略的不同解決方案</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">部落格：Apache Spark 在NetApp資料分析實務中大顯身手</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">部落格：使用 XCP 將資料從資料湖和 HPC 遷移到ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV：大數據分析播放列表</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">人工智慧解決方案</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">影片</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">NetApp Trident配置</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">用於AIPod部署的Trident後端</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">用於AIPod部署的 Kubernetes StorageClasses</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Apache Airflow 部署</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">JupyterHub 部署</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">使用NetApp SnapMirror擷取數據</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">MLflow 部署</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">使用NetApp和 MLflow 實現資料集到模型的可追溯性</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Kubeflow 部署</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">預配 Jupyter Notebook 工作區</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">訓練圖像辨識模型 - 範例工作流程</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Trident操作範例</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">AIPod部署的高效能作業範例</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">執行單節點 AI 工作負載</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">執行同步分散式 AI 工作負載</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">Domino Data Lab 和NetApp的混合 MLOps</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">初始設定</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">將現有的NetApp卷公開給 Domino</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">跨不同環境存取相同數據</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">附加資訊</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">使用NVIDIA NGC 軟體</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">使用案例範例 - TensorFlow 訓練作業</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">第 1 部分 - 將Amazon FSx for NetApp ONTAP作為私有 S3 儲存桶整合到 AWS SageMaker</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">第 2 部分 - 利用Amazon FSx for NetApp ONTAP作為 SageMaker 中模型訓練的資料來源</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">第 3 部分 - 建立簡化的 MLOps 管道</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">適用於自動駕駛工作負載的NetApp StorageGRID資料湖</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">NetApp的向量資料庫解決方案</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">向量資料庫</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">技術要求</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">使用SnapCenter進行向量資料庫保護</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">使用SnapMirror進行災難復原</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">使用 PostGreSQL 的 Instaclustr 向量資料庫：pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">附錄 B：prepare_data_netapp_new_py</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">附錄 D：docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">人工智慧融合基礎設施</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">搭載NVIDIA DGX 系統的 NVA-1173 NetApp AIPod</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">硬體組件</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">軟體元件</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">範例部署詳細信息</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">驗證和尺寸指導</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">結論和補充信息</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">搭載NetApp EF 系列的NVIDIA DGX SuperPOD</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">NetApp上的 BeeGFS 與 E 系列存儲</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">使用 E 系列儲存部署 IBM Spectrum Scale</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">ONTAP和聯想 ThinkSystem 的 AI 解決方案</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP與聯想 ThinkSystem SR670 輔助 AI</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">人工智慧用例</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">適用於 RAG 推理的NetApp AIPod Mini</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">負責任的 AI 和機密推理 - NetApp AI 與 Protopia 影像轉換</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">將資料從大數據環境遷移到人工智慧環境</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">邊緣 AI 推理 - NetApp與聯想 ThinkSystem - 解決方案設計</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">Quantum StorNext 與NetApp E 系列系統設計指南</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">Quantum StorNext 與NetApp E 系列系統部署指南</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">現代數據分析</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">NetApp針對 NFS 到 Kafka 工作負載中愚蠢重命名問題的解決方案</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">AWS 中的效能概述與驗證 - Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">AWS 中的效能概述與驗證 - FSx for NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">使用AFF本地進行效能概述和驗證</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">匯合性能驗證</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">用例摘要</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS 到 NFS - 詳細步驟</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Confluent 自我再平衡集群</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetApp混合雲資料解決方案 - 基於客戶使用案例的 Spark 和 Hadoop</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">用例 1 - 備份 Hadoop 數據</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">用例 2 - 從雲端到本地的備份和災難恢復</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">用例 3 - 在現有 Hadoop 資料上啟用 DevTest</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">用例 4 - 資料保護和多雲連接</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">用例 5 - 加速分析工作負載</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">NetApp和 Dremio 的下一代混合 Iceberg Lakehouse 解決方案</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">客戶用例</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">針對不同分析策略的不同解決方案解決方案簡介</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">Splunk SmartStore 的StorageGRID功能</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">分層和成本節省</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">單站點 SmartStore 效能</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Apache Spark 工作負載與NetApp儲存解決方案（部署指南）</block>
</blocks>